[0m18:17:20.572546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088dc450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084f8d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10893bc90>]}


============================== 18:17:20.576232 | 31b8cde6-9a60-481e-afe9-9b1a72ef75f9 ==============================
[0m18:17:20.576232 [info ] [MainThread]: Running with dbt=1.8.5
[0m18:17:20.576675 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/vaishnavitamilvanan/.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/vaishnavitamilvanan/Documents/GW MS DS/Semester/Fall 2024/NLP/PycharmProjects/Medallion-Spark-Azure-DBT/medallion_dbt_spark/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:17:20.587307 [info ] [MainThread]: dbt version: 1.8.5
[0m18:17:20.587633 [info ] [MainThread]: python version: 3.11.8
[0m18:17:20.587840 [info ] [MainThread]: python path: /Users/vaishnavitamilvanan/anaconda3/bin/python
[0m18:17:20.588006 [info ] [MainThread]: os info: macOS-14.6.1-arm64-arm-64bit
[0m18:17:20.687526 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m18:17:20.688016 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m18:17:20.688218 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m18:17:21.710835 [info ] [MainThread]: Using profiles dir at /Users/vaishnavitamilvanan/.dbt
[0m18:17:21.711299 [info ] [MainThread]: Using profiles.yml file at /Users/vaishnavitamilvanan/.dbt/profiles.yml
[0m18:17:21.711480 [info ] [MainThread]: Using dbt_project.yml file at /Users/vaishnavitamilvanan/Documents/GW MS DS/Semester/Fall 2024/NLP/PycharmProjects/Medallion-Spark-Azure-DBT/medallion_dbt_spark/dbt_project.yml
[0m18:17:21.711634 [info ] [MainThread]: adapter type: databricks
[0m18:17:21.711774 [info ] [MainThread]: adapter version: 1.8.5
[0m18:17:21.757916 [info ] [MainThread]: Configuration:
[0m18:17:21.758268 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m18:17:21.758434 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m18:17:21.758579 [info ] [MainThread]: Required dependencies:
[0m18:17:21.758792 [debug] [MainThread]: Executing "git --help"
[0m18:17:21.786810 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m18:17:21.787801 [debug] [MainThread]: STDERR: "b''"
[0m18:17:21.788055 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m18:17:21.788419 [info ] [MainThread]: Connection:
[0m18:17:21.788876 [info ] [MainThread]:   host: adb-2326510497682104.4.azuredatabricks.net
[0m18:17:21.789050 [info ] [MainThread]:   http_path: sql/protocolv1/o/2326510497682104/0824-185250-ymhg59n
[0m18:17:21.789194 [info ] [MainThread]:   catalog: hive_metastore
[0m18:17:21.789322 [info ] [MainThread]:   schema: saleslt
[0m18:17:21.789785 [info ] [MainThread]: Registered adapter: databricks=1.8.5
[0m18:17:21.798487 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5299085328, session-id=None, name=debug, idle-time=0s, acquire-count=0, language=None, thread-identifier=(2908, 8194199360), compute-name=) - Creating connection
[0m18:17:21.799131 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m18:17:21.799338 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5299085328, session-id=None, name=debug, idle-time=2.1457672119140625e-06s, acquire-count=1, language=None, thread-identifier=(2908, 8194199360), compute-name=) - Acquired connection on thread (2908, 8194199360), using default compute resource
[0m18:17:21.799562 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5299085328, session-id=None, name=debug, idle-time=0.0002491474151611328s, acquire-count=1, language=None, thread-identifier=(2908, 8194199360), compute-name=) - Checking idleness
[0m18:17:21.799748 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5299085328, session-id=None, name=debug, idle-time=0.00043010711669921875s, acquire-count=1, language=None, thread-identifier=(2908, 8194199360), compute-name=) - Retrieving connection
[0m18:17:21.799902 [debug] [MainThread]: Using databricks connection "debug"
[0m18:17:21.800055 [debug] [MainThread]: On debug: select 1 as id
[0m18:17:21.800224 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:17:22.106256 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5299085328, session-id=73aaee5b-73ca-467a-9d3c-43a8d9686f1b, name=debug, idle-time=1.0967254638671875e-05s, acquire-count=1, language=None, thread-identifier=(2908, 8194199360), compute-name=) - Connection created
[0m18:17:22.107229 [debug] [MainThread]: Databricks adapter: Cursor(session-id=73aaee5b-73ca-467a-9d3c-43a8d9686f1b, command-id=Unknown) - Created cursor
[0m18:17:22.310432 [debug] [MainThread]: SQL status: OK in 0.510 seconds
[0m18:17:22.312196 [debug] [MainThread]: Databricks adapter: Cursor(session-id=73aaee5b-73ca-467a-9d3c-43a8d9686f1b, command-id=2f97c267-3e30-42c9-9fd8-e8393cadd434) - Closing cursor
[0m18:17:22.312835 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5299085328, session-id=73aaee5b-73ca-467a-9d3c-43a8d9686f1b, name=debug, idle-time=4.0531158447265625e-06s, acquire-count=0, language=None, thread-identifier=(2908, 8194199360), compute-name=) - Released connection
[0m18:17:22.313168 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m18:17:22.313452 [info ] [MainThread]: [32mAll checks passed![0m
[0m18:17:22.317230 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 1.8258889, "process_user_time": 2.000514, "process_kernel_time": 2.235266, "process_mem_max_rss": "209960960", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m18:17:22.317762 [debug] [MainThread]: Command `dbt debug` succeeded at 18:17:22.317672 after 1.83 seconds
[0m18:17:22.318048 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m18:17:22.318265 [debug] [MainThread]: On debug: Close
[0m18:17:22.318478 [debug] [MainThread]: Databricks adapter: Connection(session-id=73aaee5b-73ca-467a-9d3c-43a8d9686f1b) - Closing connection
[0m18:17:22.508129 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088d7b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108950590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13bd9a010>]}
[0m18:17:22.509709 [debug] [MainThread]: Flushing usage events
[0m08:40:13.909718 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105744990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105747690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057b9590>]}


============================== 08:40:13.913264 | cd4848bb-684c-4b5e-8e3b-f3a1d4a8a865 ==============================
[0m08:40:13.913264 [info ] [MainThread]: Running with dbt=1.8.5
[0m08:40:13.913742 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/vaishnavitamilvanan/.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/vaishnavitamilvanan/Documents/GW MS DS/Semester/Fall 2024/NLP/PycharmProjects/Medallion-Spark-Azure-DBT/medallion_dbt_spark/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt snapshot', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:40:14.022035 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m08:40:14.022499 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m08:40:14.022718 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m08:40:15.472598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cd4848bb-684c-4b5e-8e3b-f3a1d4a8a865', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1273a7a10>]}
[0m08:40:15.500198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cd4848bb-684c-4b5e-8e3b-f3a1d4a8a865', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127316090>]}
[0m08:40:15.500590 [info ] [MainThread]: Registered adapter: databricks=1.8.5
[0m08:40:15.521446 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m08:40:15.522164 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m08:40:15.522443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'cd4848bb-684c-4b5e-8e3b-f3a1d4a8a865', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127458c90>]}
[0m08:40:16.545992 [error] [MainThread]: Encountered an error:
Compilation Error
  Snapshot 'snapshot.medallion_dbt_spark.customer_snapshot' (snapshots/customer.sql) depends on a source named 'saleslt.customer' which was not found
[0m08:40:16.555178 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_wall_clock_time": 2.715917, "process_user_time": 2.94655, "process_kernel_time": 2.277284, "process_mem_max_rss": "212090880", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m08:40:16.555592 [debug] [MainThread]: Command `dbt snapshot` failed at 08:40:16.555527 after 2.72 seconds
[0m08:40:16.555850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057d2810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10573fe90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127cd2b90>]}
[0m08:40:16.556082 [debug] [MainThread]: Flushing usage events
[0m09:10:07.129548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d95f350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d9ad8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d9bb7d0>]}


============================== 09:10:07.132970 | f9bdd36d-6fd4-48e8-b48e-34233b9a4779 ==============================
[0m09:10:07.132970 [info ] [MainThread]: Running with dbt=1.8.5
[0m09:10:07.133479 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/vaishnavitamilvanan/.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/vaishnavitamilvanan/Documents/GW MS DS/Semester/Fall 2024/NLP/PycharmProjects/Medallion-Spark-Azure-DBT/medallion_dbt_spark/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:10:07.146898 [info ] [MainThread]: dbt version: 1.8.5
[0m09:10:07.147218 [info ] [MainThread]: python version: 3.11.8
[0m09:10:07.147425 [info ] [MainThread]: python path: /Users/vaishnavitamilvanan/anaconda3/bin/python
[0m09:10:07.147601 [info ] [MainThread]: os info: macOS-14.6.1-arm64-arm-64bit
[0m09:10:07.258976 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m09:10:07.259550 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m09:10:07.259767 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m09:10:08.326577 [info ] [MainThread]: Using profiles dir at /Users/vaishnavitamilvanan/.dbt
[0m09:10:08.326986 [info ] [MainThread]: Using profiles.yml file at /Users/vaishnavitamilvanan/.dbt/profiles.yml
[0m09:10:08.327201 [info ] [MainThread]: Using dbt_project.yml file at /Users/vaishnavitamilvanan/Documents/GW MS DS/Semester/Fall 2024/NLP/PycharmProjects/Medallion-Spark-Azure-DBT/medallion_dbt_spark/dbt_project.yml
[0m09:10:08.327390 [info ] [MainThread]: adapter type: databricks
[0m09:10:08.327560 [info ] [MainThread]: adapter version: 1.8.5
[0m09:10:08.375892 [info ] [MainThread]: Configuration:
[0m09:10:08.376276 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m09:10:08.376464 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m09:10:08.376632 [info ] [MainThread]: Required dependencies:
[0m09:10:08.377868 [debug] [MainThread]: Executing "git --help"
[0m09:10:08.407215 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m09:10:08.408188 [debug] [MainThread]: STDERR: "b''"
[0m09:10:08.408452 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m09:10:08.408672 [info ] [MainThread]: Connection:
[0m09:10:08.408946 [info ] [MainThread]:   host: adb-2326510497682104.4.azuredatabricks.net
[0m09:10:08.409103 [info ] [MainThread]:   http_path: sql/protocolv1/o/2326510497682104/0824-185250-ymhg59n
[0m09:10:08.409247 [info ] [MainThread]:   catalog: hive_metastore
[0m09:10:08.409390 [info ] [MainThread]:   schema: saleslt
[0m09:10:08.409819 [info ] [MainThread]: Registered adapter: databricks=1.8.5
[0m09:10:08.418307 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5867697488, session-id=None, name=debug, idle-time=0s, acquire-count=0, language=None, thread-identifier=(6228, 8194199360), compute-name=) - Creating connection
[0m09:10:08.419124 [debug] [MainThread]: Acquiring new databricks connection 'debug'
[0m09:10:08.419479 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5867697488, session-id=None, name=debug, idle-time=3.0994415283203125e-06s, acquire-count=1, language=None, thread-identifier=(6228, 8194199360), compute-name=) - Acquired connection on thread (6228, 8194199360), using default compute resource
[0m09:10:08.419883 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5867697488, session-id=None, name=debug, idle-time=0.0003712177276611328s, acquire-count=1, language=None, thread-identifier=(6228, 8194199360), compute-name=) - Checking idleness
[0m09:10:08.420113 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5867697488, session-id=None, name=debug, idle-time=0.0006530284881591797s, acquire-count=1, language=None, thread-identifier=(6228, 8194199360), compute-name=) - Retrieving connection
[0m09:10:08.420317 [debug] [MainThread]: Using databricks connection "debug"
[0m09:10:08.420492 [debug] [MainThread]: On debug: select 1 as id
[0m09:10:08.420670 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:17:13.190363 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5867697488, session-id=5a068423-29aa-4de5-8bf3-036d436075d1, name=debug, idle-time=3.600120544433594e-05s, acquire-count=1, language=None, thread-identifier=(6228, 8194199360), compute-name=) - Connection created
[0m09:17:13.192766 [debug] [MainThread]: Databricks adapter: Cursor(session-id=5a068423-29aa-4de5-8bf3-036d436075d1, command-id=Unknown) - Created cursor
[0m09:17:52.799836 [debug] [MainThread]: SQL status: OK in 464.380 seconds
[0m09:17:52.801442 [debug] [MainThread]: Databricks adapter: Cursor(session-id=5a068423-29aa-4de5-8bf3-036d436075d1, command-id=054080f8-c236-49ae-a63e-5771ec19bceb) - Closing cursor
[0m09:17:52.923753 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5867697488, session-id=5a068423-29aa-4de5-8bf3-036d436075d1, name=debug, idle-time=8.821487426757812e-06s, acquire-count=0, language=None, thread-identifier=(6228, 8194199360), compute-name=) - Released connection
[0m09:17:52.924569 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m09:17:52.925060 [info ] [MainThread]: [32mAll checks passed![0m
[0m09:17:52.931397 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 465.87262, "process_user_time": 2.063604, "process_kernel_time": 2.235468, "process_mem_max_rss": "207257600", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:17:52.932070 [debug] [MainThread]: Command `dbt debug` succeeded at 09:17:52.931841 after 465.87 seconds
[0m09:17:52.932815 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m09:17:52.933239 [debug] [MainThread]: On debug: Close
[0m09:17:52.933457 [debug] [MainThread]: Databricks adapter: Connection(session-id=5a068423-29aa-4de5-8bf3-036d436075d1) - Closing connection
[0m09:17:53.432505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d9b8210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x15db98350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d674850>]}
[0m09:17:53.433825 [debug] [MainThread]: Flushing usage events
[0m09:18:10.063742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094e3550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094e2f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10953f7d0>]}


============================== 09:18:10.067218 | 06e1a7be-e2c9-4e47-be40-d96d87060b77 ==============================
[0m09:18:10.067218 [info ] [MainThread]: Running with dbt=1.8.5
[0m09:18:10.067705 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/vaishnavitamilvanan/Documents/GW MS DS/Semester/Fall 2024/NLP/PycharmProjects/Medallion-Spark-Azure-DBT/medallion_dbt_spark/logs', 'profiles_dir': '/Users/vaishnavitamilvanan/.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt snapshot', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:18:10.169200 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m09:18:10.169723 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m09:18:10.169934 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m09:18:11.322207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '06e1a7be-e2c9-4e47-be40-d96d87060b77', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13c30dc10>]}
[0m09:18:11.349428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '06e1a7be-e2c9-4e47-be40-d96d87060b77', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083318d0>]}
[0m09:18:11.349836 [info ] [MainThread]: Registered adapter: databricks=1.8.5
[0m09:18:11.370029 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m09:18:11.370726 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m09:18:11.370982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '06e1a7be-e2c9-4e47-be40-d96d87060b77', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13c3b3050>]}
[0m09:18:12.530717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '06e1a7be-e2c9-4e47-be40-d96d87060b77', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13dc7e0d0>]}
[0m09:18:12.608645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '06e1a7be-e2c9-4e47-be40-d96d87060b77', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13dc8a4d0>]}
[0m09:18:12.609000 [info ] [MainThread]: Found 2 models, 7 snapshots, 4 data tests, 9 sources, 590 macros
[0m09:18:12.609257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '06e1a7be-e2c9-4e47-be40-d96d87060b77', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13d854610>]}
[0m09:18:12.610439 [info ] [MainThread]: 
[0m09:18:12.610859 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5352284624, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(6275, 8194199360), compute-name=) - Creating connection
[0m09:18:12.611048 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m09:18:12.611237 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5352284624, session-id=None, name=master, idle-time=2.1457672119140625e-06s, acquire-count=1, language=None, thread-identifier=(6275, 8194199360), compute-name=) - Acquired connection on thread (6275, 8194199360), using default compute resource
[0m09:18:12.614681 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=None, name=list_hive_metastore, idle-time=0s, acquire-count=0, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Creating connection
[0m09:18:12.614904 [debug] [ThreadPool]: Acquiring new databricks connection 'list_hive_metastore'
[0m09:18:12.615083 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=None, name=list_hive_metastore, idle-time=9.5367431640625e-07s, acquire-count=1, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Acquired connection on thread (6275, 6135099392), using default compute resource
[0m09:18:12.615287 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=None, name=list_hive_metastore, idle-time=0.00020813941955566406s, acquire-count=1, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:12.615461 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=None, name=list_hive_metastore, idle-time=0.0003871917724609375s, acquire-count=1, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Retrieving connection
[0m09:18:12.615619 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore"
[0m09:18:12.615770 [debug] [ThreadPool]: On list_hive_metastore: GetSchemas(database=hive_metastore, schema=None)
[0m09:18:12.616109 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:18:12.971053 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore, idle-time=1.6927719116210938e-05s, acquire-count=1, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Connection created
[0m09:18:12.972217 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=Unknown) - Created cursor
[0m09:18:18.023333 [debug] [ThreadPool]: SQL status: OK in 5.410 seconds
[0m09:18:18.034275 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=1fff7599-14a7-4f12-a9a5-bafce838ee7d) - Closing cursor
[0m09:18:18.034684 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore, idle-time=3.0994415283203125e-06s, acquire-count=0, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:18:18.035300 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore, idle-time=0.0006310939788818359s, acquire-count=0, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:18.035543 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_hive_metastore, now create_hive_metastore_snapshots)
[0m09:18:18.035778 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=create_hive_metastore_snapshots, idle-time=0.0011110305786132812s, acquire-count=0, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Reusing connection previously named list_hive_metastore
[0m09:18:18.035995 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=create_hive_metastore_snapshots, idle-time=0.00133514404296875s, acquire-count=1, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Acquired connection on thread (6275, 6135099392), using default compute resource
[0m09:18:18.036266 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=create_hive_metastore_snapshots, idle-time=0.0016050338745117188s, acquire-count=1, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:18.036491 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=create_hive_metastore_snapshots, idle-time=0.0018320083618164062s, acquire-count=2, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Acquired connection on thread (6275, 6135099392), using default compute resource
[0m09:18:18.036750 [debug] [ThreadPool]: Creating schema "database: "hive_metastore"
schema: "snapshots"
"
[0m09:18:18.043081 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=create_hive_metastore_snapshots, idle-time=0.008415937423706055s, acquire-count=2, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:18.043292 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=create_hive_metastore_snapshots, idle-time=0.00864100456237793s, acquire-count=2, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Retrieving connection
[0m09:18:18.043483 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=create_hive_metastore_snapshots, idle-time=0.008836030960083008s, acquire-count=2, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:18.043645 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=create_hive_metastore_snapshots, idle-time=0.009001016616821289s, acquire-count=2, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Retrieving connection
[0m09:18:18.043790 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m09:18:18.043923 [debug] [ThreadPool]: Using databricks connection "create_hive_metastore_snapshots"
[0m09:18:18.044087 [debug] [ThreadPool]: On create_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "create_hive_metastore_snapshots"} */
create schema if not exists `hive_metastore`.`snapshots`
  
[0m09:18:18.044252 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=Unknown) - Created cursor
[0m09:18:18.832039 [debug] [ThreadPool]: SQL status: OK in 0.790 seconds
[0m09:18:18.832763 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=3db86b0a-3be4-47ba-b519-b940ec743362) - Closing cursor
[0m09:18:18.833006 [debug] [ThreadPool]: Spark adapter: NotImplemented: commit
[0m09:18:18.833192 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=create_hive_metastore_snapshots, idle-time=0.7985379695892334s, acquire-count=1, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:18:18.833442 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=create_hive_metastore_snapshots, idle-time=9.5367431640625e-07s, acquire-count=0, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:18:18.834413 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=create_hive_metastore_snapshots, idle-time=0.0009658336639404297s, acquire-count=0, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:18.834644 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_hive_metastore_snapshots, now list_hive_metastore_snapshots)
[0m09:18:18.834836 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore_snapshots, idle-time=0.0013947486877441406s, acquire-count=0, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Reusing connection previously named create_hive_metastore_snapshots
[0m09:18:18.835011 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore_snapshots, idle-time=0.0015707015991210938s, acquire-count=1, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Acquired connection on thread (6275, 6135099392), using default compute resource
[0m09:18:18.835203 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore_snapshots, idle-time=0.0017657279968261719s, acquire-count=1, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:18.835367 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore_snapshots, idle-time=0.0019309520721435547s, acquire-count=1, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Retrieving connection
[0m09:18:18.835517 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:18:18.835663 [debug] [ThreadPool]: On list_hive_metastore_snapshots: GetTables(database=hive_metastore, schema=snapshots, identifier=None)
[0m09:18:18.835815 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=Unknown) - Created cursor
[0m09:18:19.243503 [debug] [ThreadPool]: SQL status: OK in 0.410 seconds
[0m09:18:19.247704 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=18d5c8d2-bb84-4d03-9d0f-523892dfee49) - Closing cursor
[0m09:18:19.248012 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore_snapshots, idle-time=9.5367431640625e-07s, acquire-count=0, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:18:19.248323 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore_snapshots, idle-time=0.0003199577331542969s, acquire-count=0, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:19.248534 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_hive_metastore_snapshots, now list_hive_metastore_saleslt)
[0m09:18:19.248740 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore_saleslt, idle-time=0.0007350444793701172s, acquire-count=0, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Reusing connection previously named list_hive_metastore_snapshots
[0m09:18:19.249008 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore_saleslt, idle-time=0.0009770393371582031s, acquire-count=1, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Acquired connection on thread (6275, 6135099392), using default compute resource
[0m09:18:19.249313 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore_saleslt, idle-time=0.0012881755828857422s, acquire-count=1, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:19.249587 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore_saleslt, idle-time=0.001566171646118164s, acquire-count=1, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Retrieving connection
[0m09:18:19.249817 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:18:19.250056 [debug] [ThreadPool]: On list_hive_metastore_saleslt: GetTables(database=hive_metastore, schema=saleslt, identifier=None)
[0m09:18:19.250270 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=Unknown) - Created cursor
[0m09:18:19.396451 [debug] [ThreadPool]: SQL status: OK in 0.150 seconds
[0m09:18:19.399669 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=2d106e08-2571-46b8-baf2-50e154317d42) - Closing cursor
[0m09:18:19.403368 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore_saleslt, idle-time=0.15535187721252441s, acquire-count=1, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:19.403586 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore_saleslt, idle-time=0.1555800437927246s, acquire-count=1, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Retrieving connection
[0m09:18:19.403752 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:18:19.403918 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */

      select current_catalog()
  
[0m09:18:19.404082 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=Unknown) - Created cursor
[0m09:18:19.754984 [debug] [ThreadPool]: SQL status: OK in 0.350 seconds
[0m09:18:19.756293 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=d888fc91-1645-4b0e-b803-4bdff397dc2e) - Closing cursor
[0m09:18:19.759877 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore_saleslt, idle-time=0.5118319988250732s, acquire-count=1, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:19.760214 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore_saleslt, idle-time=0.5121891498565674s, acquire-count=1, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Retrieving connection
[0m09:18:19.760470 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:18:19.760740 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */
show views in `hive_metastore`.`saleslt`
  
[0m09:18:19.761000 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=Unknown) - Created cursor
[0m09:18:20.370920 [debug] [ThreadPool]: SQL status: OK in 0.610 seconds
[0m09:18:20.375605 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=b9e70c46-3143-4171-9b9d-b1edccce5c74) - Closing cursor
[0m09:18:20.376540 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore_saleslt, idle-time=5.0067901611328125e-06s, acquire-count=0, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:18:20.378136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '06e1a7be-e2c9-4e47-be40-d96d87060b77', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13da44210>]}
[0m09:18:20.378504 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5352284624, session-id=None, name=master, idle-time=7.767266035079956s, acquire-count=1, language=None, thread-identifier=(6275, 8194199360), compute-name=) - Checking idleness
[0m09:18:20.378677 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5352284624, session-id=None, name=master, idle-time=7.767452001571655s, acquire-count=1, language=None, thread-identifier=(6275, 8194199360), compute-name=) - Retrieving connection
[0m09:18:20.378848 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5352284624, session-id=None, name=master, idle-time=7.767627000808716s, acquire-count=1, language=None, thread-identifier=(6275, 8194199360), compute-name=) - Checking idleness
[0m09:18:20.379008 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5352284624, session-id=None, name=master, idle-time=7.767786026000977s, acquire-count=1, language=None, thread-identifier=(6275, 8194199360), compute-name=) - Retrieving connection
[0m09:18:20.379201 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m09:18:20.379375 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m09:18:20.379549 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5352284624, session-id=None, name=master, idle-time=2.1457672119140625e-06s, acquire-count=0, language=None, thread-identifier=(6275, 8194199360), compute-name=) - Released connection
[0m09:18:20.379822 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:18:20.380008 [info ] [MainThread]: 
[0m09:18:20.382141 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.address_snapshot
[0m09:18:20.382456 [info ] [Thread-1 (]: 1 of 7 START snapshot snapshots.address_snapshot ............................... [RUN]
[0m09:18:20.382776 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=list_hive_metastore_saleslt, idle-time=0.006253957748413086s, acquire-count=0, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:20.382954 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_hive_metastore_saleslt, now snapshot.medallion_dbt_spark.address_snapshot)
[0m09:18:20.383205 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.006644248962402344s, acquire-count=0, language=None, thread-identifier=(6275, 6135099392), compute-name=) - Reusing connection previously named list_hive_metastore_saleslt
[0m09:18:20.383553 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.006984233856201172s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Acquired connection on thread (6275, 6135099392), using default compute resource for model '`hive_metastore`.`snapshots`.`address_snapshot`'
[0m09:18:20.383869 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.address_snapshot
[0m09:18:20.390916 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.address_snapshot
[0m09:18:20.446249 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.medallion_dbt_spark.address_snapshot"
[0m09:18:20.447224 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.07068896293640137s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:20.447475 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.07095909118652344s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Retrieving connection
[0m09:18:20.447650 [debug] [Thread-1 (]: Using databricks connection "snapshot.medallion_dbt_spark.address_snapshot"
[0m09:18:20.447916 [debug] [Thread-1 (]: On snapshot.medallion_dbt_spark.address_snapshot: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "snapshot.medallion_dbt_spark.address_snapshot"} */

          
  
    
        create or replace table `hive_metastore`.`snapshots`.`address_snapshot`
      
      using delta
      
      
      
      
      
    location '/mnt/silver/address/address_snapshot'
      
      
      as
      

    select *,
        md5(coalesce(cast(AddressID as string ), '')
         || '|' || coalesce(cast(
    current_timestamp()
 as string ), '')
        ) as dbt_scd_id,
        
    current_timestamp()
 as dbt_updated_at,
        
    current_timestamp()
 as dbt_valid_from,
        nullif(
    current_timestamp()
, 
    current_timestamp()
) as dbt_valid_to
    from (
        



with source_data as (
    select
        AddressID,
        AddressLine1,
        AddressLine2,
        City,
        StateProvince,
        CountryRegion,
        PostalCode
    from `hive_metastore`.`saleslt`.`address`
)
select *
from source_data

    ) sbq



  
      
[0m09:18:20.448179 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=Unknown) - Created cursor
[0m09:18:38.213116 [debug] [Thread-1 (]: SQL status: OK in 17.760 seconds
[0m09:18:38.215800 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=534185e9-369b-4182-b0de-750444de77f4) - Closing cursor
[0m09:18:38.289631 [debug] [Thread-1 (]: Spark adapter: NotImplemented: commit
[0m09:18:38.290932 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:18:38.291335 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:18:38.292350 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06e1a7be-e2c9-4e47-be40-d96d87060b77', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13f157810>]}
[0m09:18:38.292994 [info ] [Thread-1 (]: 1 of 7 OK snapshotted snapshots.address_snapshot ............................... [[32mOK[0m in 17.91s]
[0m09:18:38.293480 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.address_snapshot
[0m09:18:38.293731 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.customer_snapshot
[0m09:18:38.294061 [info ] [Thread-1 (]: 2 of 7 START snapshot snapshots.customer_snapshot .............................. [RUN]
[0m09:18:38.294449 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.003136157989501953s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:38.294649 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.address_snapshot, now snapshot.medallion_dbt_spark.customer_snapshot)
[0m09:18:38.294870 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.003566265106201172s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.address_snapshot
[0m09:18:38.295097 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.0037953853607177734s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Acquired connection on thread (6275, 6135099392), using default compute resource for model '`hive_metastore`.`snapshots`.`customer_snapshot`'
[0m09:18:38.295390 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.customer_snapshot
[0m09:18:38.297947 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.customer_snapshot
[0m09:18:38.300904 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.medallion_dbt_spark.customer_snapshot"
[0m09:18:38.301614 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.010300159454345703s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:38.301854 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.010557174682617188s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Retrieving connection
[0m09:18:38.302028 [debug] [Thread-1 (]: Using databricks connection "snapshot.medallion_dbt_spark.customer_snapshot"
[0m09:18:38.302290 [debug] [Thread-1 (]: On snapshot.medallion_dbt_spark.customer_snapshot: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "snapshot.medallion_dbt_spark.customer_snapshot"} */

          
  
    
        create or replace table `hive_metastore`.`snapshots`.`customer_snapshot`
      
      using delta
      
      
      
      
      
    location '/mnt/silver/customer/customer_snapshot'
      
      
      as
      

    select *,
        md5(coalesce(cast(CustomerId as string ), '')
         || '|' || coalesce(cast(
    current_timestamp()
 as string ), '')
        ) as dbt_scd_id,
        
    current_timestamp()
 as dbt_updated_at,
        
    current_timestamp()
 as dbt_valid_from,
        nullif(
    current_timestamp()
, 
    current_timestamp()
) as dbt_valid_to
    from (
        



with source_data as (
    select
        CustomerId,
        NameStyle,
        Title,
        FirstName,
        MiddleName,
        LastName,
        Suffix,
        CompanyName,
        SalesPerson,
        EmailAddress,
        Phone,
        PasswordHash,
        PasswordSalt
    from `hive_metastore`.`saleslt`.`customer`
)
select *
from source_data

    ) sbq



  
      
[0m09:18:38.302538 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=Unknown) - Created cursor
[0m09:18:42.485786 [debug] [Thread-1 (]: SQL status: OK in 4.180 seconds
[0m09:18:42.487803 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=fda973e2-1b83-4fe7-8da3-208b36a7ea94) - Closing cursor
[0m09:18:42.488914 [debug] [Thread-1 (]: Spark adapter: NotImplemented: commit
[0m09:18:42.489503 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:18:42.489816 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:18:42.490073 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06e1a7be-e2c9-4e47-be40-d96d87060b77', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13f14c210>]}
[0m09:18:42.490564 [info ] [Thread-1 (]: 2 of 7 OK snapshotted snapshots.customer_snapshot .............................. [[32mOK[0m in 4.20s]
[0m09:18:42.490962 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.customer_snapshot
[0m09:18:42.491353 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m09:18:42.491927 [info ] [Thread-1 (]: 3 of 7 START snapshot snapshots.customeraddress_snapshot ....................... [RUN]
[0m09:18:42.492527 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.002646923065185547s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:42.492852 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.customer_snapshot, now snapshot.medallion_dbt_spark.customeraddress_snapshot)
[0m09:18:42.493217 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.0033469200134277344s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.customer_snapshot
[0m09:18:42.493458 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.0036427974700927734s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Acquired connection on thread (6275, 6135099392), using default compute resource for model '`hive_metastore`.`snapshots`.`customeraddress_snapshot`'
[0m09:18:42.493650 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m09:18:42.496729 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m09:18:42.501148 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.medallion_dbt_spark.customeraddress_snapshot"
[0m09:18:42.501834 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.011995792388916016s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:42.502098 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.012276887893676758s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Retrieving connection
[0m09:18:42.502268 [debug] [Thread-1 (]: Using databricks connection "snapshot.medallion_dbt_spark.customeraddress_snapshot"
[0m09:18:42.502521 [debug] [Thread-1 (]: On snapshot.medallion_dbt_spark.customeraddress_snapshot: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "snapshot.medallion_dbt_spark.customeraddress_snapshot"} */

          
  
    
        create or replace table `hive_metastore`.`snapshots`.`customeraddress_snapshot`
      
      using delta
      
      
      
      
      
    location '/mnt/silver/customeraddress/customeraddress_snapshot'
      
      
      as
      

    select *,
        md5(coalesce(cast(CustomerId||'-'||AddressId as string ), '')
         || '|' || coalesce(cast(
    current_timestamp()
 as string ), '')
        ) as dbt_scd_id,
        
    current_timestamp()
 as dbt_updated_at,
        
    current_timestamp()
 as dbt_valid_from,
        nullif(
    current_timestamp()
, 
    current_timestamp()
) as dbt_valid_to
    from (
        



with source_data as (
    select
        CustomerId,
        AddressId,
        AddressType
    from `hive_metastore`.`saleslt`.`customeraddress`
)
select *
from source_data

    ) sbq



  
      
[0m09:18:42.502860 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=Unknown) - Created cursor
[0m09:18:46.177809 [debug] [Thread-1 (]: SQL status: OK in 3.670 seconds
[0m09:18:46.179556 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=c8bd57ee-40ff-4b69-9f45-8246e9694d68) - Closing cursor
[0m09:18:46.180565 [debug] [Thread-1 (]: Spark adapter: NotImplemented: commit
[0m09:18:46.181131 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:18:46.181432 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=7.152557373046875e-07s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:18:46.181702 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06e1a7be-e2c9-4e47-be40-d96d87060b77', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13f1f0bd0>]}
[0m09:18:46.182202 [info ] [Thread-1 (]: 3 of 7 OK snapshotted snapshots.customeraddress_snapshot ....................... [[32mOK[0m in 3.69s]
[0m09:18:46.182603 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m09:18:46.182990 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.product_snapshot
[0m09:18:46.183554 [info ] [Thread-1 (]: 4 of 7 START snapshot snapshots.product_snapshot ............................... [RUN]
[0m09:18:46.184177 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.0026726722717285156s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:46.184526 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.customeraddress_snapshot, now snapshot.medallion_dbt_spark.product_snapshot)
[0m09:18:46.184894 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.0034036636352539062s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m09:18:46.185255 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.0037708282470703125s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Acquired connection on thread (6275, 6135099392), using default compute resource for model '`hive_metastore`.`snapshots`.`product_snapshot`'
[0m09:18:46.185450 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.product_snapshot
[0m09:18:46.188982 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.product_snapshot
[0m09:18:46.192324 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.medallion_dbt_spark.product_snapshot"
[0m09:18:46.192954 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.011497974395751953s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:46.193193 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.011760711669921875s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Retrieving connection
[0m09:18:46.193486 [debug] [Thread-1 (]: Using databricks connection "snapshot.medallion_dbt_spark.product_snapshot"
[0m09:18:46.193898 [debug] [Thread-1 (]: On snapshot.medallion_dbt_spark.product_snapshot: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "snapshot.medallion_dbt_spark.product_snapshot"} */

          
  
    
        create or replace table `hive_metastore`.`snapshots`.`product_snapshot`
      
      using delta
      
      
      
      
      
    location '/mnt/silver/product/product_snapshot'
      
      
      as
      

    select *,
        md5(coalesce(cast(ProductID as string ), '')
         || '|' || coalesce(cast(
    current_timestamp()
 as string ), '')
        ) as dbt_scd_id,
        
    current_timestamp()
 as dbt_updated_at,
        
    current_timestamp()
 as dbt_valid_from,
        nullif(
    current_timestamp()
, 
    current_timestamp()
) as dbt_valid_to
    from (
        



with product_snapshot as (
    SELECT
        ProductID,
        Name,
        ProductNumber,
        Color,
        StandardCost,
        ListPrice,
        Size,
        Weight,
        ProductCategoryID,
        ProductModelID,
        SellStartDate,
        SellEndDate,
        DiscontinuedDate,
        ThumbNailPhoto,
        ThumbnailPhotoFileName
    FROM `hive_metastore`.`saleslt`.`product`
)

select * from product_snapshot

    ) sbq



  
      
[0m09:18:46.194199 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=Unknown) - Created cursor
[0m09:18:50.163338 [debug] [Thread-1 (]: SQL status: OK in 3.970 seconds
[0m09:18:50.165050 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=9f32c176-3452-46e5-9080-b7cc10dcaa32) - Closing cursor
[0m09:18:50.166589 [debug] [Thread-1 (]: Spark adapter: NotImplemented: commit
[0m09:18:50.167517 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=3.814697265625e-06s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:18:50.168026 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:18:50.168465 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06e1a7be-e2c9-4e47-be40-d96d87060b77', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13f17e7d0>]}
[0m09:18:50.169358 [info ] [Thread-1 (]: 4 of 7 OK snapshotted snapshots.product_snapshot ............................... [[32mOK[0m in 3.98s]
[0m09:18:50.169830 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.product_snapshot
[0m09:18:50.170114 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.productmodel_snapshot
[0m09:18:50.170489 [info ] [Thread-1 (]: 5 of 7 START snapshot snapshots.productmodel_snapshot .......................... [RUN]
[0m09:18:50.170871 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.0028810501098632812s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:50.171074 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.product_snapshot, now snapshot.medallion_dbt_spark.productmodel_snapshot)
[0m09:18:50.171311 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.00333404541015625s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.product_snapshot
[0m09:18:50.171532 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.0035560131072998047s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Acquired connection on thread (6275, 6135099392), using default compute resource for model '`hive_metastore`.`snapshots`.`productmodel_snapshot`'
[0m09:18:50.171730 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.productmodel_snapshot
[0m09:18:50.174304 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.productmodel_snapshot
[0m09:18:50.177810 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.medallion_dbt_spark.productmodel_snapshot"
[0m09:18:50.178431 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.010390043258666992s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:50.178784 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.01080012321472168s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Retrieving connection
[0m09:18:50.178953 [debug] [Thread-1 (]: Using databricks connection "snapshot.medallion_dbt_spark.productmodel_snapshot"
[0m09:18:50.179236 [debug] [Thread-1 (]: On snapshot.medallion_dbt_spark.productmodel_snapshot: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "snapshot.medallion_dbt_spark.productmodel_snapshot"} */

          
  
    
        create or replace table `hive_metastore`.`snapshots`.`productmodel_snapshot`
      
      using delta
      
      
      
      
      
    location '/mnt/silver/productmodel/productmodel_snapshot'
      
      
      as
      

    select *,
        md5(coalesce(cast(ProductModelID as string ), '')
         || '|' || coalesce(cast(
    current_timestamp()
 as string ), '')
        ) as dbt_scd_id,
        
    current_timestamp()
 as dbt_updated_at,
        
    current_timestamp()
 as dbt_valid_from,
        nullif(
    current_timestamp()
, 
    current_timestamp()
) as dbt_valid_to
    from (
        



with product_snapshot as (
    SELECT
        ProductModelID,
        Name,
        CatalogDescription
    FROM `hive_metastore`.`saleslt`.`productmodel`
)

select * from product_snapshot

    ) sbq



  
      
[0m09:18:50.179474 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=Unknown) - Created cursor
[0m09:18:53.749396 [debug] [Thread-1 (]: SQL status: OK in 3.570 seconds
[0m09:18:53.751556 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=7d4dc9fc-cebc-4e52-80fa-c769298bf8b3) - Closing cursor
[0m09:18:53.753320 [debug] [Thread-1 (]: Spark adapter: NotImplemented: commit
[0m09:18:53.754450 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=5.9604644775390625e-06s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:18:53.754973 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=5.0067901611328125e-06s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:18:53.755287 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06e1a7be-e2c9-4e47-be40-d96d87060b77', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13f1ae890>]}
[0m09:18:53.755863 [info ] [Thread-1 (]: 5 of 7 OK snapshotted snapshots.productmodel_snapshot .......................... [[32mOK[0m in 3.58s]
[0m09:18:53.756491 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.productmodel_snapshot
[0m09:18:53.756966 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m09:18:53.757639 [info ] [Thread-1 (]: 6 of 7 START snapshot snapshots.salesorderdetail_snapshot ...................... [RUN]
[0m09:18:53.758146 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.0031709671020507812s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:53.758355 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.productmodel_snapshot, now snapshot.medallion_dbt_spark.salesorderdetail_snapshot)
[0m09:18:53.758584 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.0036139488220214844s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.productmodel_snapshot
[0m09:18:53.758819 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.003847837448120117s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Acquired connection on thread (6275, 6135099392), using default compute resource for model '`hive_metastore`.`snapshots`.`salesorderdetail_snapshot`'
[0m09:18:53.759023 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m09:18:53.762230 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m09:18:53.766093 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.medallion_dbt_spark.salesorderdetail_snapshot"
[0m09:18:53.766808 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.01182699203491211s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:53.767046 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.012078046798706055s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Retrieving connection
[0m09:18:53.767223 [debug] [Thread-1 (]: Using databricks connection "snapshot.medallion_dbt_spark.salesorderdetail_snapshot"
[0m09:18:53.767559 [debug] [Thread-1 (]: On snapshot.medallion_dbt_spark.salesorderdetail_snapshot: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "snapshot.medallion_dbt_spark.salesorderdetail_snapshot"} */

          
  
    
        create or replace table `hive_metastore`.`snapshots`.`salesorderdetail_snapshot`
      
      using delta
      
      
      
      
      
    location '/mnt/silver/salesorderdetail/salesorderdetail_snapshot'
      
      
      as
      

    select *,
        md5(coalesce(cast(SalesOrderDetailID as string ), '')
         || '|' || coalesce(cast(
    current_timestamp()
 as string ), '')
        ) as dbt_scd_id,
        
    current_timestamp()
 as dbt_updated_at,
        
    current_timestamp()
 as dbt_valid_from,
        nullif(
    current_timestamp()
, 
    current_timestamp()
) as dbt_valid_to
    from (
        



with salesorderdetail_snapshot as (
    SELECT
        SalesOrderID,
        SalesOrderDetailID,
        OrderQty,
        ProductID,
        UnitPrice,
        UnitPriceDiscount,
        LineTotal
    FROM `hive_metastore`.`saleslt`.`salesorderdetail`
)

select * from salesorderdetail_snapshot

    ) sbq



  
      
[0m09:18:53.767897 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=Unknown) - Created cursor
[0m09:18:57.844183 [debug] [Thread-1 (]: SQL status: OK in 4.080 seconds
[0m09:18:57.845882 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=b73b4a52-9d03-4010-87bd-695d388226cc) - Closing cursor
[0m09:18:57.847450 [debug] [Thread-1 (]: Spark adapter: NotImplemented: commit
[0m09:18:57.848310 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=5.0067901611328125e-06s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:18:57.848852 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=7.152557373046875e-07s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:18:57.849335 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06e1a7be-e2c9-4e47-be40-d96d87060b77', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13f0c8610>]}
[0m09:18:57.850466 [info ] [Thread-1 (]: 6 of 7 OK snapshotted snapshots.salesorderdetail_snapshot ...................... [[32mOK[0m in 4.09s]
[0m09:18:57.851122 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m09:18:57.851463 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.salesorderheader_snapshot
[0m09:18:57.852045 [info ] [Thread-1 (]: 7 of 7 START snapshot snapshots.salesorderheader_snapshot ...................... [RUN]
[0m09:18:57.852872 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.003949880599975586s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:57.853282 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.salesorderdetail_snapshot, now snapshot.medallion_dbt_spark.salesorderheader_snapshot)
[0m09:18:57.853519 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=0.004709005355834961s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m09:18:57.853745 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=0.004936933517456055s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Acquired connection on thread (6275, 6135099392), using default compute resource for model '`hive_metastore`.`snapshots`.`salesorderheader_snapshot`'
[0m09:18:57.853956 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.salesorderheader_snapshot
[0m09:18:57.856950 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.salesorderheader_snapshot
[0m09:18:57.861918 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.medallion_dbt_spark.salesorderheader_snapshot"
[0m09:18:57.862577 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=0.013746976852416992s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Checking idleness
[0m09:18:57.862825 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=0.014019966125488281s, acquire-count=1, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Retrieving connection
[0m09:18:57.862986 [debug] [Thread-1 (]: Using databricks connection "snapshot.medallion_dbt_spark.salesorderheader_snapshot"
[0m09:18:57.863266 [debug] [Thread-1 (]: On snapshot.medallion_dbt_spark.salesorderheader_snapshot: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "snapshot.medallion_dbt_spark.salesorderheader_snapshot"} */

          
  
    
        create or replace table `hive_metastore`.`snapshots`.`salesorderheader_snapshot`
      
      using delta
      
      
      
      
      
    location '/mnt/silver/salesorderheader/salesorderheader_snapshot'
      
      
      as
      

    select *,
        md5(coalesce(cast(SalesOrderID as string ), '')
         || '|' || coalesce(cast(
    current_timestamp()
 as string ), '')
        ) as dbt_scd_id,
        
    current_timestamp()
 as dbt_updated_at,
        
    current_timestamp()
 as dbt_valid_from,
        nullif(
    current_timestamp()
, 
    current_timestamp()
) as dbt_valid_to
    from (
        



with salesorderheader_snapshot as (
    SELECT
        SalesOrderID,
        RevisionNumber,
        OrderDate,
        DueDate,
        ShipDate,
        Status,
        OnlineOrderFlag,
        SalesOrderNumber,
        PurchaseOrderNumber,
        AccountNumber,
        CustomerID,
        ShipToAddressID,
        BillToAddressID,
        ShipMethod,
        CreditCardApprovalCode,
        SubTotal,
        TaxAmt,
        Freight,
        TotalDue,
        Comment
    FROM `hive_metastore`.`saleslt`.`salesorderheader`
)

select * from salesorderheader_snapshot

    ) sbq



  
      
[0m09:18:57.863560 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=Unknown) - Created cursor
[0m09:19:01.480786 [debug] [Thread-1 (]: SQL status: OK in 3.620 seconds
[0m09:19:01.482837 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, command-id=c67f4521-523e-4dec-a26d-099f614a8358) - Closing cursor
[0m09:19:01.484559 [debug] [Thread-1 (]: Spark adapter: NotImplemented: commit
[0m09:19:01.485566 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=5.245208740234375e-06s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:19:01.486354 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5352742608, session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(6275, 6135099392), compute-name=) - Released connection
[0m09:19:01.487222 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '06e1a7be-e2c9-4e47-be40-d96d87060b77', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13f445d90>]}
[0m09:19:01.487900 [info ] [Thread-1 (]: 7 of 7 OK snapshotted snapshots.salesorderheader_snapshot ...................... [[32mOK[0m in 3.63s]
[0m09:19:01.488502 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.salesorderheader_snapshot
[0m09:19:01.490048 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5352284624, session-id=None, name=master, idle-time=41.110419034957886s, acquire-count=0, language=None, thread-identifier=(6275, 8194199360), compute-name=) - Checking idleness
[0m09:19:01.490297 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5352284624, session-id=None, name=master, idle-time=41.110743045806885s, acquire-count=0, language=None, thread-identifier=(6275, 8194199360), compute-name=) - Reusing connection previously named master
[0m09:19:01.490486 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5352284624, session-id=None, name=master, idle-time=41.1109402179718s, acquire-count=1, language=None, thread-identifier=(6275, 8194199360), compute-name=) - Acquired connection on thread (6275, 8194199360), using default compute resource
[0m09:19:01.490676 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5352284624, session-id=None, name=master, idle-time=41.11113715171814s, acquire-count=1, language=None, thread-identifier=(6275, 8194199360), compute-name=) - Checking idleness
[0m09:19:01.490856 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5352284624, session-id=None, name=master, idle-time=41.111316204071045s, acquire-count=1, language=None, thread-identifier=(6275, 8194199360), compute-name=) - Retrieving connection
[0m09:19:01.491010 [debug] [MainThread]: On master: ROLLBACK
[0m09:19:01.491158 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:19:01.789516 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5352284624, session-id=a6d67b00-3cb5-4712-9e32-dec6c31dde3c, name=master, idle-time=6.9141387939453125e-06s, acquire-count=1, language=None, thread-identifier=(6275, 8194199360), compute-name=) - Connection created
[0m09:19:01.790538 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:19:01.790977 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5352284624, session-id=a6d67b00-3cb5-4712-9e32-dec6c31dde3c, name=master, idle-time=0.0018088817596435547s, acquire-count=1, language=None, thread-identifier=(6275, 8194199360), compute-name=) - Checking idleness
[0m09:19:01.791314 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5352284624, session-id=a6d67b00-3cb5-4712-9e32-dec6c31dde3c, name=master, idle-time=0.002156972885131836s, acquire-count=1, language=None, thread-identifier=(6275, 8194199360), compute-name=) - Retrieving connection
[0m09:19:01.791609 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m09:19:01.791880 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m09:19:01.792217 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5352284624, session-id=a6d67b00-3cb5-4712-9e32-dec6c31dde3c, name=master, idle-time=1.1920928955078125e-06s, acquire-count=0, language=None, thread-identifier=(6275, 8194199360), compute-name=) - Released connection
[0m09:19:01.792826 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:19:01.793143 [debug] [MainThread]: On master: ROLLBACK
[0m09:19:01.793420 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:19:01.793686 [debug] [MainThread]: On master: Close
[0m09:19:01.794138 [debug] [MainThread]: Databricks adapter: Connection(session-id=a6d67b00-3cb5-4712-9e32-dec6c31dde3c) - Closing connection
[0m09:19:01.857524 [debug] [MainThread]: Connection 'snapshot.medallion_dbt_spark.salesorderheader_snapshot' was properly closed.
[0m09:19:01.858306 [debug] [MainThread]: On snapshot.medallion_dbt_spark.salesorderheader_snapshot: ROLLBACK
[0m09:19:01.858808 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:19:01.859119 [debug] [MainThread]: On snapshot.medallion_dbt_spark.salesorderheader_snapshot: Close
[0m09:19:01.859456 [debug] [MainThread]: Databricks adapter: Connection(session-id=6598a5ed-e42c-4250-92d1-ad323aa8c46c) - Closing connection
[0m09:19:01.984601 [info ] [MainThread]: 
[0m09:19:01.985439 [info ] [MainThread]: Finished running 7 snapshots in 0 hours 0 minutes and 49.37 seconds (49.37s).
[0m09:19:01.986760 [debug] [MainThread]: Command end result
[0m09:19:02.014012 [info ] [MainThread]: 
[0m09:19:02.014356 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:19:02.014556 [info ] [MainThread]: 
[0m09:19:02.014752 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m09:19:02.018232 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_success": true, "command_wall_clock_time": 52.0289, "process_user_time": 3.564114, "process_kernel_time": 2.258113, "process_mem_max_rss": "227016704", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:19:02.018555 [debug] [MainThread]: Command `dbt snapshot` succeeded at 09:19:02.018507 after 52.03 seconds
[0m09:19:02.018776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10953fe10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10556d290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10556d150>]}
[0m09:19:02.018977 [debug] [MainThread]: Flushing usage events
[0m09:44:35.361452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e33190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e936d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e93c90>]}


============================== 09:44:35.366136 | b3ea7c1f-5015-46c4-9ade-479b391989ae ==============================
[0m09:44:35.366136 [info ] [MainThread]: Running with dbt=1.8.5
[0m09:44:35.366598 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/vaishnavitamilvanan/Documents/GW MS DS/Semester/Fall 2024/NLP/PycharmProjects/Medallion-Spark-Azure-DBT/medallion_dbt_spark/logs', 'version_check': 'True', 'profiles_dir': '/Users/vaishnavitamilvanan/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m09:44:35.474150 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m09:44:35.474684 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m09:44:35.474904 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m09:44:36.805054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b3ea7c1f-5015-46c4-9ade-479b391989ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e85010>]}
[0m09:44:36.833073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b3ea7c1f-5015-46c4-9ade-479b391989ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x156016090>]}
[0m09:44:36.833547 [info ] [MainThread]: Registered adapter: databricks=1.8.5
[0m09:44:36.857173 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m09:44:37.056168 [debug] [MainThread]: Partial parsing enabled: 3 files deleted, 6 files added, 0 files changed.
[0m09:44:37.056761 [debug] [MainThread]: Partial parsing: added file: medallion_dbt_spark://models/marts/sales/dim_sales.yml
[0m09:44:37.056987 [debug] [MainThread]: Partial parsing: added file: medallion_dbt_spark://models/marts/sales/dim_sales.sql
[0m09:44:37.057218 [debug] [MainThread]: Partial parsing: added file: medallion_dbt_spark://models/marts/product/dim_product.sql
[0m09:44:37.057434 [debug] [MainThread]: Partial parsing: added file: medallion_dbt_spark://models/marts/product/dim_product.yml
[0m09:44:37.057630 [debug] [MainThread]: Partial parsing: added file: medallion_dbt_spark://models/marts/customer/dim_customer.yml
[0m09:44:37.057793 [debug] [MainThread]: Partial parsing: added file: medallion_dbt_spark://models/marts/customer/dim_customer.sql
[0m09:44:37.058049 [debug] [MainThread]: Partial parsing: deleted file: medallion_dbt_spark://models/example/my_first_dbt_model.sql
[0m09:44:37.058212 [debug] [MainThread]: Partial parsing: deleted file: medallion_dbt_spark://models/example/my_second_dbt_model.sql
[0m09:44:37.187430 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m09:44:37.187824 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'b3ea7c1f-5015-46c4-9ade-479b391989ae', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1561ba2d0>]}
[0m09:44:37.263184 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'dim_products' in the 'models' section of file 'models/marts/product/dim_product.yml'
[0m09:44:37.270151 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'dim_customers' in the 'models' section of file 'models/marts/customer/dim_customer.yml'
[0m09:44:37.274778 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.unique_dim_products_product_sk.8f20ac7c5b' (models/marts/product/dim_product.yml) depends on a node named 'dim_products' in package '' which was not found
[0m09:44:37.275076 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_products_product_sk.2a2df3e1b9' (models/marts/product/dim_product.yml) depends on a node named 'dim_products' in package '' which was not found
[0m09:44:37.275356 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_products_product_name.991aec73f3' (models/marts/product/dim_product.yml) depends on a node named 'dim_products' in package '' which was not found
[0m09:44:37.275626 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_products_sellstartdate.f97a265a0f' (models/marts/product/dim_product.yml) depends on a node named 'dim_products' in package '' which was not found
[0m09:44:37.275822 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.unique_dim_customers_customer_sk.22a014df62' (models/marts/customer/dim_customer.yml) depends on a node named 'dim_customers' in package '' which was not found
[0m09:44:37.276010 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_customers_customer_sk.8ae5836863' (models/marts/customer/dim_customer.yml) depends on a node named 'dim_customers' in package '' which was not found
[0m09:44:37.276189 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_customers_customerid.209fbdda85' (models/marts/customer/dim_customer.yml) depends on a node named 'dim_customers' in package '' which was not found
[0m09:44:37.276378 [warn ] [MainThread]: [[33mWARNING[0m]: Test 'test.medallion_dbt_spark.not_null_dim_customers_AddressId.86b771f63e' (models/marts/customer/dim_customer.yml) depends on a node named 'dim_customers' in package '' which was not found
[0m09:44:37.342150 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.medallion_dbt_spark.example
[0m09:44:37.350661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b3ea7c1f-5015-46c4-9ade-479b391989ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x156606b90>]}
[0m09:44:37.447928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b3ea7c1f-5015-46c4-9ade-479b391989ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x157377f10>]}
[0m09:44:37.448410 [info ] [MainThread]: Found 7 snapshots, 3 models, 19 data tests, 9 sources, 590 macros
[0m09:44:37.448644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b3ea7c1f-5015-46c4-9ade-479b391989ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x15654d2d0>]}
[0m09:44:37.450224 [info ] [MainThread]: 
[0m09:44:37.450686 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5744026768, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(6900, 8194199360), compute-name=) - Creating connection
[0m09:44:37.450888 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m09:44:37.451085 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5744026768, session-id=None, name=master, idle-time=1.1920928955078125e-06s, acquire-count=1, language=None, thread-identifier=(6900, 8194199360), compute-name=) - Acquired connection on thread (6900, 8194199360), using default compute resource
[0m09:44:37.454913 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=None, name=list_hive_metastore_saleslt, idle-time=0s, acquire-count=0, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Creating connection
[0m09:44:37.455401 [debug] [ThreadPool]: Acquiring new databricks connection 'list_hive_metastore_saleslt'
[0m09:44:37.455666 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=None, name=list_hive_metastore_saleslt, idle-time=2.1457672119140625e-06s, acquire-count=1, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource
[0m09:44:37.455929 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=None, name=list_hive_metastore_saleslt, idle-time=0.000263214111328125s, acquire-count=1, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:37.456111 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=None, name=list_hive_metastore_saleslt, idle-time=0.0004601478576660156s, acquire-count=1, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:37.456301 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:44:37.456519 [debug] [ThreadPool]: On list_hive_metastore_saleslt: GetTables(database=hive_metastore, schema=saleslt, identifier=None)
[0m09:44:37.456688 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:44:38.173721 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_saleslt, idle-time=9.059906005859375e-06s, acquire-count=1, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Connection created
[0m09:44:38.174950 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:38.296637 [debug] [ThreadPool]: SQL status: OK in 0.840 seconds
[0m09:44:38.305970 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=de9440f8-867e-45bc-86bc-baf1c91b3d15) - Closing cursor
[0m09:44:38.312845 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_saleslt, idle-time=0.13950300216674805s, acquire-count=1, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:38.313081 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_saleslt, idle-time=0.13975811004638672s, acquire-count=1, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:38.313273 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_saleslt, idle-time=0.1399540901184082s, acquire-count=1, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:38.313444 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_saleslt, idle-time=0.14012908935546875s, acquire-count=1, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:38.313611 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m09:44:38.313761 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:44:38.313935 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */

      select current_catalog()
  
[0m09:44:38.314114 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:38.688967 [debug] [ThreadPool]: SQL status: OK in 0.370 seconds
[0m09:44:38.690617 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=0db6ff92-67f1-49ff-962b-834b875113c8) - Closing cursor
[0m09:44:38.694193 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_saleslt, idle-time=0.5208508968353271s, acquire-count=1, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:38.694425 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_saleslt, idle-time=0.5211021900177002s, acquire-count=1, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:38.694591 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:44:38.694772 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */
show views in `hive_metastore`.`saleslt`
  
[0m09:44:38.694948 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:38.869019 [debug] [ThreadPool]: SQL status: OK in 0.170 seconds
[0m09:44:38.872291 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=83b2c968-2a99-4a8e-a22c-bc4e38a19e03) - Closing cursor
[0m09:44:38.872867 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_saleslt, idle-time=7.152557373046875e-07s, acquire-count=0, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:38.873303 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_saleslt, idle-time=0.0004527568817138672s, acquire-count=0, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:38.874417 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_hive_metastore_saleslt, now list_hive_metastore_snapshots)
[0m09:44:38.874626 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_snapshots, idle-time=0.0017728805541992188s, acquire-count=0, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named list_hive_metastore_saleslt
[0m09:44:38.874833 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_snapshots, idle-time=0.001981973648071289s, acquire-count=1, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource
[0m09:44:38.875024 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_snapshots, idle-time=0.0021767616271972656s, acquire-count=1, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:38.875194 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_snapshots, idle-time=0.0023539066314697266s, acquire-count=1, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:38.875338 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:44:38.875498 [debug] [ThreadPool]: On list_hive_metastore_snapshots: GetTables(database=hive_metastore, schema=snapshots, identifier=None)
[0m09:44:38.875662 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:38.991410 [debug] [ThreadPool]: SQL status: OK in 0.120 seconds
[0m09:44:38.995233 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=bd265c4f-4a39-462e-ae9e-e3efc00563ab) - Closing cursor
[0m09:44:38.997864 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_snapshots, idle-time=0.12496376037597656s, acquire-count=1, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:38.998251 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_snapshots, idle-time=0.12537884712219238s, acquire-count=1, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:38.998528 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:44:38.998803 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */

      select current_catalog()
  
[0m09:44:38.999060 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:39.300996 [debug] [ThreadPool]: SQL status: OK in 0.300 seconds
[0m09:44:39.305735 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=a4fe0c64-2052-4c5f-b4b0-248b60a193c4) - Closing cursor
[0m09:44:39.310283 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_snapshots, idle-time=0.43741583824157715s, acquire-count=1, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:39.310545 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_snapshots, idle-time=0.43769288063049316s, acquire-count=1, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:39.310717 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:44:39.310912 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */
show views in `hive_metastore`.`snapshots`
  
[0m09:44:39.311112 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:39.713036 [debug] [ThreadPool]: SQL status: OK in 0.400 seconds
[0m09:44:39.716325 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=90d7143a-1bb0-4a02-aabd-ae27c02c98e2) - Closing cursor
[0m09:44:39.716796 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_snapshots, idle-time=3.0994415283203125e-06s, acquire-count=0, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:39.717934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b3ea7c1f-5015-46c4-9ade-479b391989ae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1566bc310>]}
[0m09:44:39.718579 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5744026768, session-id=None, name=master, idle-time=2.2674760818481445s, acquire-count=1, language=None, thread-identifier=(6900, 8194199360), compute-name=) - Checking idleness
[0m09:44:39.718907 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5744026768, session-id=None, name=master, idle-time=2.2678470611572266s, acquire-count=1, language=None, thread-identifier=(6900, 8194199360), compute-name=) - Retrieving connection
[0m09:44:39.719079 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5744026768, session-id=None, name=master, idle-time=2.2680258750915527s, acquire-count=1, language=None, thread-identifier=(6900, 8194199360), compute-name=) - Checking idleness
[0m09:44:39.719256 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5744026768, session-id=None, name=master, idle-time=2.268193006515503s, acquire-count=1, language=None, thread-identifier=(6900, 8194199360), compute-name=) - Retrieving connection
[0m09:44:39.719405 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m09:44:39.719559 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m09:44:39.719714 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5744026768, session-id=None, name=master, idle-time=2.1457672119140625e-06s, acquire-count=0, language=None, thread-identifier=(6900, 8194199360), compute-name=) - Released connection
[0m09:44:39.719964 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:44:39.720178 [info ] [MainThread]: 
[0m09:44:39.722955 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:44:39.723182 [info ] [Thread-1 (]: 1 of 19 START test not_null_dim_sales_customerID ............................... [RUN]
[0m09:44:39.723504 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=list_hive_metastore_snapshots, idle-time=0.006691932678222656s, acquire-count=0, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:39.723685 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_hive_metastore_snapshots, now test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5)
[0m09:44:39.723888 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.007075071334838867s, acquire-count=0, language=None, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named list_hive_metastore_snapshots
[0m09:44:39.724096 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.007288217544555664s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:39.724285 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:44:39.735910 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"
[0m09:44:39.736879 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:44:39.745858 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"
[0m09:44:39.746676 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.02984309196472168s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:39.746932 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.030117034912109375s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:39.747142 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"
[0m09:44:39.747396 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customerID
from `hive_metastore`.`saleslt`.`dim_sales`
where customerID is null



      
    ) dbt_internal_test
[0m09:44:39.747727 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:39.890139 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:39.891422 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customerID
from `hive_metastore`.`saleslt`.`dim_sales`
where customerID is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=7a571ff6-50d6-4d1e-a501-d6121821215a
[0m09:44:39.892116 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:39.901372 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_customerID (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:39.901832 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:39.902129 [error] [Thread-1 (]: 1 of 19 ERROR not_null_dim_sales_customerID .................................... [[31mERROR[0m in 0.18s]
[0m09:44:39.902498 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:44:39.902741 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:44:39.903024 [info ] [Thread-1 (]: 2 of 19 START test not_null_dim_sales_freight .................................. [RUN]
[0m09:44:39.903321 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.0014939308166503906s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:39.903505 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, now test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131)
[0m09:44:39.903711 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.0018880367279052734s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:44:39.903916 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.002095937728881836s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:39.904105 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:44:39.907837 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m09:44:39.908360 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:44:39.910418 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m09:44:39.910886 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.00905609130859375s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:39.911110 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.009285926818847656s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:39.911271 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m09:44:39.911488 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select freight
from `hive_metastore`.`saleslt`.`dim_sales`
where freight is null



      
    ) dbt_internal_test
[0m09:44:39.911716 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:40.013624 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:40.015354 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select freight
from `hive_metastore`.`saleslt`.`dim_sales`
where freight is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=c4e97456-bdb9-4b7d-8497-b683879aa682
[0m09:44:40.016579 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=7.3909759521484375e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:40.021015 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_freight (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:40.021590 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=4.0531158447265625e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:40.022040 [error] [Thread-1 (]: 2 of 19 ERROR not_null_dim_sales_freight ....................................... [[31mERROR[0m in 0.12s]
[0m09:44:40.022767 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:44:40.023266 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:44:40.023740 [info ] [Thread-1 (]: 3 of 19 START test not_null_dim_sales_lineTotal ................................ [RUN]
[0m09:44:40.024125 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.0025510787963867188s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:40.024315 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, now test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8)
[0m09:44:40.024568 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.0029821395874023438s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:44:40.024782 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.003228902816772461s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:40.024981 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:44:40.028655 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m09:44:40.029196 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:44:40.031452 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m09:44:40.032160 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.010474920272827148s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:40.032551 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.010982036590576172s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:40.032749 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m09:44:40.032988 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select lineTotal
from `hive_metastore`.`saleslt`.`dim_sales`
where lineTotal is null



      
    ) dbt_internal_test
[0m09:44:40.033242 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:40.142776 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:40.144802 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select lineTotal
from `hive_metastore`.`saleslt`.`dim_sales`
where lineTotal is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=89097eeb-2e29-4b00-863b-501bff0d52b9
[0m09:44:40.146244 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=7.867813110351562e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:40.149973 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_lineTotal (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:40.150406 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:40.150727 [error] [Thread-1 (]: 3 of 19 ERROR not_null_dim_sales_lineTotal ..................................... [[31mERROR[0m in 0.13s]
[0m09:44:40.151116 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:44:40.151530 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:44:40.151871 [info ] [Thread-1 (]: 4 of 19 START test not_null_dim_sales_listPrice ................................ [RUN]
[0m09:44:40.152311 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.0018889904022216797s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:40.152571 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, now test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f)
[0m09:44:40.152807 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.002408742904663086s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:44:40.153037 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.002651691436767578s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:40.153230 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:44:40.156419 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m09:44:40.157143 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:44:40.160495 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m09:44:40.160984 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.010594844818115234s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:40.161198 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.010816812515258789s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:40.161352 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m09:44:40.161579 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select listPrice
from `hive_metastore`.`saleslt`.`dim_sales`
where listPrice is null



      
    ) dbt_internal_test
[0m09:44:40.161848 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:40.294854 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:40.296447 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select listPrice
from `hive_metastore`.`saleslt`.`dim_sales`
where listPrice is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=c6ff54a0-b9f9-4926-a7e2-007b5020f354
[0m09:44:40.297606 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=6.198883056640625e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:40.300512 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_listPrice (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:40.301241 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=2.6226043701171875e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:40.301880 [error] [Thread-1 (]: 4 of 19 ERROR not_null_dim_sales_listPrice ..................................... [[31mERROR[0m in 0.15s]
[0m09:44:40.302572 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:44:40.302855 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:44:40.303077 [info ] [Thread-1 (]: 5 of 19 START test not_null_dim_sales_name ..................................... [RUN]
[0m09:44:40.303610 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.0024356842041015625s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:40.303830 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, now test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77)
[0m09:44:40.304050 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0029108524322509766s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:44:40.304309 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0031337738037109375s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:40.304614 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:44:40.308332 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m09:44:40.309106 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:44:40.311203 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m09:44:40.311627 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.010488748550415039s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:40.311862 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.010733604431152344s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:40.312019 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m09:44:40.312280 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select name
from `hive_metastore`.`saleslt`.`dim_sales`
where name is null



      
    ) dbt_internal_test
[0m09:44:40.312562 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:40.422262 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:40.423938 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select name
from `hive_metastore`.`saleslt`.`dim_sales`
where name is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=8ee66b67-62e5-48a3-80d7-3362b33ae9ab
[0m09:44:40.424729 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:40.427838 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_name (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:40.428146 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:40.428434 [error] [Thread-1 (]: 5 of 19 ERROR not_null_dim_sales_name .......................................... [[31mERROR[0m in 0.12s]
[0m09:44:40.428809 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:44:40.429067 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:44:40.429515 [info ] [Thread-1 (]: 6 of 19 START test not_null_dim_sales_orderDate ................................ [RUN]
[0m09:44:40.430126 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0019779205322265625s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:40.430358 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, now test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3)
[0m09:44:40.430593 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0024559497833251953s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:44:40.430825 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0026857852935791016s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:40.431038 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:44:40.433951 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m09:44:40.434504 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:44:40.436309 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m09:44:40.436752 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.00861501693725586s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:40.436962 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.008836030960083008s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:40.437150 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m09:44:40.437435 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orderDate
from `hive_metastore`.`saleslt`.`dim_sales`
where orderDate is null



      
    ) dbt_internal_test
[0m09:44:40.437712 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:40.835480 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:40.837224 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orderDate
from `hive_metastore`.`saleslt`.`dim_sales`
where orderDate is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=491c8a1c-97cd-4b04-8817-b0a731b4f4b4
[0m09:44:40.838376 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=5.0067901611328125e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:40.842061 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_orderDate (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:40.842680 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=2.86102294921875e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:40.842984 [error] [Thread-1 (]: 6 of 19 ERROR not_null_dim_sales_orderDate ..................................... [[31mERROR[0m in 0.41s]
[0m09:44:40.843395 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:44:40.843784 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:44:40.844252 [info ] [Thread-1 (]: 7 of 19 START test not_null_dim_sales_orderQty ................................. [RUN]
[0m09:44:40.844878 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.002171754837036133s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:40.845142 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, now test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596)
[0m09:44:40.845355 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.0027027130126953125s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:44:40.845564 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.002917766571044922s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:40.845750 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:44:40.849158 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"
[0m09:44:40.849767 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:44:40.851446 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"
[0m09:44:40.852071 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.009381771087646484s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:40.852379 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.009709835052490234s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:40.852597 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"
[0m09:44:40.852884 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orderQty
from `hive_metastore`.`saleslt`.`dim_sales`
where orderQty is null



      
    ) dbt_internal_test
[0m09:44:40.853182 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:40.964028 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:40.965558 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orderQty
from `hive_metastore`.`saleslt`.`dim_sales`
where orderQty is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=1dae291b-2f5c-41fc-8c1e-7397782fbb8f
[0m09:44:40.966808 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=8.821487426757812e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:40.969139 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_orderQty (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:40.969466 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:40.969767 [error] [Thread-1 (]: 7 of 19 ERROR not_null_dim_sales_orderQty ...................................... [[31mERROR[0m in 0.13s]
[0m09:44:40.970172 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:44:40.970677 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:44:40.971219 [info ] [Thread-1 (]: 8 of 19 START test not_null_dim_sales_productID ................................ [RUN]
[0m09:44:40.971912 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.002373218536376953s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:40.972263 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, now test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890)
[0m09:44:40.972618 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.003114938735961914s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:44:40.972906 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0034449100494384766s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:40.973101 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:44:40.977052 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m09:44:40.977640 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:44:40.979296 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m09:44:40.979761 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.010290861129760742s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:40.979981 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.010529041290283203s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:40.980136 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m09:44:40.980350 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select productID
from `hive_metastore`.`saleslt`.`dim_sales`
where productID is null



      
    ) dbt_internal_test
[0m09:44:40.980578 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:41.098821 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:41.100339 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select productID
from `hive_metastore`.`saleslt`.`dim_sales`
where productID is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=4f79b858-b40f-44e5-a089-b7b91d38e190
[0m09:44:41.101746 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=6.9141387939453125e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:41.106204 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_productID (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:41.106700 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=3.0994415283203125e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:41.107031 [error] [Thread-1 (]: 8 of 19 ERROR not_null_dim_sales_productID ..................................... [[31mERROR[0m in 0.14s]
[0m09:44:41.107409 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:44:41.107682 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:44:41.108190 [info ] [Thread-1 (]: 9 of 19 START test not_null_dim_sales_productNumber ............................ [RUN]
[0m09:44:41.108817 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.002096891403198242s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:41.109059 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, now test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd)
[0m09:44:41.109809 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.0030870437622070312s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:44:41.110114 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.0034291744232177734s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:41.110339 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:44:41.113742 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m09:44:41.114689 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:44:41.118690 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m09:44:41.120498 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.013695955276489258s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:41.120942 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.014240026473999023s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:41.121183 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m09:44:41.121465 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select productNumber
from `hive_metastore`.`saleslt`.`dim_sales`
where productNumber is null



      
    ) dbt_internal_test
[0m09:44:41.121739 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:41.240473 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:41.241746 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select productNumber
from `hive_metastore`.`saleslt`.`dim_sales`
where productNumber is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=faf12428-4408-4be1-a690-9f0ce86f65ae
[0m09:44:41.242817 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=6.198883056640625e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:41.246298 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_productNumber (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:41.247009 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:41.247351 [error] [Thread-1 (]: 9 of 19 ERROR not_null_dim_sales_productNumber ................................. [[31mERROR[0m in 0.14s]
[0m09:44:41.247781 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:44:41.248108 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:44:41.248538 [info ] [Thread-1 (]: 10 of 19 START test not_null_dim_sales_saleOrderDetailID ....................... [RUN]
[0m09:44:41.249054 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.002093791961669922s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:41.249277 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, now test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a)
[0m09:44:41.249540 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.002599000930786133s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:44:41.249766 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.0028297901153564453s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:41.249967 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:44:41.252928 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"
[0m09:44:41.253599 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:44:41.255239 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"
[0m09:44:41.255791 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.008844137191772461s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:41.256024 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.009090900421142578s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:41.256192 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"
[0m09:44:41.256417 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderDetailID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is null



      
    ) dbt_internal_test
[0m09:44:41.256644 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:41.376261 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:41.377249 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderDetailID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=63d61d43-d830-4805-8080-db6f6dacad67
[0m09:44:41.378152 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:41.380517 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:41.380867 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:41.381231 [error] [Thread-1 (]: 10 of 19 ERROR not_null_dim_sales_saleOrderDetailID ............................ [[31mERROR[0m in 0.13s]
[0m09:44:41.381702 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:44:41.382015 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:44:41.382217 [info ] [Thread-1 (]: 11 of 19 START test not_null_dim_sales_saleOrderID ............................. [RUN]
[0m09:44:41.382587 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.0017549991607666016s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:41.382771 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, now test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3)
[0m09:44:41.382975 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.0021491050720214844s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:44:41.383184 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.002357006072998047s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:41.383372 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:44:41.386509 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"
[0m09:44:41.387105 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:44:41.388950 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"
[0m09:44:41.389578 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.008725881576538086s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:41.389842 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.009006977081298828s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:41.390029 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"
[0m09:44:41.390291 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is null



      
    ) dbt_internal_test
[0m09:44:41.390548 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:41.493410 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:41.494955 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=89243b33-80aa-4f1f-b764-5c065c4884a4
[0m09:44:41.497079 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=1.0013580322265625e-05s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:41.500336 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:41.500777 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:41.501117 [error] [Thread-1 (]: 11 of 19 ERROR not_null_dim_sales_saleOrderID .................................. [[31mERROR[0m in 0.12s]
[0m09:44:41.501516 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:44:41.501773 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:44:41.502060 [info ] [Thread-1 (]: 12 of 19 START test not_null_dim_sales_sellStartDate ........................... [RUN]
[0m09:44:41.502426 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.0016710758209228516s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:41.502624 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, now test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118)
[0m09:44:41.502841 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0020890235900878906s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:44:41.503098 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0023069381713867188s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:41.503413 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:44:41.506889 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m09:44:41.507815 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:44:41.510110 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m09:44:41.510602 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.009844064712524414s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:41.510820 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.010079145431518555s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:41.511004 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m09:44:41.511297 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select sellStartDate
from `hive_metastore`.`saleslt`.`dim_sales`
where sellStartDate is null



      
    ) dbt_internal_test
[0m09:44:41.511587 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:41.611765 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:41.613465 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select sellStartDate
from `hive_metastore`.`saleslt`.`dim_sales`
where sellStartDate is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=0022c9b2-07a6-475a-add4-b814d6e1eb27
[0m09:44:41.614710 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=5.0067901611328125e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:41.618057 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_sellStartDate (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:41.618474 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=7.152557373046875e-07s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:41.618932 [error] [Thread-1 (]: 12 of 19 ERROR not_null_dim_sales_sellStartDate ................................ [[31mERROR[0m in 0.12s]
[0m09:44:41.619505 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:44:41.619891 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:44:41.620133 [info ] [Thread-1 (]: 13 of 19 START test not_null_dim_sales_standardCost ............................ [RUN]
[0m09:44:41.620460 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0020308494567871094s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:41.620721 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, now test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3)
[0m09:44:41.620975 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0025489330291748047s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:44:41.621199 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.00278472900390625s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:41.621405 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:44:41.625024 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m09:44:41.625897 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:44:41.628121 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m09:44:41.628776 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.010347604751586914s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:41.629004 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.010593652725219727s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:41.629158 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m09:44:41.629368 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select standardCost
from `hive_metastore`.`saleslt`.`dim_sales`
where standardCost is null



      
    ) dbt_internal_test
[0m09:44:41.629576 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:41.728506 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:41.730059 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select standardCost
from `hive_metastore`.`saleslt`.`dim_sales`
where standardCost is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=fe489728-f110-4fba-8829-d2240a97b556
[0m09:44:41.731651 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=6.198883056640625e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:41.735551 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_standardCost (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:41.735966 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:41.736348 [error] [Thread-1 (]: 13 of 19 ERROR not_null_dim_sales_standardCost ................................. [[31mERROR[0m in 0.12s]
[0m09:44:41.736750 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:44:41.737103 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:44:41.737507 [info ] [Thread-1 (]: 14 of 19 START test not_null_dim_sales_subTotal ................................ [RUN]
[0m09:44:41.738037 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0020418167114257812s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:41.738333 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, now test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487)
[0m09:44:41.738670 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.00267791748046875s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:44:41.739044 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.0030198097229003906s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:41.739284 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:44:41.742861 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m09:44:41.743414 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:44:41.747097 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m09:44:41.747897 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.011921882629394531s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:41.748216 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.012248754501342773s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:41.748482 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m09:44:41.748727 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select subTotal
from `hive_metastore`.`saleslt`.`dim_sales`
where subTotal is null



      
    ) dbt_internal_test
[0m09:44:41.749026 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:41.860663 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:41.862276 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select subTotal
from `hive_metastore`.`saleslt`.`dim_sales`
where subTotal is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=68cd56e1-f13b-46ee-82c7-2fbd8665cf8f
[0m09:44:41.863998 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=1.0967254638671875e-05s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:41.867832 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_subTotal (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:41.868210 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:41.868498 [error] [Thread-1 (]: 14 of 19 ERROR not_null_dim_sales_subTotal ..................................... [[31mERROR[0m in 0.13s]
[0m09:44:41.869051 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:44:41.869506 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:44:41.869931 [info ] [Thread-1 (]: 15 of 19 START test not_null_dim_sales_taxAmt .................................. [RUN]
[0m09:44:41.870322 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.002109050750732422s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:41.870527 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, now test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a)
[0m09:44:41.870743 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.0025451183319091797s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:44:41.870956 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.0027608871459960938s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:41.871151 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:44:41.874175 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m09:44:41.874703 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:44:41.876626 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m09:44:41.877096 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.008893966674804688s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:41.877308 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.009117841720581055s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:41.877457 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m09:44:41.877666 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select taxAmt
from `hive_metastore`.`saleslt`.`dim_sales`
where taxAmt is null



      
    ) dbt_internal_test
[0m09:44:41.877869 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:41.962398 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:41.964080 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select taxAmt
from `hive_metastore`.`saleslt`.`dim_sales`
where taxAmt is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=181d3a68-826d-4612-a9e2-e13f9a003b93
[0m09:44:41.965762 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=5.7220458984375e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:41.968900 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_taxAmt (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:41.969284 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=7.152557373046875e-07s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:41.969618 [error] [Thread-1 (]: 15 of 19 ERROR not_null_dim_sales_taxAmt ....................................... [[31mERROR[0m in 0.10s]
[0m09:44:41.970258 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:44:41.970703 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:44:41.971208 [info ] [Thread-1 (]: 16 of 19 START test not_null_dim_sales_totalDue ................................ [RUN]
[0m09:44:41.971523 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.002261638641357422s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:41.971696 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, now test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023)
[0m09:44:41.971901 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.0026397705078125s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:44:41.972106 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.0028486251831054688s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:41.972290 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:44:41.975388 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m09:44:41.975926 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:44:41.977738 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m09:44:41.978412 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.009107828140258789s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:41.978725 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.009446859359741211s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:41.978946 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m09:44:41.979246 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select totalDue
from `hive_metastore`.`saleslt`.`dim_sales`
where totalDue is null



      
    ) dbt_internal_test
[0m09:44:41.979528 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:42.067660 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:42.069457 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select totalDue
from `hive_metastore`.`saleslt`.`dim_sales`
where totalDue is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=d96372c7-1108-480e-b005-c5387dd2f553
[0m09:44:42.070680 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=5.7220458984375e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:42.074466 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_totalDue (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.074885 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:42.075176 [error] [Thread-1 (]: 16 of 19 ERROR not_null_dim_sales_totalDue ..................................... [[31mERROR[0m in 0.10s]
[0m09:44:42.075537 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:44:42.075796 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:44:42.076334 [info ] [Thread-1 (]: 17 of 19 START test not_null_dim_sales_unitPrice ............................... [RUN]
[0m09:44:42.077033 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.002084970474243164s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:42.077407 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, now test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a)
[0m09:44:42.077799 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.0028908252716064453s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:44:42.078149 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.003242969512939453s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:42.078454 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:44:42.082370 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m09:44:42.082894 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:44:42.084775 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m09:44:42.085199 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.010322093963623047s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:42.085420 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.010564088821411133s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:42.085572 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m09:44:42.085778 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select unitPrice
from `hive_metastore`.`saleslt`.`dim_sales`
where unitPrice is null



      
    ) dbt_internal_test
[0m09:44:42.085983 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:42.182190 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:42.183938 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select unitPrice
from `hive_metastore`.`saleslt`.`dim_sales`
where unitPrice is null



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=703e07e1-484e-4fd6-8950-244c7ba8e354
[0m09:44:42.185251 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=7.152557373046875e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:42.189231 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_unitPrice (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.189717 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:42.190013 [error] [Thread-1 (]: 17 of 19 ERROR not_null_dim_sales_unitPrice .................................... [[31mERROR[0m in 0.11s]
[0m09:44:42.190396 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:44:42.190663 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:44:42.190970 [info ] [Thread-1 (]: 18 of 19 START test unique_dim_sales_saleOrderDetailID ......................... [RUN]
[0m09:44:42.191410 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.0017170906066894531s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:42.191625 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, now test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405)
[0m09:44:42.191944 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.002254009246826172s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:44:42.192167 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.0024728775024414062s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:42.192359 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:44:42.197791 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"
[0m09:44:42.198201 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:44:42.199758 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"
[0m09:44:42.200289 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.010571002960205078s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:42.200545 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.010869026184082031s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:42.200694 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"
[0m09:44:42.200947 [debug] [Thread-1 (]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderDetailID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is not null
group by saleOrderDetailID
having count(*) > 1



      
    ) dbt_internal_test
[0m09:44:42.201266 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:42.320963 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:42.322434 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderDetailID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is not null
group by saleOrderDetailID
having count(*) > 1



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 15 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 15 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 15 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=f4afbd14-4aaa-4792-b640-3d4b0f02033d
[0m09:44:42.323463 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=5.7220458984375e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:42.327589 [debug] [Thread-1 (]: Runtime Error in test unique_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 15 pos 5
[0m09:44:42.328324 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:42.328658 [error] [Thread-1 (]: 18 of 19 ERROR unique_dim_sales_saleOrderDetailID .............................. [[31mERROR[0m in 0.14s]
[0m09:44:42.329060 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:44:42.329312 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:44:42.329586 [info ] [Thread-1 (]: 19 of 19 START test unique_dim_sales_saleOrderID ............................... [RUN]
[0m09:44:42.330091 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.001764059066772461s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:42.330431 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, now test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c)
[0m09:44:42.330781 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.0024611949920654297s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:44:42.331148 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.0028519630432128906s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Acquired connection on thread (6900, 6142095360), using default compute resource for model 'None'
[0m09:44:42.331353 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:44:42.334603 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"
[0m09:44:42.335236 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:44:42.338904 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"
[0m09:44:42.339512 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.011204004287719727s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Checking idleness
[0m09:44:42.339805 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.011527061462402344s, acquire-count=1, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Retrieving connection
[0m09:44:42.339959 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"
[0m09:44:42.340174 [debug] [Thread-1 (]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is not null
group by saleOrderID
having count(*) > 1



      
    ) dbt_internal_test
[0m09:44:42.340387 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Created cursor
[0m09:44:42.461120 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, command-id=Unknown) - Closing cursor
[0m09:44:42.462527 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is not null
group by saleOrderID
having count(*) > 1



      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 15 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 15 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 15 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=0d189cc7-b041-4197-a612-9b39b0057ea2
[0m09:44:42.463876 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=5.9604644775390625e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:42.467935 [debug] [Thread-1 (]: Runtime Error in test unique_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 15 pos 5
[0m09:44:42.468363 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5758198096, session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(6900, 6142095360), compute-name=) - Released connection
[0m09:44:42.468702 [error] [Thread-1 (]: 19 of 19 ERROR unique_dim_sales_saleOrderID .................................... [[31mERROR[0m in 0.14s]
[0m09:44:42.469070 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:44:42.470088 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5744026768, session-id=None, name=master, idle-time=2.750352144241333s, acquire-count=0, language=None, thread-identifier=(6900, 8194199360), compute-name=) - Checking idleness
[0m09:44:42.470435 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5744026768, session-id=None, name=master, idle-time=2.750694990158081s, acquire-count=0, language=None, thread-identifier=(6900, 8194199360), compute-name=) - Reusing connection previously named master
[0m09:44:42.470638 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5744026768, session-id=None, name=master, idle-time=2.7509162425994873s, acquire-count=1, language=None, thread-identifier=(6900, 8194199360), compute-name=) - Acquired connection on thread (6900, 8194199360), using default compute resource
[0m09:44:42.470844 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5744026768, session-id=None, name=master, idle-time=2.7511281967163086s, acquire-count=1, language=None, thread-identifier=(6900, 8194199360), compute-name=) - Checking idleness
[0m09:44:42.471010 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5744026768, session-id=None, name=master, idle-time=2.751296043395996s, acquire-count=1, language=None, thread-identifier=(6900, 8194199360), compute-name=) - Retrieving connection
[0m09:44:42.471168 [debug] [MainThread]: On master: ROLLBACK
[0m09:44:42.471341 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:44:42.674092 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5744026768, session-id=23cd9ca2-d2c6-42f4-8efb-662a47908409, name=master, idle-time=1.6689300537109375e-06s, acquire-count=1, language=None, thread-identifier=(6900, 8194199360), compute-name=) - Connection created
[0m09:44:42.674408 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:44:42.674621 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5744026768, session-id=23cd9ca2-d2c6-42f4-8efb-662a47908409, name=master, idle-time=0.0005838871002197266s, acquire-count=1, language=None, thread-identifier=(6900, 8194199360), compute-name=) - Checking idleness
[0m09:44:42.674812 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5744026768, session-id=23cd9ca2-d2c6-42f4-8efb-662a47908409, name=master, idle-time=0.0007789134979248047s, acquire-count=1, language=None, thread-identifier=(6900, 8194199360), compute-name=) - Retrieving connection
[0m09:44:42.674975 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m09:44:42.675126 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m09:44:42.675405 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5744026768, session-id=23cd9ca2-d2c6-42f4-8efb-662a47908409, name=master, idle-time=7.152557373046875e-07s, acquire-count=0, language=None, thread-identifier=(6900, 8194199360), compute-name=) - Released connection
[0m09:44:42.675849 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:44:42.676156 [debug] [MainThread]: On master: ROLLBACK
[0m09:44:42.676448 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:44:42.676634 [debug] [MainThread]: On master: Close
[0m09:44:42.676797 [debug] [MainThread]: Databricks adapter: Connection(session-id=23cd9ca2-d2c6-42f4-8efb-662a47908409) - Closing connection
[0m09:44:42.760718 [debug] [MainThread]: Connection 'test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c' was properly closed.
[0m09:44:42.761621 [debug] [MainThread]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c: ROLLBACK
[0m09:44:42.762114 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:44:42.762514 [debug] [MainThread]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c: Close
[0m09:44:42.762960 [debug] [MainThread]: Databricks adapter: Connection(session-id=d86118ca-3e20-463d-9eab-8c39f210f5bc) - Closing connection
[0m09:44:42.837513 [info ] [MainThread]: 
[0m09:44:42.838270 [info ] [MainThread]: Finished running 19 data tests in 0 hours 0 minutes and 5.39 seconds (5.39s).
[0m09:44:42.840551 [debug] [MainThread]: Command end result
[0m09:44:42.941851 [info ] [MainThread]: 
[0m09:44:42.942324 [info ] [MainThread]: [31mCompleted with 19 errors and 0 warnings:[0m
[0m09:44:42.942548 [info ] [MainThread]: 
[0m09:44:42.942828 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_customerID (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.943031 [info ] [MainThread]: 
[0m09:44:42.943246 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_freight (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.943419 [info ] [MainThread]: 
[0m09:44:42.943612 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_lineTotal (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.943779 [info ] [MainThread]: 
[0m09:44:42.943971 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_listPrice (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.944131 [info ] [MainThread]: 
[0m09:44:42.944321 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_name (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.944485 [info ] [MainThread]: 
[0m09:44:42.944670 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_orderDate (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.944835 [info ] [MainThread]: 
[0m09:44:42.945020 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_orderQty (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.945183 [info ] [MainThread]: 
[0m09:44:42.945373 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_productID (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.945530 [info ] [MainThread]: 
[0m09:44:42.945722 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_productNumber (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.945878 [info ] [MainThread]: 
[0m09:44:42.946067 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.946225 [info ] [MainThread]: 
[0m09:44:42.946413 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.946571 [info ] [MainThread]: 
[0m09:44:42.946755 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_sellStartDate (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.946916 [info ] [MainThread]: 
[0m09:44:42.947103 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_standardCost (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.947484 [info ] [MainThread]: 
[0m09:44:42.947731 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_subTotal (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.947907 [info ] [MainThread]: 
[0m09:44:42.948133 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_taxAmt (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.948525 [info ] [MainThread]: 
[0m09:44:42.948742 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_totalDue (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.948913 [info ] [MainThread]: 
[0m09:44:42.949110 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_unitPrice (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
[0m09:44:42.949275 [info ] [MainThread]: 
[0m09:44:42.949707 [error] [MainThread]:   Runtime Error in test unique_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 15 pos 5
[0m09:44:42.950148 [info ] [MainThread]: 
[0m09:44:42.950393 [error] [MainThread]:   Runtime Error in test unique_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `hive_metastore`.`saleslt`.`dim_sales` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 15 pos 5
[0m09:44:42.950602 [info ] [MainThread]: 
[0m09:44:42.950787 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=19 SKIP=0 TOTAL=19
[0m09:44:42.974880 [debug] [MainThread]: Resource report: {"command_name": "test", "command_wall_clock_time": 7.676578, "process_user_time": 3.158801, "process_kernel_time": 2.461196, "process_mem_max_rss": "232112128", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:44:42.978707 [debug] [MainThread]: Command `dbt test` failed at 09:44:42.978605 after 7.68 seconds
[0m09:44:42.979400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e32bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e32f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dda810>]}
[0m09:44:42.979760 [debug] [MainThread]: Flushing usage events
[0m09:47:18.656372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106873350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068dc710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068dcfd0>]}


============================== 09:47:18.659903 | 8542197a-3e53-4e88-b412-8c4687748b70 ==============================
[0m09:47:18.659903 [info ] [MainThread]: Running with dbt=1.8.5
[0m09:47:18.660381 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/vaishnavitamilvanan/.dbt', 'log_path': '/Users/vaishnavitamilvanan/Documents/GW MS DS/Semester/Fall 2024/NLP/PycharmProjects/Medallion-Spark-Azure-DBT/medallion_dbt_spark/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:47:18.722277 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m09:47:18.722743 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m09:47:18.722956 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m09:47:19.732934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8542197a-3e53-4e88-b412-8c4687748b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x138661c10>]}
[0m09:47:19.759930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8542197a-3e53-4e88-b412-8c4687748b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1385160d0>]}
[0m09:47:19.760335 [info ] [MainThread]: Registered adapter: databricks=1.8.5
[0m09:47:19.780673 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m09:47:19.967303 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:47:19.967705 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:47:19.971642 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.medallion_dbt_spark.example
[0m09:47:20.002837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8542197a-3e53-4e88-b412-8c4687748b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10687e590>]}
[0m09:47:20.090900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8542197a-3e53-4e88-b412-8c4687748b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x139ae0050>]}
[0m09:47:20.091299 [info ] [MainThread]: Found 7 snapshots, 3 models, 19 data tests, 9 sources, 590 macros
[0m09:47:20.091537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8542197a-3e53-4e88-b412-8c4687748b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x139958410>]}
[0m09:47:20.092795 [info ] [MainThread]: 
[0m09:47:20.093323 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5259933712, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(6952, 8194199360), compute-name=) - Creating connection
[0m09:47:20.093540 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m09:47:20.093733 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5259933712, session-id=None, name=master, idle-time=4.0531158447265625e-06s, acquire-count=1, language=None, thread-identifier=(6952, 8194199360), compute-name=) - Acquired connection on thread (6952, 8194199360), using default compute resource
[0m09:47:20.097303 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=None, name=list_hive_metastore, idle-time=0s, acquire-count=0, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Creating connection
[0m09:47:20.097594 [debug] [ThreadPool]: Acquiring new databricks connection 'list_hive_metastore'
[0m09:47:20.097795 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=None, name=list_hive_metastore, idle-time=2.86102294921875e-06s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Acquired connection on thread (6952, 6164508672), using default compute resource
[0m09:47:20.098033 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=None, name=list_hive_metastore, idle-time=0.0002486705780029297s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Checking idleness
[0m09:47:20.098254 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=None, name=list_hive_metastore, idle-time=0.00044989585876464844s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Retrieving connection
[0m09:47:20.098523 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore"
[0m09:47:20.098693 [debug] [ThreadPool]: On list_hive_metastore: GetSchemas(database=hive_metastore, schema=None)
[0m09:47:20.098843 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:47:20.481452 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore, idle-time=2.288818359375e-05s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Connection created
[0m09:47:20.482882 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=Unknown) - Created cursor
[0m09:47:21.201460 [debug] [ThreadPool]: SQL status: OK in 1.100 seconds
[0m09:47:21.209500 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=e08c0e4a-7859-49be-a003-f40ff2fab03a) - Closing cursor
[0m09:47:21.209863 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore, idle-time=4.76837158203125e-06s, acquire-count=0, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Released connection
[0m09:47:21.211011 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore, idle-time=0.0011210441589355469s, acquire-count=0, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Checking idleness
[0m09:47:21.211307 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_hive_metastore, now list_hive_metastore_saleslt)
[0m09:47:21.211515 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_saleslt, idle-time=0.0016651153564453125s, acquire-count=0, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Reusing connection previously named list_hive_metastore
[0m09:47:21.211713 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_saleslt, idle-time=0.0018630027770996094s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Acquired connection on thread (6952, 6164508672), using default compute resource
[0m09:47:21.211912 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_saleslt, idle-time=0.002070903778076172s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Checking idleness
[0m09:47:21.212090 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_saleslt, idle-time=0.002249002456665039s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Retrieving connection
[0m09:47:21.212247 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:47:21.212416 [debug] [ThreadPool]: On list_hive_metastore_saleslt: GetTables(database=hive_metastore, schema=saleslt, identifier=None)
[0m09:47:21.212581 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=Unknown) - Created cursor
[0m09:47:21.433246 [debug] [ThreadPool]: SQL status: OK in 0.220 seconds
[0m09:47:21.435801 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=5442beff-b949-4c7a-adf8-fd34a76fb33f) - Closing cursor
[0m09:47:21.443903 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_saleslt, idle-time=0.2340238094329834s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Checking idleness
[0m09:47:21.444200 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_saleslt, idle-time=0.23434901237487793s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Retrieving connection
[0m09:47:21.444415 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_saleslt, idle-time=0.2345740795135498s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Checking idleness
[0m09:47:21.444587 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_saleslt, idle-time=0.23474884033203125s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Retrieving connection
[0m09:47:21.444769 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m09:47:21.444911 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:47:21.445081 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */

      select current_catalog()
  
[0m09:47:21.445255 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=Unknown) - Created cursor
[0m09:47:21.712484 [debug] [ThreadPool]: SQL status: OK in 0.270 seconds
[0m09:47:21.715604 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=1c01102a-aa35-4168-a840-33868ac475e1) - Closing cursor
[0m09:47:21.720599 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_saleslt, idle-time=0.5107247829437256s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Checking idleness
[0m09:47:21.720841 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_saleslt, idle-time=0.5109949111938477s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Retrieving connection
[0m09:47:21.721012 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:47:21.721189 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */
show views in `hive_metastore`.`saleslt`
  
[0m09:47:21.721424 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=Unknown) - Created cursor
[0m09:47:22.016859 [debug] [ThreadPool]: SQL status: OK in 0.300 seconds
[0m09:47:22.022275 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=07867517-bac4-4e30-a5ce-2d57dfc10587) - Closing cursor
[0m09:47:22.022894 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_saleslt, idle-time=8.344650268554688e-06s, acquire-count=0, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Released connection
[0m09:47:22.023321 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_saleslt, idle-time=0.00044918060302734375s, acquire-count=0, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Checking idleness
[0m09:47:22.024532 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_hive_metastore_saleslt, now list_hive_metastore_snapshots)
[0m09:47:22.024766 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_snapshots, idle-time=0.0018870830535888672s, acquire-count=0, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Reusing connection previously named list_hive_metastore_saleslt
[0m09:47:22.024960 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_snapshots, idle-time=0.0020911693572998047s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Acquired connection on thread (6952, 6164508672), using default compute resource
[0m09:47:22.025155 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_snapshots, idle-time=0.002293109893798828s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Checking idleness
[0m09:47:22.025334 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_snapshots, idle-time=0.0024690628051757812s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Retrieving connection
[0m09:47:22.025478 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:47:22.025652 [debug] [ThreadPool]: On list_hive_metastore_snapshots: GetTables(database=hive_metastore, schema=snapshots, identifier=None)
[0m09:47:22.025818 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=Unknown) - Created cursor
[0m09:47:22.327141 [debug] [ThreadPool]: SQL status: OK in 0.300 seconds
[0m09:47:22.330721 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=cef2bc08-77b1-4753-ad8c-8eb876f16b20) - Closing cursor
[0m09:47:22.332821 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_snapshots, idle-time=0.30994606018066406s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Checking idleness
[0m09:47:22.333037 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_snapshots, idle-time=0.31017231941223145s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Retrieving connection
[0m09:47:22.333191 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:47:22.333350 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */

      select current_catalog()
  
[0m09:47:22.333517 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=Unknown) - Created cursor
[0m09:47:22.445235 [debug] [ThreadPool]: SQL status: OK in 0.110 seconds
[0m09:47:22.448593 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=51eb7d37-8ba5-418d-92c2-c61dd8cff870) - Closing cursor
[0m09:47:22.454014 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_snapshots, idle-time=0.43111515045166016s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Checking idleness
[0m09:47:22.454298 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_snapshots, idle-time=0.43143415451049805s, acquire-count=1, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Retrieving connection
[0m09:47:22.454457 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:47:22.454656 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */
show views in `hive_metastore`.`snapshots`
  
[0m09:47:22.454945 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=Unknown) - Created cursor
[0m09:47:22.732139 [debug] [ThreadPool]: SQL status: OK in 0.280 seconds
[0m09:47:22.736642 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=6aebc9e3-f328-4290-8cee-319c2173cf35) - Closing cursor
[0m09:47:22.737768 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_snapshots, idle-time=6.9141387939453125e-06s, acquire-count=0, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Released connection
[0m09:47:22.739076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8542197a-3e53-4e88-b412-8c4687748b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103b7aed0>]}
[0m09:47:22.739474 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5259933712, session-id=None, name=master, idle-time=2.6457340717315674s, acquire-count=1, language=None, thread-identifier=(6952, 8194199360), compute-name=) - Checking idleness
[0m09:47:22.739670 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5259933712, session-id=None, name=master, idle-time=2.6459381580352783s, acquire-count=1, language=None, thread-identifier=(6952, 8194199360), compute-name=) - Retrieving connection
[0m09:47:22.739846 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5259933712, session-id=None, name=master, idle-time=2.6461308002471924s, acquire-count=1, language=None, thread-identifier=(6952, 8194199360), compute-name=) - Checking idleness
[0m09:47:22.740004 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5259933712, session-id=None, name=master, idle-time=2.6462900638580322s, acquire-count=1, language=None, thread-identifier=(6952, 8194199360), compute-name=) - Retrieving connection
[0m09:47:22.740152 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m09:47:22.740309 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m09:47:22.740650 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5259933712, session-id=None, name=master, idle-time=4.0531158447265625e-06s, acquire-count=0, language=None, thread-identifier=(6952, 8194199360), compute-name=) - Released connection
[0m09:47:22.740929 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:47:22.741129 [info ] [MainThread]: 
[0m09:47:22.743700 [debug] [Thread-1 (]: Began running node model.medallion_dbt_spark.dim_customer
[0m09:47:22.744032 [info ] [Thread-1 (]: 1 of 3 START sql table model saleslt.dim_customer .............................. [RUN]
[0m09:47:22.744806 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=list_hive_metastore_snapshots, idle-time=0.0070037841796875s, acquire-count=0, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Checking idleness
[0m09:47:22.745105 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_hive_metastore_snapshots, now model.medallion_dbt_spark.dim_customer)
[0m09:47:22.745443 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_customer, idle-time=0.007658958435058594s, acquire-count=0, language=None, thread-identifier=(6952, 6164508672), compute-name=) - Reusing connection previously named list_hive_metastore_snapshots
[0m09:47:22.745782 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_customer, idle-time=0.008002042770385742s, acquire-count=1, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Acquired connection on thread (6952, 6164508672), using default compute resource for model '`hive_metastore`.`saleslt`.`dim_customer`'
[0m09:47:22.746099 [debug] [Thread-1 (]: Began compiling node model.medallion_dbt_spark.dim_customer
[0m09:47:22.752332 [debug] [Thread-1 (]: Writing injected SQL for node "model.medallion_dbt_spark.dim_customer"
[0m09:47:22.753125 [debug] [Thread-1 (]: Began executing node model.medallion_dbt_spark.dim_customer
[0m09:47:22.760106 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m09:47:22.786992 [debug] [Thread-1 (]: Writing runtime sql for node "model.medallion_dbt_spark.dim_customer"
[0m09:47:22.787773 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_customer, idle-time=0.05001974105834961s, acquire-count=1, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Checking idleness
[0m09:47:22.788020 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_customer, idle-time=0.05028390884399414s, acquire-count=1, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Retrieving connection
[0m09:47:22.788183 [debug] [Thread-1 (]: Using databricks connection "model.medallion_dbt_spark.dim_customer"
[0m09:47:22.788494 [debug] [Thread-1 (]: On model.medallion_dbt_spark.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "model.medallion_dbt_spark.dim_customer"} */

  
    
        create or replace table `hive_metastore`.`saleslt`.`dim_customer`
      
      using delta
      
      
      
      
      
    location '/mnt/gold/customers/dim_customer'
      
      
      as
      

with address_snapshot as (
    select
        AddressID,
        AddressLine1,
        AddressLine2,
        City,
        StateProvince,
        CountryRegion,
        PostalCode
    from `hive_metastore`.`snapshots`.`address_snapshot` where dbt_valid_to is null
)

, customeraddress_snapshot as (
    select
        CustomerId,
        AddressId,
        AddressType
    from `hive_metastore`.`snapshots`.`customeraddress_snapshot` where dbt_valid_to is null
)

, customer_snapshot as (
    select
        CustomerId,
        concat(ifnull(FirstName,' '),' ',ifnull(MiddleName,' '),' ',ifnull(LastName,' ')) as FullName
    from `hive_metastore`.`snapshots`.`customer_snapshot` where dbt_valid_to is null
)

, transformed as (
    select
    row_number() over (order by customer_snapshot.customerid) as customer_sk, -- auto-incremental surrogate key
    customer_snapshot.CustomerId,
    customer_snapshot.fullname,
    customeraddress_snapshot.AddressID,
    customeraddress_snapshot.AddressType,
    address_snapshot.AddressLine1,
    address_snapshot.City,
    address_snapshot.StateProvince,
    address_snapshot.CountryRegion,
    address_snapshot.PostalCode
    from customer_snapshot
    inner join customeraddress_snapshot on customer_snapshot.CustomerId = customeraddress_snapshot.CustomerId
    inner join address_snapshot on customeraddress_snapshot.AddressID = address_snapshot.AddressID
)
select *
from transformed
  
[0m09:47:22.788786 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=Unknown) - Created cursor
[0m09:47:29.046198 [debug] [Thread-1 (]: SQL status: OK in 6.260 seconds
[0m09:47:29.049183 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=021ae8a7-8ab6-4205-a36e-763fbf0ccedd) - Closing cursor
[0m09:47:29.128259 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_customer, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Released connection
[0m09:47:29.128679 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_customer, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Released connection
[0m09:47:29.129468 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8542197a-3e53-4e88-b412-8c4687748b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1386c9310>]}
[0m09:47:29.129839 [info ] [Thread-1 (]: 1 of 3 OK created sql table model saleslt.dim_customer ......................... [[32mOK[0m in 6.38s]
[0m09:47:29.130180 [debug] [Thread-1 (]: Finished running node model.medallion_dbt_spark.dim_customer
[0m09:47:29.130417 [debug] [Thread-1 (]: Began running node model.medallion_dbt_spark.dim_product
[0m09:47:29.130758 [info ] [Thread-1 (]: 2 of 3 START sql table model saleslt.dim_product ............................... [RUN]
[0m09:47:29.131142 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_customer, idle-time=0.0024728775024414062s, acquire-count=0, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Checking idleness
[0m09:47:29.131350 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.medallion_dbt_spark.dim_customer, now model.medallion_dbt_spark.dim_product)
[0m09:47:29.131569 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_product, idle-time=0.002908945083618164s, acquire-count=0, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Reusing connection previously named model.medallion_dbt_spark.dim_customer
[0m09:47:29.131783 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_product, idle-time=0.003126859664916992s, acquire-count=1, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Acquired connection on thread (6952, 6164508672), using default compute resource for model '`hive_metastore`.`saleslt`.`dim_product`'
[0m09:47:29.131984 [debug] [Thread-1 (]: Began compiling node model.medallion_dbt_spark.dim_product
[0m09:47:29.134574 [debug] [Thread-1 (]: Writing injected SQL for node "model.medallion_dbt_spark.dim_product"
[0m09:47:29.135207 [debug] [Thread-1 (]: Began executing node model.medallion_dbt_spark.dim_product
[0m09:47:29.136711 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m09:47:29.138177 [debug] [Thread-1 (]: Writing runtime sql for node "model.medallion_dbt_spark.dim_product"
[0m09:47:29.138827 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_product, idle-time=0.010156869888305664s, acquire-count=1, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Checking idleness
[0m09:47:29.139064 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_product, idle-time=0.01040792465209961s, acquire-count=1, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Retrieving connection
[0m09:47:29.139227 [debug] [Thread-1 (]: Using databricks connection "model.medallion_dbt_spark.dim_product"
[0m09:47:29.139504 [debug] [Thread-1 (]: On model.medallion_dbt_spark.dim_product: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "model.medallion_dbt_spark.dim_product"} */

  
    
        create or replace table `hive_metastore`.`saleslt`.`dim_product`
      
      using delta
      
      
      
      
      
    location '/mnt/gold/products/dim_product'
      
      
      as
      

with product_snapshot as (
    select
        productId,
        name,
        standardCost,
        listPrice,
        size,
        weight,
        productcategoryid,
        productmodelid,
        sellstartdate,
        sellenddate,
        discontinueddate
    from `hive_metastore`.`snapshots`.`product_snapshot`
    where dbt_valid_to is null
),

product_model_snapshot as (
    select
        productmodelid,
        name,
        CatalogDescription,
        row_number() over (order by name) as model_id
    from `hive_metastore`.`snapshots`.`productmodel_snapshot`
    where dbt_valid_to is null
),


transformed as (
    select
        row_number() over (order by p.productId) as product_sk,
        p.name as product_name,
        p.standardCost,
        p.listPrice,
        p.size,
        p.weight,
        pm.name as model,
        pm.CatalogDescription as description,
        p.sellstartdate,
        p.sellenddate,
        p.discontinueddate
    from product_snapshot p
    left join product_model_snapshot pm on p.productmodelid = pm.productmodelid
)

select * from transformed
  
[0m09:47:29.139767 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=Unknown) - Created cursor
[0m09:47:32.984733 [debug] [Thread-1 (]: SQL status: OK in 3.840 seconds
[0m09:47:32.986762 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=8d5505f7-2c1a-4549-a464-5d86893d1c16) - Closing cursor
[0m09:47:32.989542 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_product, idle-time=9.298324584960938e-06s, acquire-count=0, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Released connection
[0m09:47:32.990236 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_product, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Released connection
[0m09:47:32.990588 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8542197a-3e53-4e88-b412-8c4687748b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x139b69610>]}
[0m09:47:32.991092 [info ] [Thread-1 (]: 2 of 3 OK created sql table model saleslt.dim_product .......................... [[32mOK[0m in 3.86s]
[0m09:47:32.991586 [debug] [Thread-1 (]: Finished running node model.medallion_dbt_spark.dim_product
[0m09:47:32.991983 [debug] [Thread-1 (]: Began running node model.medallion_dbt_spark.dim_sales
[0m09:47:32.992357 [info ] [Thread-1 (]: 3 of 3 START sql table model saleslt.dim_sales ................................. [RUN]
[0m09:47:32.992751 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_product, idle-time=0.002526998519897461s, acquire-count=0, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Checking idleness
[0m09:47:32.992942 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.medallion_dbt_spark.dim_product, now model.medallion_dbt_spark.dim_sales)
[0m09:47:32.993148 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_sales, idle-time=0.0029311180114746094s, acquire-count=0, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Reusing connection previously named model.medallion_dbt_spark.dim_product
[0m09:47:32.993386 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_sales, idle-time=0.003161191940307617s, acquire-count=1, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Acquired connection on thread (6952, 6164508672), using default compute resource for model '`hive_metastore`.`saleslt`.`dim_sales`'
[0m09:47:32.993584 [debug] [Thread-1 (]: Began compiling node model.medallion_dbt_spark.dim_sales
[0m09:47:32.996481 [debug] [Thread-1 (]: Writing injected SQL for node "model.medallion_dbt_spark.dim_sales"
[0m09:47:32.997016 [debug] [Thread-1 (]: Began executing node model.medallion_dbt_spark.dim_sales
[0m09:47:33.000667 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m09:47:33.002076 [debug] [Thread-1 (]: Writing runtime sql for node "model.medallion_dbt_spark.dim_sales"
[0m09:47:33.002722 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_sales, idle-time=0.012428045272827148s, acquire-count=1, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Checking idleness
[0m09:47:33.003056 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_sales, idle-time=0.012833118438720703s, acquire-count=1, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Retrieving connection
[0m09:47:33.003241 [debug] [Thread-1 (]: Using databricks connection "model.medallion_dbt_spark.dim_sales"
[0m09:47:33.003611 [debug] [Thread-1 (]: On model.medallion_dbt_spark.dim_sales: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "model.medallion_dbt_spark.dim_sales"} */

  
    
        create or replace table `hive_metastore`.`saleslt`.`dim_sales`
      
      using delta
      
      
      
      
      
    location '/mnt/gold/sales/dim_sales'
      
      
      as
      

with salesorderdetail_snapshot as (
    SELECT
        SalesOrderID,
        SalesOrderDetailID,
        OrderQty,
        ProductID,
        UnitPrice,
        UnitPriceDiscount,
        LineTotal
    FROM `hive_metastore`.`snapshots`.`salesorderdetail_snapshot`
),

product_snapshot as (
    SELECT
        ProductID,
        Name,
        ProductNumber,
        Color,
        StandardCost,
        ListPrice,
        Size,
        Weight,
        SellStartDate,
        SellEndDate,
        DiscontinuedDate,
        ThumbNailPhoto,
        ThumbnailPhotoFileName
    FROM `hive_metastore`.`saleslt`.`product`
),

saleorderheader_snapshot as (
    SELECT
        SalesOrderID,
        RevisionNumber,
        OrderDate,
        DueDate,
        ShipDate,
        Status,
        OnlineOrderFlag,
        SalesOrderNumber,
        PurchaseOrderNumber,
        AccountNumber,
        CustomerID,
        ShipToAddressID,
        BillToAddressID,
        ShipMethod,
        CreditCardApprovalCode,
        SubTotal,
        TaxAmt,
        Freight,
        TotalDue,
        Comment,
        row_number() over (partition by SalesOrderID order by SalesOrderID) as row_num
    FROM `hive_metastore`.`saleslt`.`salesorderheader`
),

transformed as (
    select
        sod.SalesOrderID,
        sod.SalesOrderDetailID,
        sod.OrderQty,
        sod.ProductID,
        sod.UnitPrice,
        sod.UnitPriceDiscount,
        sod.LineTotal,
        p.Name,
        p.ProductNumber,
        p.Color,
        p.StandardCost,
        p.ListPrice,
        p.Size,
        p.Weight,
        p.SellStartDate,
        p.SellEndDate,
        p.DiscontinuedDate,
        p.ThumbNailPhoto,
        p.ThumbnailPhotoFileName,
        soh.RevisionNumber,
        soh.OrderDate,
        soh.DueDate,
        soh.ShipDate,
        soh.Status,
        soh.OnlineOrderFlag,
        soh.SalesOrderNumber,
        soh.PurchaseOrderNumber,
        soh.AccountNumber,
        soh.CustomerID,
        soh.ShipToAddressID,
        soh.BillToAddressID,
        soh.ShipMethod,
        soh.CreditCardApprovalCode,
        soh.SubTotal,
        soh.TaxAmt,
        soh.Freight,
        soh.TotalDue,
        soh.Comment
    from salesorderdetail_snapshot sod
    left join product_snapshot p on sod.ProductID = p.ProductID
    left join saleorderheader_snapshot soh on sod.SalesOrderID = soh.SalesOrderID
)

select * from transformed
  
[0m09:47:33.003940 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=Unknown) - Created cursor
[0m09:47:37.176823 [debug] [Thread-1 (]: SQL status: OK in 4.170 seconds
[0m09:47:37.178743 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, command-id=e9753d6a-d329-41b2-925f-295e719248bd) - Closing cursor
[0m09:47:37.181426 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_sales, idle-time=1.0251998901367188e-05s, acquire-count=0, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Released connection
[0m09:47:37.181893 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5262562576, session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81, name=model.medallion_dbt_spark.dim_sales, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(6952, 6164508672), compute-name=) - Released connection
[0m09:47:37.182239 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8542197a-3e53-4e88-b412-8c4687748b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x139e31610>]}
[0m09:47:37.182706 [info ] [Thread-1 (]: 3 of 3 OK created sql table model saleslt.dim_sales ............................ [[32mOK[0m in 4.19s]
[0m09:47:37.183073 [debug] [Thread-1 (]: Finished running node model.medallion_dbt_spark.dim_sales
[0m09:47:37.184131 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5259933712, session-id=None, name=master, idle-time=14.443481206893921s, acquire-count=0, language=None, thread-identifier=(6952, 8194199360), compute-name=) - Checking idleness
[0m09:47:37.184405 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5259933712, session-id=None, name=master, idle-time=14.443774938583374s, acquire-count=0, language=None, thread-identifier=(6952, 8194199360), compute-name=) - Reusing connection previously named master
[0m09:47:37.184602 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5259933712, session-id=None, name=master, idle-time=14.443977117538452s, acquire-count=1, language=None, thread-identifier=(6952, 8194199360), compute-name=) - Acquired connection on thread (6952, 8194199360), using default compute resource
[0m09:47:37.184822 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5259933712, session-id=None, name=master, idle-time=14.44420313835144s, acquire-count=1, language=None, thread-identifier=(6952, 8194199360), compute-name=) - Checking idleness
[0m09:47:37.185046 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5259933712, session-id=None, name=master, idle-time=14.444427967071533s, acquire-count=1, language=None, thread-identifier=(6952, 8194199360), compute-name=) - Retrieving connection
[0m09:47:37.185204 [debug] [MainThread]: On master: ROLLBACK
[0m09:47:37.185382 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:47:37.366354 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5259933712, session-id=46b9afc0-faab-44ee-8b7c-9c8ff0f19e8f, name=master, idle-time=2.6226043701171875e-06s, acquire-count=1, language=None, thread-identifier=(6952, 8194199360), compute-name=) - Connection created
[0m09:47:37.366705 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:47:37.366929 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5259933712, session-id=46b9afc0-faab-44ee-8b7c-9c8ff0f19e8f, name=master, idle-time=0.0007078647613525391s, acquire-count=1, language=None, thread-identifier=(6952, 8194199360), compute-name=) - Checking idleness
[0m09:47:37.367111 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5259933712, session-id=46b9afc0-faab-44ee-8b7c-9c8ff0f19e8f, name=master, idle-time=0.0008897781372070312s, acquire-count=1, language=None, thread-identifier=(6952, 8194199360), compute-name=) - Retrieving connection
[0m09:47:37.367290 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m09:47:37.367445 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m09:47:37.367613 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5259933712, session-id=46b9afc0-faab-44ee-8b7c-9c8ff0f19e8f, name=master, idle-time=9.5367431640625e-07s, acquire-count=0, language=None, thread-identifier=(6952, 8194199360), compute-name=) - Released connection
[0m09:47:37.367875 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:47:37.368027 [debug] [MainThread]: On master: ROLLBACK
[0m09:47:37.368170 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:47:37.368324 [debug] [MainThread]: On master: Close
[0m09:47:37.368489 [debug] [MainThread]: Databricks adapter: Connection(session-id=46b9afc0-faab-44ee-8b7c-9c8ff0f19e8f) - Closing connection
[0m09:47:37.427801 [debug] [MainThread]: Connection 'model.medallion_dbt_spark.dim_sales' was properly closed.
[0m09:47:37.428548 [debug] [MainThread]: On model.medallion_dbt_spark.dim_sales: ROLLBACK
[0m09:47:37.429221 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:47:37.429768 [debug] [MainThread]: On model.medallion_dbt_spark.dim_sales: Close
[0m09:47:37.430275 [debug] [MainThread]: Databricks adapter: Connection(session-id=f33351a8-8303-4cc6-a43b-9bab3f8efd81) - Closing connection
[0m09:47:37.504533 [info ] [MainThread]: 
[0m09:47:37.505062 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 17.41 seconds (17.41s).
[0m09:47:37.505929 [debug] [MainThread]: Command end result
[0m09:47:37.537548 [info ] [MainThread]: 
[0m09:47:37.537852 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:47:37.538028 [info ] [MainThread]: 
[0m09:47:37.538214 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m09:47:37.540460 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 18.956003, "process_user_time": 2.617381, "process_kernel_time": 2.225845, "process_mem_max_rss": "218726400", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:47:37.540789 [debug] [MainThread]: Command `dbt run` succeeded at 09:47:37.540739 after 18.96 seconds
[0m09:47:37.541003 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068c6bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10650c610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102901150>]}
[0m09:47:37.541207 [debug] [MainThread]: Flushing usage events
[0m09:47:44.921793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109540550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109542fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109591590>]}


============================== 09:47:44.925442 | be227114-9805-4cf2-9df2-18762421ca13 ==============================
[0m09:47:44.925442 [info ] [MainThread]: Running with dbt=1.8.5
[0m09:47:44.925889 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/vaishnavitamilvanan/.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/vaishnavitamilvanan/Documents/GW MS DS/Semester/Fall 2024/NLP/PycharmProjects/Medallion-Spark-Azure-DBT/medallion_dbt_spark/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:47:44.982262 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m09:47:44.982715 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m09:47:44.982928 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m09:47:45.816678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'be227114-9805-4cf2-9df2-18762421ca13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x131df3810>]}
[0m09:47:45.846201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'be227114-9805-4cf2-9df2-18762421ca13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x131d16050>]}
[0m09:47:45.846723 [info ] [MainThread]: Registered adapter: databricks=1.8.5
[0m09:47:45.864630 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m09:47:46.055243 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:47:46.055597 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:47:46.059956 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.medallion_dbt_spark.example
[0m09:47:46.091905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'be227114-9805-4cf2-9df2-18762421ca13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13205a610>]}
[0m09:47:46.187624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'be227114-9805-4cf2-9df2-18762421ca13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1323c7cd0>]}
[0m09:47:46.188029 [info ] [MainThread]: Found 7 snapshots, 3 models, 19 data tests, 9 sources, 590 macros
[0m09:47:46.188255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'be227114-9805-4cf2-9df2-18762421ca13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x131f2fb10>]}
[0m09:47:46.189796 [info ] [MainThread]: 
[0m09:47:46.190259 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5133049040, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7004, 8194199360), compute-name=) - Creating connection
[0m09:47:46.190471 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m09:47:46.190646 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5133049040, session-id=None, name=master, idle-time=9.5367431640625e-07s, acquire-count=1, language=None, thread-identifier=(7004, 8194199360), compute-name=) - Acquired connection on thread (7004, 8194199360), using default compute resource
[0m09:47:46.194684 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=None, name=list_hive_metastore_saleslt, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Creating connection
[0m09:47:46.195028 [debug] [ThreadPool]: Acquiring new databricks connection 'list_hive_metastore_saleslt'
[0m09:47:46.195229 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=None, name=list_hive_metastore_saleslt, idle-time=9.5367431640625e-07s, acquire-count=1, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource
[0m09:47:46.195453 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=None, name=list_hive_metastore_saleslt, idle-time=0.00022792816162109375s, acquire-count=1, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:46.195635 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=None, name=list_hive_metastore_saleslt, idle-time=0.0004076957702636719s, acquire-count=1, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:46.195869 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:47:46.196035 [debug] [ThreadPool]: On list_hive_metastore_saleslt: GetTables(database=hive_metastore, schema=saleslt, identifier=None)
[0m09:47:46.196186 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:47:46.387832 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_saleslt, idle-time=3.814697265625e-06s, acquire-count=1, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Connection created
[0m09:47:46.388239 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:46.513582 [debug] [ThreadPool]: SQL status: OK in 0.320 seconds
[0m09:47:46.517645 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=553c9a0f-db0f-47cc-b689-caccc5c0b977) - Closing cursor
[0m09:47:46.527984 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_saleslt, idle-time=0.14021992683410645s, acquire-count=1, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:46.528218 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_saleslt, idle-time=0.1404716968536377s, acquire-count=1, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:46.528406 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_saleslt, idle-time=0.14066481590270996s, acquire-count=1, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:46.528575 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_saleslt, idle-time=0.14083576202392578s, acquire-count=1, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:46.528729 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m09:47:46.528867 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:47:46.529024 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */

      select current_catalog()
  
[0m09:47:46.529192 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:46.628922 [debug] [ThreadPool]: SQL status: OK in 0.100 seconds
[0m09:47:46.631944 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=56c3209c-6dd8-4034-9489-14c23ded510a) - Closing cursor
[0m09:47:46.636540 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_saleslt, idle-time=0.2487330436706543s, acquire-count=1, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:46.636929 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_saleslt, idle-time=0.24918103218078613s, acquire-count=1, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:46.637104 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:47:46.637286 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */
show views in `hive_metastore`.`saleslt`
  
[0m09:47:46.637477 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:46.831746 [debug] [ThreadPool]: SQL status: OK in 0.190 seconds
[0m09:47:46.833513 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=92d19faf-c230-4772-8e2f-56b885a85189) - Closing cursor
[0m09:47:46.834022 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_saleslt, idle-time=6.198883056640625e-06s, acquire-count=0, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:46.834411 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_saleslt, idle-time=0.0004019737243652344s, acquire-count=0, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:46.835619 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_hive_metastore_saleslt, now list_hive_metastore_snapshots)
[0m09:47:46.835869 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_snapshots, idle-time=0.001850128173828125s, acquire-count=0, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named list_hive_metastore_saleslt
[0m09:47:46.836080 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_snapshots, idle-time=0.0020689964294433594s, acquire-count=1, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource
[0m09:47:46.836292 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_snapshots, idle-time=0.002293109893798828s, acquire-count=1, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:46.836482 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_snapshots, idle-time=0.0024709701538085938s, acquire-count=1, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:46.836633 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:47:46.836785 [debug] [ThreadPool]: On list_hive_metastore_snapshots: GetTables(database=hive_metastore, schema=snapshots, identifier=None)
[0m09:47:46.836957 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:46.946797 [debug] [ThreadPool]: SQL status: OK in 0.110 seconds
[0m09:47:46.949157 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=aaf9e99c-eeeb-4290-b283-2a61ae1861d4) - Closing cursor
[0m09:47:46.951066 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_snapshots, idle-time=0.11704802513122559s, acquire-count=1, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:46.951297 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_snapshots, idle-time=0.11728525161743164s, acquire-count=1, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:46.951470 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:47:46.951644 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */

      select current_catalog()
  
[0m09:47:46.951819 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:47.062181 [debug] [ThreadPool]: SQL status: OK in 0.110 seconds
[0m09:47:47.063868 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=67c97e39-fd65-4ebf-ac99-1a0b42ce0377) - Closing cursor
[0m09:47:47.065621 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_snapshots, idle-time=0.23158907890319824s, acquire-count=1, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:47.065896 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_snapshots, idle-time=0.23189187049865723s, acquire-count=1, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:47.066065 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:47:47.066242 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */
show views in `hive_metastore`.`snapshots`
  
[0m09:47:47.066423 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:47.243956 [debug] [ThreadPool]: SQL status: OK in 0.180 seconds
[0m09:47:47.249372 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=f7ad7c26-b39d-4079-9cf1-39d19abaef1c) - Closing cursor
[0m09:47:47.250066 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_snapshots, idle-time=3.0994415283203125e-06s, acquire-count=0, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:47.251305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'be227114-9805-4cf2-9df2-18762421ca13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095b45d0>]}
[0m09:47:47.251973 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5133049040, session-id=None, name=master, idle-time=1.0612881183624268s, acquire-count=1, language=None, thread-identifier=(7004, 8194199360), compute-name=) - Checking idleness
[0m09:47:47.252294 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5133049040, session-id=None, name=master, idle-time=1.0616471767425537s, acquire-count=1, language=None, thread-identifier=(7004, 8194199360), compute-name=) - Retrieving connection
[0m09:47:47.252473 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5133049040, session-id=None, name=master, idle-time=1.0618391036987305s, acquire-count=1, language=None, thread-identifier=(7004, 8194199360), compute-name=) - Checking idleness
[0m09:47:47.252652 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5133049040, session-id=None, name=master, idle-time=1.0620200634002686s, acquire-count=1, language=None, thread-identifier=(7004, 8194199360), compute-name=) - Retrieving connection
[0m09:47:47.252804 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m09:47:47.252950 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m09:47:47.253109 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5133049040, session-id=None, name=master, idle-time=1.9073486328125e-06s, acquire-count=0, language=None, thread-identifier=(7004, 8194199360), compute-name=) - Released connection
[0m09:47:47.253366 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:47:47.253582 [info ] [MainThread]: 
[0m09:47:47.256624 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:47:47.256882 [info ] [Thread-1 (]: 1 of 19 START test not_null_dim_sales_customerID ............................... [RUN]
[0m09:47:47.257258 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=list_hive_metastore_snapshots, idle-time=0.007145881652832031s, acquire-count=0, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:47.257455 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_hive_metastore_snapshots, now test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5)
[0m09:47:47.257685 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.007608175277709961s, acquire-count=0, language=None, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named list_hive_metastore_snapshots
[0m09:47:47.257921 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.007843017578125s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:47.258120 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:47:47.270359 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"
[0m09:47:47.271067 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:47:47.280427 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"
[0m09:47:47.281085 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.03099203109741211s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:47.281425 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.031324148178100586s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:47.281652 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"
[0m09:47:47.281883 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customerID
from `hive_metastore`.`saleslt`.`dim_sales`
where customerID is null



      
    ) dbt_internal_test
[0m09:47:47.282125 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:47.924970 [debug] [Thread-1 (]: SQL status: OK in 0.640 seconds
[0m09:47:47.930021 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=7c41662a-aaf9-4ac4-a832-22efec924dd8) - Closing cursor
[0m09:47:47.932917 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:47.933324 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:47.933642 [info ] [Thread-1 (]: 1 of 19 PASS not_null_dim_sales_customerID ..................................... [[32mPASS[0m in 0.68s]
[0m09:47:47.934037 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:47:47.934292 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:47:47.934658 [info ] [Thread-1 (]: 2 of 19 START test not_null_dim_sales_freight .................................. [RUN]
[0m09:47:47.935226 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.001867055892944336s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:47.935470 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, now test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131)
[0m09:47:47.935708 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.0023801326751708984s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:47:47.935936 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.0026090145111083984s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:47.936133 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:47:47.941556 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m09:47:47.942052 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:47:47.943811 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m09:47:47.944218 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.010893106460571289s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:47.944435 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.011118173599243164s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:47.944671 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m09:47:47.944922 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select freight
from `hive_metastore`.`saleslt`.`dim_sales`
where freight is null



      
    ) dbt_internal_test
[0m09:47:47.945181 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:48.334704 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m09:47:48.339310 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=0fd80e3b-b14b-4fa7-9eb6-4baa51d4716a) - Closing cursor
[0m09:47:48.340084 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:48.340508 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:48.340849 [info ] [Thread-1 (]: 2 of 19 PASS not_null_dim_sales_freight ........................................ [[32mPASS[0m in 0.41s]
[0m09:47:48.341328 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:47:48.341729 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:47:48.342202 [info ] [Thread-1 (]: 3 of 19 START test not_null_dim_sales_lineTotal ................................ [RUN]
[0m09:47:48.342808 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.0022478103637695312s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:48.343174 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, now test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8)
[0m09:47:48.343562 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.002986907958984375s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:47:48.343792 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.0032949447631835938s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:48.344000 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:47:48.347846 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m09:47:48.348385 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:47:48.350161 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m09:47:48.350553 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.010055780410766602s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:48.350765 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.010276079177856445s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:48.350913 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m09:47:48.351121 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select lineTotal
from `hive_metastore`.`saleslt`.`dim_sales`
where lineTotal is null



      
    ) dbt_internal_test
[0m09:47:48.351335 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:48.642387 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:47:48.646695 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=d40d9ebd-5e63-4e66-8d9e-6724bc3d31d7) - Closing cursor
[0m09:47:48.647395 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=5.0067901611328125e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:48.647932 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=1.621246337890625e-05s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:48.648485 [info ] [Thread-1 (]: 3 of 19 PASS not_null_dim_sales_lineTotal ...................................... [[32mPASS[0m in 0.31s]
[0m09:47:48.648897 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:47:48.649155 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:47:48.649475 [info ] [Thread-1 (]: 4 of 19 START test not_null_dim_sales_listPrice ................................ [RUN]
[0m09:47:48.649801 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.0019791126251220703s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:48.650018 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, now test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f)
[0m09:47:48.650234 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.002413034439086914s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:47:48.650448 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.002637147903442383s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:48.650643 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:47:48.654116 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m09:47:48.654764 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:47:48.657164 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m09:47:48.657563 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.009749889373779297s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:48.657778 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.009959936141967773s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:48.657951 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m09:47:48.658159 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select listPrice
from `hive_metastore`.`saleslt`.`dim_sales`
where listPrice is null



      
    ) dbt_internal_test
[0m09:47:48.658380 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:48.913183 [debug] [Thread-1 (]: SQL status: OK in 0.250 seconds
[0m09:47:48.918288 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=371fff3a-5861-4283-bc56-2d8b022e1548) - Closing cursor
[0m09:47:48.918941 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:48.919384 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:48.919930 [info ] [Thread-1 (]: 4 of 19 PASS not_null_dim_sales_listPrice ...................................... [[32mPASS[0m in 0.27s]
[0m09:47:48.920578 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:47:48.921036 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:47:48.921398 [info ] [Thread-1 (]: 5 of 19 START test not_null_dim_sales_name ..................................... [RUN]
[0m09:47:48.921776 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.002465963363647461s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:48.921983 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, now test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77)
[0m09:47:48.922206 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0029020309448242188s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:47:48.922435 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0031311511993408203s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:48.922632 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:47:48.926217 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m09:47:48.926962 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:47:48.929572 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m09:47:48.930112 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.010801076889038086s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:48.930361 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.011050939559936523s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:48.930523 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m09:47:48.930741 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select name
from `hive_metastore`.`saleslt`.`dim_sales`
where name is null



      
    ) dbt_internal_test
[0m09:47:48.930958 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:49.255392 [debug] [Thread-1 (]: SQL status: OK in 0.320 seconds
[0m09:47:49.259820 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=15c1a082-d2a5-4f97-9391-6d618a7671aa) - Closing cursor
[0m09:47:49.260440 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:49.260818 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:49.261107 [info ] [Thread-1 (]: 5 of 19 PASS not_null_dim_sales_name ........................................... [[32mPASS[0m in 0.34s]
[0m09:47:49.261475 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:47:49.261753 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:47:49.262018 [info ] [Thread-1 (]: 6 of 19 START test not_null_dim_sales_orderDate ................................ [RUN]
[0m09:47:49.262375 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0015611648559570312s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:49.262580 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, now test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3)
[0m09:47:49.262808 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.002000093460083008s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:47:49.263015 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.002215147018432617s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:49.263228 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:47:49.267116 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m09:47:49.267587 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:47:49.269377 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m09:47:49.269771 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.008965015411376953s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:49.269980 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.009185075759887695s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:49.270123 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m09:47:49.270325 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orderDate
from `hive_metastore`.`saleslt`.`dim_sales`
where orderDate is null



      
    ) dbt_internal_test
[0m09:47:49.270524 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:49.562179 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:47:49.567305 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=71e551f3-58bf-4a10-8006-d9e4965bb864) - Closing cursor
[0m09:47:49.568062 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:49.568457 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:49.568779 [info ] [Thread-1 (]: 6 of 19 PASS not_null_dim_sales_orderDate ...................................... [[32mPASS[0m in 0.31s]
[0m09:47:49.569145 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:47:49.569453 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:47:49.569928 [info ] [Thread-1 (]: 7 of 19 START test not_null_dim_sales_orderQty ................................. [RUN]
[0m09:47:49.570531 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.002009868621826172s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:49.570865 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, now test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596)
[0m09:47:49.571218 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.002723217010498047s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:47:49.571502 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.003050088882446289s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:49.571693 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:47:49.577181 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"
[0m09:47:49.577796 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:47:49.579885 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"
[0m09:47:49.580367 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.011905193328857422s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:49.580583 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.012143850326538086s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:49.580731 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"
[0m09:47:49.580931 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orderQty
from `hive_metastore`.`saleslt`.`dim_sales`
where orderQty is null



      
    ) dbt_internal_test
[0m09:47:49.581135 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:49.894187 [debug] [Thread-1 (]: SQL status: OK in 0.310 seconds
[0m09:47:49.899602 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=41871923-3a4e-4786-bdd9-2fb6c9ddb7f8) - Closing cursor
[0m09:47:49.900328 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:49.900699 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:49.901010 [info ] [Thread-1 (]: 7 of 19 PASS not_null_dim_sales_orderQty ....................................... [[32mPASS[0m in 0.33s]
[0m09:47:49.901564 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:47:49.902025 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:47:49.902442 [info ] [Thread-1 (]: 8 of 19 START test not_null_dim_sales_productID ................................ [RUN]
[0m09:47:49.902820 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.002117156982421875s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:49.903049 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, now test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890)
[0m09:47:49.903268 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0025703907012939453s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:47:49.903501 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0028061866760253906s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:49.903706 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:47:49.907168 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m09:47:49.907772 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:47:49.909780 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m09:47:49.910336 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.009610414505004883s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:49.910626 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.009913206100463867s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:49.910835 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m09:47:49.911053 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select productID
from `hive_metastore`.`saleslt`.`dim_sales`
where productID is null



      
    ) dbt_internal_test
[0m09:47:49.911252 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:50.133182 [debug] [Thread-1 (]: SQL status: OK in 0.220 seconds
[0m09:47:50.136921 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=6511387d-ecd7-4ed3-99d8-670c7d934ddf) - Closing cursor
[0m09:47:50.137823 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:50.138266 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:50.138558 [info ] [Thread-1 (]: 8 of 19 PASS not_null_dim_sales_productID ...................................... [[32mPASS[0m in 0.24s]
[0m09:47:50.138914 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:47:50.139282 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:47:50.139631 [info ] [Thread-1 (]: 9 of 19 START test not_null_dim_sales_productNumber ............................ [RUN]
[0m09:47:50.140082 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0017998218536376953s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:50.140326 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, now test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd)
[0m09:47:50.140568 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.0022940635681152344s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:47:50.140798 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.0025370121002197266s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:50.141022 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:47:50.144130 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m09:47:50.144622 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:47:50.146538 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m09:47:50.146969 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.00870203971862793s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:50.147178 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.00892496109008789s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:50.147325 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m09:47:50.147530 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select productNumber
from `hive_metastore`.`saleslt`.`dim_sales`
where productNumber is null



      
    ) dbt_internal_test
[0m09:47:50.147732 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:50.484201 [debug] [Thread-1 (]: SQL status: OK in 0.340 seconds
[0m09:47:50.488952 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=97603509-a00a-41c0-bda5-1d41540b2eb8) - Closing cursor
[0m09:47:50.489612 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:50.490143 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:50.490695 [info ] [Thread-1 (]: 9 of 19 PASS not_null_dim_sales_productNumber .................................. [[32mPASS[0m in 0.35s]
[0m09:47:50.491352 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:47:50.491656 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:47:50.491956 [info ] [Thread-1 (]: 10 of 19 START test not_null_dim_sales_saleOrderDetailID ....................... [RUN]
[0m09:47:50.492346 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.002276897430419922s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:50.492557 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, now test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a)
[0m09:47:50.492780 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.0027201175689697266s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:47:50.493003 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.0029380321502685547s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:50.493197 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:47:50.496527 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"
[0m09:47:50.497112 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:47:50.499254 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"
[0m09:47:50.499803 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.009716033935546875s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:50.500104 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.01002812385559082s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:50.500257 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"
[0m09:47:50.500461 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderDetailID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is null



      
    ) dbt_internal_test
[0m09:47:50.500659 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:50.653782 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Closing cursor
[0m09:47:50.655580 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderDetailID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is null



      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=05651a1e-fec4-4e2c-8e39-f5a4fe55ea45
[0m09:47:50.656942 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=4.0531158447265625e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:50.665789 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
[0m09:47:50.666141 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:50.666479 [error] [Thread-1 (]: 10 of 19 ERROR not_null_dim_sales_saleOrderDetailID ............................ [[31mERROR[0m in 0.17s]
[0m09:47:50.667014 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:47:50.667400 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:47:50.667840 [info ] [Thread-1 (]: 11 of 19 START test not_null_dim_sales_saleOrderID ............................. [RUN]
[0m09:47:50.668316 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.002145051956176758s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:50.668542 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, now test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3)
[0m09:47:50.668752 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.002629995346069336s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:47:50.668956 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.002836942672729492s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:50.669146 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:47:50.672747 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"
[0m09:47:50.673175 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:47:50.675051 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"
[0m09:47:50.675663 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.009466886520385742s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:50.675985 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.009839057922363281s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:50.676192 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"
[0m09:47:50.676458 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is null



      
    ) dbt_internal_test
[0m09:47:50.676705 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:50.831422 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Closing cursor
[0m09:47:50.832367 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is null



      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=a0ebb8b5-3d13-45a6-966d-a91dc3dc760c
[0m09:47:50.833190 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:50.835580 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
[0m09:47:50.835967 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:50.836326 [error] [Thread-1 (]: 11 of 19 ERROR not_null_dim_sales_saleOrderID .................................. [[31mERROR[0m in 0.17s]
[0m09:47:50.836783 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:47:50.837033 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:47:50.837344 [info ] [Thread-1 (]: 12 of 19 START test not_null_dim_sales_sellStartDate ........................... [RUN]
[0m09:47:50.837723 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.0017809867858886719s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:50.837926 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, now test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118)
[0m09:47:50.838147 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0022039413452148438s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:47:50.838369 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0024309158325195312s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:50.838574 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:47:50.843353 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m09:47:50.843781 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:47:50.845622 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m09:47:50.846079 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.010126113891601562s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:50.846312 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.010380983352661133s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:50.846488 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m09:47:50.846702 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select sellStartDate
from `hive_metastore`.`saleslt`.`dim_sales`
where sellStartDate is null



      
    ) dbt_internal_test
[0m09:47:50.846921 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:51.202851 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m09:47:51.207332 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=7a12e385-9d68-45a5-b1e7-f12850ae5d49) - Closing cursor
[0m09:47:51.208100 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:51.208558 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=3.814697265625e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:51.208918 [info ] [Thread-1 (]: 12 of 19 PASS not_null_dim_sales_sellStartDate ................................. [[32mPASS[0m in 0.37s]
[0m09:47:51.209296 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:47:51.209554 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:47:51.209832 [info ] [Thread-1 (]: 13 of 19 START test not_null_dim_sales_standardCost ............................ [RUN]
[0m09:47:51.210180 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.001653909683227539s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:51.210376 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, now test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3)
[0m09:47:51.210587 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0020627975463867188s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:47:51.210829 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0022859573364257812s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:51.211017 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:47:51.214822 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m09:47:51.215347 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:47:51.216912 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m09:47:51.217356 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.008828878402709961s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:51.217567 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.009053945541381836s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:51.217713 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m09:47:51.217923 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select standardCost
from `hive_metastore`.`saleslt`.`dim_sales`
where standardCost is null



      
    ) dbt_internal_test
[0m09:47:51.218136 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:51.609773 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m09:47:51.614778 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=f4d69383-22f6-417d-bf09-cb059bd77066) - Closing cursor
[0m09:47:51.615388 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:51.615733 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:51.616015 [info ] [Thread-1 (]: 13 of 19 PASS not_null_dim_sales_standardCost .................................. [[32mPASS[0m in 0.41s]
[0m09:47:51.616369 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:47:51.616641 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:47:51.616913 [info ] [Thread-1 (]: 14 of 19 START test not_null_dim_sales_subTotal ................................ [RUN]
[0m09:47:51.617331 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0015590190887451172s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:51.617681 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, now test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487)
[0m09:47:51.617913 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.002185821533203125s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:47:51.618128 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.002402782440185547s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:51.618316 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:47:51.622054 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m09:47:51.622780 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:47:51.624554 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m09:47:51.624924 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.009185075759887695s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:51.625150 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.00942373275756836s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:51.625364 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m09:47:51.625657 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select subTotal
from `hive_metastore`.`saleslt`.`dim_sales`
where subTotal is null



      
    ) dbt_internal_test
[0m09:47:51.625952 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:51.914692 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:47:51.916660 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=a0948a0f-c4d6-4563-8a47-a47e0f35d61b) - Closing cursor
[0m09:47:51.917157 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:51.917481 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:51.917761 [info ] [Thread-1 (]: 14 of 19 PASS not_null_dim_sales_subTotal ...................................... [[32mPASS[0m in 0.30s]
[0m09:47:51.918112 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:47:51.918350 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:47:51.918553 [info ] [Thread-1 (]: 15 of 19 START test not_null_dim_sales_taxAmt .................................. [RUN]
[0m09:47:51.918925 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.0014271736145019531s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:51.919161 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, now test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a)
[0m09:47:51.919392 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.001905202865600586s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:47:51.919629 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.0021440982818603516s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:51.919836 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:47:51.922898 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m09:47:51.923445 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:47:51.925253 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m09:47:51.925743 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.008255958557128906s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:51.925997 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.008515119552612305s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:51.926152 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m09:47:51.926360 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select taxAmt
from `hive_metastore`.`saleslt`.`dim_sales`
where taxAmt is null



      
    ) dbt_internal_test
[0m09:47:51.926580 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:52.227225 [debug] [Thread-1 (]: SQL status: OK in 0.300 seconds
[0m09:47:52.229760 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=95bdb7bd-977c-49e0-a3f7-0af031af18c7) - Closing cursor
[0m09:47:52.230376 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:52.230741 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:52.231050 [info ] [Thread-1 (]: 15 of 19 PASS not_null_dim_sales_taxAmt ........................................ [[32mPASS[0m in 0.31s]
[0m09:47:52.231404 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:47:52.231664 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:47:52.231932 [info ] [Thread-1 (]: 16 of 19 START test not_null_dim_sales_totalDue ................................ [RUN]
[0m09:47:52.232436 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.0016570091247558594s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:52.232665 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, now test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023)
[0m09:47:52.232930 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.0021839141845703125s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:47:52.233167 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.0024251937866210938s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:52.233375 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:47:52.236921 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m09:47:52.237453 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:47:52.239211 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m09:47:52.239695 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.008946895599365234s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:52.239947 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.009213924407958984s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:52.240123 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m09:47:52.240377 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select totalDue
from `hive_metastore`.`saleslt`.`dim_sales`
where totalDue is null



      
    ) dbt_internal_test
[0m09:47:52.240673 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:52.532004 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:47:52.535588 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=c796d7e5-b945-4d32-9aa7-c6e433d41525) - Closing cursor
[0m09:47:52.536573 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=3.0994415283203125e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:52.537182 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:52.537704 [info ] [Thread-1 (]: 16 of 19 PASS not_null_dim_sales_totalDue ...................................... [[32mPASS[0m in 0.31s]
[0m09:47:52.538058 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:47:52.538311 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:47:52.538579 [info ] [Thread-1 (]: 17 of 19 START test not_null_dim_sales_unitPrice ............................... [RUN]
[0m09:47:52.538989 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.0018470287322998047s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:52.539215 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, now test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a)
[0m09:47:52.539447 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.002331256866455078s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:47:52.539810 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.0026459693908691406s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:52.540121 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:47:52.545317 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m09:47:52.545732 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:47:52.547324 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m09:47:52.547928 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.010761022567749023s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:52.548228 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.011092901229858398s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:52.548438 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m09:47:52.548949 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select unitPrice
from `hive_metastore`.`saleslt`.`dim_sales`
where unitPrice is null



      
    ) dbt_internal_test
[0m09:47:52.549330 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:52.839449 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:47:52.844559 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=4c5c7cf3-d428-48f8-99df-89472ad5b62b) - Closing cursor
[0m09:47:52.845489 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:52.845839 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:52.846112 [info ] [Thread-1 (]: 17 of 19 PASS not_null_dim_sales_unitPrice ..................................... [[32mPASS[0m in 0.31s]
[0m09:47:52.846460 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:47:52.846696 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:47:52.846962 [info ] [Thread-1 (]: 18 of 19 START test unique_dim_sales_saleOrderDetailID ......................... [RUN]
[0m09:47:52.847295 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.0014519691467285156s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:52.847566 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, now test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405)
[0m09:47:52.847919 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.002032041549682617s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:47:52.848308 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.0024230480194091797s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:52.848514 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:47:52.854417 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"
[0m09:47:52.854838 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:47:52.856979 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"
[0m09:47:52.857664 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.011806011199951172s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:52.857900 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.01206207275390625s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:52.858065 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"
[0m09:47:52.858293 [debug] [Thread-1 (]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderDetailID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is not null
group by saleOrderDetailID
having count(*) > 1



      
    ) dbt_internal_test
[0m09:47:52.858517 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:52.968914 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Closing cursor
[0m09:47:52.970515 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderDetailID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is not null
group by saleOrderDetailID
having count(*) > 1



      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=a874e217-57a0-4fc2-9b59-b73e9be49817
[0m09:47:52.971632 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=5.245208740234375e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:52.974889 [debug] [Thread-1 (]: Runtime Error in test unique_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
[0m09:47:52.975258 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:52.975546 [error] [Thread-1 (]: 18 of 19 ERROR unique_dim_sales_saleOrderDetailID .............................. [[31mERROR[0m in 0.13s]
[0m09:47:52.976102 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:47:52.976377 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:47:52.976584 [info ] [Thread-1 (]: 19 of 19 START test unique_dim_sales_saleOrderID ............................... [RUN]
[0m09:47:52.976928 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.00168609619140625s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:52.977134 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, now test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c)
[0m09:47:52.977472 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.0022079944610595703s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:47:52.977700 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.0024619102478027344s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Acquired connection on thread (7004, 6117535744), using default compute resource for model 'None'
[0m09:47:52.977895 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:47:52.981890 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"
[0m09:47:52.982562 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:47:52.984591 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"
[0m09:47:52.985092 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.009839057922363281s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Checking idleness
[0m09:47:52.985327 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.01009511947631836s, acquire-count=1, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Retrieving connection
[0m09:47:52.985501 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"
[0m09:47:52.985722 [debug] [Thread-1 (]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is not null
group by saleOrderID
having count(*) > 1



      
    ) dbt_internal_test
[0m09:47:52.985939 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Created cursor
[0m09:47:53.106626 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, command-id=Unknown) - Closing cursor
[0m09:47:53.108241 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is not null
group by saleOrderID
having count(*) > 1



      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=e966ceca-6d5d-468f-a157-0514350ac5db
[0m09:47:53.109508 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=5.9604644775390625e-06s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:53.113435 [debug] [Thread-1 (]: Runtime Error in test unique_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
[0m09:47:53.113878 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5131997904, session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7004, 6117535744), compute-name=) - Released connection
[0m09:47:53.114204 [error] [Thread-1 (]: 19 of 19 ERROR unique_dim_sales_saleOrderID .................................... [[31mERROR[0m in 0.14s]
[0m09:47:53.114614 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:47:53.115642 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5133049040, session-id=None, name=master, idle-time=5.8625030517578125s, acquire-count=0, language=None, thread-identifier=(7004, 8194199360), compute-name=) - Checking idleness
[0m09:47:53.115869 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5133049040, session-id=None, name=master, idle-time=5.8627519607543945s, acquire-count=0, language=None, thread-identifier=(7004, 8194199360), compute-name=) - Reusing connection previously named master
[0m09:47:53.116048 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5133049040, session-id=None, name=master, idle-time=5.862936973571777s, acquire-count=1, language=None, thread-identifier=(7004, 8194199360), compute-name=) - Acquired connection on thread (7004, 8194199360), using default compute resource
[0m09:47:53.116274 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5133049040, session-id=None, name=master, idle-time=5.86316990852356s, acquire-count=1, language=None, thread-identifier=(7004, 8194199360), compute-name=) - Checking idleness
[0m09:47:53.116454 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5133049040, session-id=None, name=master, idle-time=5.863347053527832s, acquire-count=1, language=None, thread-identifier=(7004, 8194199360), compute-name=) - Retrieving connection
[0m09:47:53.116693 [debug] [MainThread]: On master: ROLLBACK
[0m09:47:53.116928 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:47:53.281171 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5133049040, session-id=ec7d4503-8b04-472e-a7ae-f18c708396e6, name=master, idle-time=2.1457672119140625e-06s, acquire-count=1, language=None, thread-identifier=(7004, 8194199360), compute-name=) - Connection created
[0m09:47:53.281489 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:47:53.281698 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5133049040, session-id=ec7d4503-8b04-472e-a7ae-f18c708396e6, name=master, idle-time=0.0005681514739990234s, acquire-count=1, language=None, thread-identifier=(7004, 8194199360), compute-name=) - Checking idleness
[0m09:47:53.281940 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5133049040, session-id=ec7d4503-8b04-472e-a7ae-f18c708396e6, name=master, idle-time=0.0008120536804199219s, acquire-count=1, language=None, thread-identifier=(7004, 8194199360), compute-name=) - Retrieving connection
[0m09:47:53.282158 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m09:47:53.282356 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m09:47:53.282579 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5133049040, session-id=ec7d4503-8b04-472e-a7ae-f18c708396e6, name=master, idle-time=9.5367431640625e-07s, acquire-count=0, language=None, thread-identifier=(7004, 8194199360), compute-name=) - Released connection
[0m09:47:53.282892 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:47:53.283103 [debug] [MainThread]: On master: ROLLBACK
[0m09:47:53.283305 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:47:53.283502 [debug] [MainThread]: On master: Close
[0m09:47:53.283708 [debug] [MainThread]: Databricks adapter: Connection(session-id=ec7d4503-8b04-472e-a7ae-f18c708396e6) - Closing connection
[0m09:47:53.343531 [debug] [MainThread]: Connection 'test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c' was properly closed.
[0m09:47:53.343787 [debug] [MainThread]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c: ROLLBACK
[0m09:47:53.343959 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:47:53.344107 [debug] [MainThread]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c: Close
[0m09:47:53.344269 [debug] [MainThread]: Databricks adapter: Connection(session-id=3f575588-09e6-42ee-a8e1-85a7dc9b1b40) - Closing connection
[0m09:47:53.407985 [info ] [MainThread]: 
[0m09:47:53.408516 [info ] [MainThread]: Finished running 19 data tests in 0 hours 0 minutes and 7.22 seconds (7.22s).
[0m09:47:53.410205 [debug] [MainThread]: Command end result
[0m09:47:53.442938 [info ] [MainThread]: 
[0m09:47:53.443257 [info ] [MainThread]: [31mCompleted with 4 errors and 0 warnings:[0m
[0m09:47:53.443439 [info ] [MainThread]: 
[0m09:47:53.443661 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
[0m09:47:53.443830 [info ] [MainThread]: 
[0m09:47:53.444017 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
[0m09:47:53.444216 [info ] [MainThread]: 
[0m09:47:53.444466 [error] [MainThread]:   Runtime Error in test unique_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
[0m09:47:53.444645 [info ] [MainThread]: 
[0m09:47:53.444842 [error] [MainThread]:   Runtime Error in test unique_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
[0m09:47:53.445016 [info ] [MainThread]: 
[0m09:47:53.445182 [info ] [MainThread]: Done. PASS=15 WARN=0 ERROR=4 SKIP=0 TOTAL=19
[0m09:47:53.447650 [debug] [MainThread]: Resource report: {"command_name": "test", "command_wall_clock_time": 8.600924, "process_user_time": 2.754633, "process_kernel_time": 2.196497, "process_mem_max_rss": "226623488", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:47:53.448021 [debug] [MainThread]: Command `dbt test` failed at 09:47:53.447966 after 8.60 seconds
[0m09:47:53.448263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10553ec10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10553ebd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055cd290>]}
[0m09:47:53.448493 [debug] [MainThread]: Flushing usage events
[0m09:52:52.983738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cada50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c5c990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cd1190>]}


============================== 09:52:52.987727 | 886b2d4f-c060-4e92-abda-78e419d2aa43 ==============================
[0m09:52:52.987727 [info ] [MainThread]: Running with dbt=1.8.5
[0m09:52:52.988187 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/vaishnavitamilvanan/Documents/GW MS DS/Semester/Fall 2024/NLP/PycharmProjects/Medallion-Spark-Azure-DBT/medallion_dbt_spark/logs', 'debug': 'False', 'profiles_dir': '/Users/vaishnavitamilvanan/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt test', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:52:53.050692 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m09:52:53.051190 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m09:52:53.051414 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m09:52:54.059329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '886b2d4f-c060-4e92-abda-78e419d2aa43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x169c2b990>]}
[0m09:52:54.086096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '886b2d4f-c060-4e92-abda-78e419d2aa43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cb5910>]}
[0m09:52:54.086503 [info ] [MainThread]: Registered adapter: databricks=1.8.5
[0m09:52:54.108507 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m09:52:54.294604 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:52:54.294939 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:52:54.298811 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.medallion_dbt_spark.example
[0m09:52:54.329050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '886b2d4f-c060-4e92-abda-78e419d2aa43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x169d4c610>]}
[0m09:52:54.423911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '886b2d4f-c060-4e92-abda-78e419d2aa43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x16aac7f50>]}
[0m09:52:54.424285 [info ] [MainThread]: Found 7 snapshots, 3 models, 19 data tests, 9 sources, 590 macros
[0m09:52:54.424514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '886b2d4f-c060-4e92-abda-78e419d2aa43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x169d3c690>]}
[0m09:52:54.426021 [info ] [MainThread]: 
[0m09:52:54.426472 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=6084652240, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7054, 8194199360), compute-name=) - Creating connection
[0m09:52:54.426664 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m09:52:54.426845 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=6084652240, session-id=None, name=master, idle-time=1.9073486328125e-06s, acquire-count=1, language=None, thread-identifier=(7054, 8194199360), compute-name=) - Acquired connection on thread (7054, 8194199360), using default compute resource
[0m09:52:54.430808 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=None, name=list_hive_metastore_saleslt, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Creating connection
[0m09:52:54.431133 [debug] [ThreadPool]: Acquiring new databricks connection 'list_hive_metastore_saleslt'
[0m09:52:54.431322 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=None, name=list_hive_metastore_saleslt, idle-time=9.5367431640625e-07s, acquire-count=1, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource
[0m09:52:54.431527 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=None, name=list_hive_metastore_saleslt, idle-time=0.0002079010009765625s, acquire-count=1, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:54.431777 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=None, name=list_hive_metastore_saleslt, idle-time=0.0004417896270751953s, acquire-count=1, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:52:54.431962 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:52:54.432126 [debug] [ThreadPool]: On list_hive_metastore_saleslt: GetTables(database=hive_metastore, schema=saleslt, identifier=None)
[0m09:52:54.432277 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:52:54.921220 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_saleslt, idle-time=8.821487426757812e-06s, acquire-count=1, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Connection created
[0m09:52:54.922364 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:52:55.643659 [debug] [ThreadPool]: SQL status: OK in 1.210 seconds
[0m09:52:55.654992 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=844954a5-348a-430d-b1ce-eb44d120c746) - Closing cursor
[0m09:52:55.662945 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_saleslt, idle-time=0.7419998645782471s, acquire-count=1, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:55.663209 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_saleslt, idle-time=0.7422869205474854s, acquire-count=1, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:52:55.663406 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_saleslt, idle-time=0.7424907684326172s, acquire-count=1, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:55.663576 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_saleslt, idle-time=0.7426629066467285s, acquire-count=1, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:52:55.663733 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m09:52:55.663878 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:52:55.664035 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */

      select current_catalog()
  
[0m09:52:55.664367 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:52:55.949956 [debug] [ThreadPool]: SQL status: OK in 0.290 seconds
[0m09:52:55.953213 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=11c957d8-ebcd-4733-9e63-223fb0756d89) - Closing cursor
[0m09:52:55.957805 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_saleslt, idle-time=1.0368409156799316s, acquire-count=1, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:55.958081 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_saleslt, idle-time=1.0371630191802979s, acquire-count=1, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:52:55.958247 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:52:55.958418 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */
show views in `hive_metastore`.`saleslt`
  
[0m09:52:55.958610 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:52:56.357192 [debug] [ThreadPool]: SQL status: OK in 0.400 seconds
[0m09:52:56.361179 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=63bec890-eaa4-4ba6-a93c-a0dacfed5d2a) - Closing cursor
[0m09:52:56.361903 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_saleslt, idle-time=1.9073486328125e-06s, acquire-count=0, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:56.362619 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_saleslt, idle-time=0.0006999969482421875s, acquire-count=0, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:56.363822 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_hive_metastore_saleslt, now list_hive_metastore_snapshots)
[0m09:52:56.364034 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_snapshots, idle-time=0.0021419525146484375s, acquire-count=0, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named list_hive_metastore_saleslt
[0m09:52:56.364222 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_snapshots, idle-time=0.0023407936096191406s, acquire-count=1, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource
[0m09:52:56.364412 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_snapshots, idle-time=0.002537965774536133s, acquire-count=1, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:56.364585 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_snapshots, idle-time=0.002710103988647461s, acquire-count=1, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:52:56.364739 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:52:56.364899 [debug] [ThreadPool]: On list_hive_metastore_snapshots: GetTables(database=hive_metastore, schema=snapshots, identifier=None)
[0m09:52:56.365074 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:52:56.481858 [debug] [ThreadPool]: SQL status: OK in 0.120 seconds
[0m09:52:56.484784 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=ef9b256e-03d4-4e5f-beaf-ef8fa9b78ffb) - Closing cursor
[0m09:52:56.487035 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_snapshots, idle-time=0.1251368522644043s, acquire-count=1, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:56.487266 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_snapshots, idle-time=0.12538599967956543s, acquire-count=1, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:52:56.487434 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:52:56.487625 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */

      select current_catalog()
  
[0m09:52:56.487805 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:52:56.671255 [debug] [ThreadPool]: SQL status: OK in 0.180 seconds
[0m09:52:56.675760 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=c887ceda-ef74-4b8f-acde-b68a059bc03e) - Closing cursor
[0m09:52:56.678122 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_snapshots, idle-time=0.3161647319793701s, acquire-count=1, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:56.678655 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_snapshots, idle-time=0.3167250156402588s, acquire-count=1, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:52:56.679018 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:52:56.679234 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */
show views in `hive_metastore`.`snapshots`
  
[0m09:52:56.679427 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:52:57.071948 [debug] [ThreadPool]: SQL status: OK in 0.390 seconds
[0m09:52:57.076316 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=cbcd1951-5def-433a-b1b1-4b6c43e7ca37) - Closing cursor
[0m09:52:57.076967 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_snapshots, idle-time=1.9073486328125e-06s, acquire-count=0, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:57.078077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '886b2d4f-c060-4e92-abda-78e419d2aa43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x16ac18750>]}
[0m09:52:57.078491 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=6084652240, session-id=None, name=master, idle-time=2.651639938354492s, acquire-count=1, language=None, thread-identifier=(7054, 8194199360), compute-name=) - Checking idleness
[0m09:52:57.078679 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=6084652240, session-id=None, name=master, idle-time=2.651839017868042s, acquire-count=1, language=None, thread-identifier=(7054, 8194199360), compute-name=) - Retrieving connection
[0m09:52:57.078850 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=6084652240, session-id=None, name=master, idle-time=2.6520180702209473s, acquire-count=1, language=None, thread-identifier=(7054, 8194199360), compute-name=) - Checking idleness
[0m09:52:57.079012 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=6084652240, session-id=None, name=master, idle-time=2.6521780490875244s, acquire-count=1, language=None, thread-identifier=(7054, 8194199360), compute-name=) - Retrieving connection
[0m09:52:57.079169 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m09:52:57.079314 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m09:52:57.079475 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=6084652240, session-id=None, name=master, idle-time=9.5367431640625e-07s, acquire-count=0, language=None, thread-identifier=(7054, 8194199360), compute-name=) - Released connection
[0m09:52:57.079737 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:52:57.079952 [info ] [MainThread]: 
[0m09:52:57.083464 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:52:57.083748 [info ] [Thread-1 (]: 1 of 19 START test not_null_dim_sales_customerID ............................... [RUN]
[0m09:52:57.084085 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=list_hive_metastore_snapshots, idle-time=0.007100105285644531s, acquire-count=0, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:57.084357 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_hive_metastore_snapshots, now test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5)
[0m09:52:57.084694 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.007673978805541992s, acquire-count=0, language=None, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named list_hive_metastore_snapshots
[0m09:52:57.085041 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.00802302360534668s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:52:57.085424 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:52:57.097135 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"
[0m09:52:57.097769 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:52:57.107711 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"
[0m09:52:57.108277 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.031278133392333984s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:57.108534 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.03155183792114258s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:52:57.108695 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"
[0m09:52:57.108941 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customerID
from `hive_metastore`.`saleslt`.`dim_sales`
where customerID is null



      
    ) dbt_internal_test
[0m09:52:57.109180 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:52:57.379729 [debug] [Thread-1 (]: SQL status: OK in 0.270 seconds
[0m09:52:57.385697 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=bc585b94-b019-49f4-8c87-190846e69638) - Closing cursor
[0m09:52:57.389099 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:57.389620 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:57.390035 [info ] [Thread-1 (]: 1 of 19 PASS not_null_dim_sales_customerID ..................................... [[32mPASS[0m in 0.31s]
[0m09:52:57.390423 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:52:57.390700 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:52:57.390984 [info ] [Thread-1 (]: 2 of 19 START test not_null_dim_sales_freight .................................. [RUN]
[0m09:52:57.391322 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.0017430782318115234s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:57.391523 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, now test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131)
[0m09:52:57.391739 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.00215911865234375s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:52:57.391946 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.002373218536376953s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:52:57.392140 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:52:57.396639 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m09:52:57.397298 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:52:57.399186 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m09:52:57.399609 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.010018110275268555s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:57.399830 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.01026010513305664s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:52:57.399984 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m09:52:57.400199 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select freight
from `hive_metastore`.`saleslt`.`dim_sales`
where freight is null



      
    ) dbt_internal_test
[0m09:52:57.400437 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:52:57.891723 [debug] [Thread-1 (]: SQL status: OK in 0.490 seconds
[0m09:52:57.895656 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=44832eac-faff-4f91-90f1-ccff0b5e648c) - Closing cursor
[0m09:52:57.896618 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:57.897087 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:57.897390 [info ] [Thread-1 (]: 2 of 19 PASS not_null_dim_sales_freight ........................................ [[32mPASS[0m in 0.51s]
[0m09:52:57.897766 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:52:57.898017 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:52:57.898325 [info ] [Thread-1 (]: 3 of 19 START test not_null_dim_sales_lineTotal ................................ [RUN]
[0m09:52:57.898865 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.0017421245574951172s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:57.899137 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, now test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8)
[0m09:52:57.899449 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.002340078353881836s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:52:57.899753 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.0026459693908691406s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:52:57.900033 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:52:57.903992 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m09:52:57.904477 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:52:57.906032 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m09:52:57.906578 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.009446859359741211s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:57.906865 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.009796142578125s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:52:57.907024 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m09:52:57.907236 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select lineTotal
from `hive_metastore`.`saleslt`.`dim_sales`
where lineTotal is null



      
    ) dbt_internal_test
[0m09:52:57.907454 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:52:58.199991 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:52:58.202579 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=7ced0cca-a19a-4a4d-b362-94b8802a9fb7) - Closing cursor
[0m09:52:58.203263 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=1.6689300537109375e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:58.203651 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:58.204089 [info ] [Thread-1 (]: 3 of 19 PASS not_null_dim_sales_lineTotal ...................................... [[32mPASS[0m in 0.31s]
[0m09:52:58.204646 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:52:58.205047 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:52:58.205483 [info ] [Thread-1 (]: 4 of 19 START test not_null_dim_sales_listPrice ................................ [RUN]
[0m09:52:58.205934 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.0022962093353271484s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:58.206131 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, now test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f)
[0m09:52:58.206346 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.0027179718017578125s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:52:58.206567 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.002936124801635742s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:52:58.206759 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:52:58.210404 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m09:52:58.210869 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:52:58.212948 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m09:52:58.213495 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.009837150573730469s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:58.213788 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.01014399528503418s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:52:58.213993 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m09:52:58.214293 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select listPrice
from `hive_metastore`.`saleslt`.`dim_sales`
where listPrice is null



      
    ) dbt_internal_test
[0m09:52:58.214521 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:52:58.430751 [debug] [Thread-1 (]: SQL status: OK in 0.220 seconds
[0m09:52:58.436206 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=d302c230-03fa-44f8-8407-b34ad7a45f6c) - Closing cursor
[0m09:52:58.436825 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:58.437157 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:58.437440 [info ] [Thread-1 (]: 4 of 19 PASS not_null_dim_sales_listPrice ...................................... [[32mPASS[0m in 0.23s]
[0m09:52:58.437931 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:52:58.438180 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:52:58.438477 [info ] [Thread-1 (]: 5 of 19 START test not_null_dim_sales_name ..................................... [RUN]
[0m09:52:58.438852 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.0016858577728271484s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:58.439064 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, now test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77)
[0m09:52:58.439290 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0021321773529052734s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:52:58.439511 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.002354145050048828s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:52:58.439714 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:52:58.443638 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m09:52:58.444059 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:52:58.445577 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m09:52:58.446087 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.008899927139282227s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:58.446383 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.00921010971069336s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:52:58.446585 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m09:52:58.446799 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select name
from `hive_metastore`.`saleslt`.`dim_sales`
where name is null



      
    ) dbt_internal_test
[0m09:52:58.447002 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:52:58.814548 [debug] [Thread-1 (]: SQL status: OK in 0.370 seconds
[0m09:52:58.817588 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=4aee2928-d930-496f-83fe-ef950aaee869) - Closing cursor
[0m09:52:58.818209 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:58.818578 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:58.818926 [info ] [Thread-1 (]: 5 of 19 PASS not_null_dim_sales_name ........................................... [[32mPASS[0m in 0.38s]
[0m09:52:58.819411 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:52:58.819879 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:52:58.820367 [info ] [Thread-1 (]: 6 of 19 START test not_null_dim_sales_orderDate ................................ [RUN]
[0m09:52:58.821041 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.002360820770263672s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:58.821221 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, now test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3)
[0m09:52:58.821423 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0028526782989501953s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:52:58.821637 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0030629634857177734s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:52:58.821824 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:52:58.825458 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m09:52:58.825922 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:52:58.827679 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m09:52:58.828208 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.00960683822631836s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:58.828499 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.009909868240356445s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:52:58.828702 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m09:52:58.828986 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orderDate
from `hive_metastore`.`saleslt`.`dim_sales`
where orderDate is null



      
    ) dbt_internal_test
[0m09:52:58.829269 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:52:59.121330 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:52:59.124193 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=a3a741cc-3042-4e3d-a5b5-eb1c503818b2) - Closing cursor
[0m09:52:59.124722 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:59.125063 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:59.125352 [info ] [Thread-1 (]: 6 of 19 PASS not_null_dim_sales_orderDate ...................................... [[32mPASS[0m in 0.30s]
[0m09:52:59.125793 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:52:59.126035 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:52:59.126304 [info ] [Thread-1 (]: 7 of 19 START test not_null_dim_sales_orderQty ................................. [RUN]
[0m09:52:59.126657 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0015931129455566406s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:59.126849 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, now test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596)
[0m09:52:59.127072 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.0020051002502441406s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:52:59.127289 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.002231121063232422s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:52:59.127477 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:52:59.132852 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"
[0m09:52:59.133264 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:52:59.134992 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"
[0m09:52:59.135356 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.010290145874023438s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:59.135563 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.010511159896850586s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:52:59.135721 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"
[0m09:52:59.135926 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orderQty
from `hive_metastore`.`saleslt`.`dim_sales`
where orderQty is null



      
    ) dbt_internal_test
[0m09:52:59.136139 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:52:59.339582 [debug] [Thread-1 (]: SQL status: OK in 0.200 seconds
[0m09:52:59.344126 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=f9346360-e8bc-4705-91fa-51fa808a7439) - Closing cursor
[0m09:52:59.344723 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:59.345050 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:59.345325 [info ] [Thread-1 (]: 7 of 19 PASS not_null_dim_sales_orderQty ....................................... [[32mPASS[0m in 0.22s]
[0m09:52:59.345839 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:52:59.346322 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:52:59.346568 [info ] [Thread-1 (]: 8 of 19 START test not_null_dim_sales_productID ................................ [RUN]
[0m09:52:59.346958 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.0018830299377441406s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:59.347177 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, now test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890)
[0m09:52:59.347405 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0023529529571533203s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:52:59.347637 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0025870800018310547s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:52:59.347841 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:52:59.352067 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m09:52:59.352513 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:52:59.354316 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m09:52:59.354870 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.00978708267211914s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:59.355150 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.010104894638061523s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:52:59.355294 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m09:52:59.355510 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select productID
from `hive_metastore`.`saleslt`.`dim_sales`
where productID is null



      
    ) dbt_internal_test
[0m09:52:59.355707 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:52:59.555854 [debug] [Thread-1 (]: SQL status: OK in 0.200 seconds
[0m09:52:59.559621 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=3eb7a5bd-ef1e-48fc-8cd6-c918ed0718b6) - Closing cursor
[0m09:52:59.560300 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:59.560648 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:59.560931 [info ] [Thread-1 (]: 8 of 19 PASS not_null_dim_sales_productID ...................................... [[32mPASS[0m in 0.21s]
[0m09:52:59.561368 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:52:59.561662 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:52:59.561938 [info ] [Thread-1 (]: 9 of 19 START test not_null_dim_sales_productNumber ............................ [RUN]
[0m09:52:59.562313 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0016210079193115234s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:59.562605 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, now test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd)
[0m09:52:59.562943 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.002251863479614258s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:52:59.563283 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.002591848373413086s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:52:59.563585 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:52:59.567596 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m09:52:59.568011 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:52:59.569583 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m09:52:59.569965 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.00931096076965332s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:59.570228 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.00956583023071289s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:52:59.570433 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m09:52:59.570717 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select productNumber
from `hive_metastore`.`saleslt`.`dim_sales`
where productNumber is null



      
    ) dbt_internal_test
[0m09:52:59.570993 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:52:59.940732 [debug] [Thread-1 (]: SQL status: OK in 0.370 seconds
[0m09:52:59.944378 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=4f1c28e3-826b-4af3-8dab-fb1e32e6b8f1) - Closing cursor
[0m09:52:59.945272 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=4.291534423828125e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:59.945953 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:52:59.946477 [info ] [Thread-1 (]: 9 of 19 PASS not_null_dim_sales_productNumber .................................. [[32mPASS[0m in 0.38s]
[0m09:52:59.947054 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:52:59.947354 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:52:59.947561 [info ] [Thread-1 (]: 10 of 19 START test not_null_dim_sales_saleOrderDetailID ....................... [RUN]
[0m09:52:59.947976 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.0020868778228759766s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:59.948188 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, now test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a)
[0m09:52:59.948435 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.002560138702392578s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:52:59.948694 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.0027790069580078125s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:52:59.949015 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:52:59.953106 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"
[0m09:52:59.953542 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:52:59.955095 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"
[0m09:52:59.955507 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.009615898132324219s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:52:59.955716 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.009853124618530273s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:52:59.955862 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"
[0m09:52:59.956066 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderDetailID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is null



      
    ) dbt_internal_test
[0m09:52:59.956269 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:53:00.062086 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Closing cursor
[0m09:53:00.063479 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderDetailID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is null



      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=4fd7718a-edac-446a-8e54-1caebf61cf89
[0m09:53:00.064481 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:00.073769 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
[0m09:53:00.074293 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=4.0531158447265625e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:00.074708 [error] [Thread-1 (]: 10 of 19 ERROR not_null_dim_sales_saleOrderDetailID ............................ [[31mERROR[0m in 0.13s]
[0m09:53:00.075126 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:53:00.075372 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:53:00.075665 [info ] [Thread-1 (]: 11 of 19 START test not_null_dim_sales_saleOrderID ............................. [RUN]
[0m09:53:00.075989 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.0017540454864501953s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:53:00.076174 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, now test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3)
[0m09:53:00.076390 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.0021600723266601562s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:53:00.076617 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.002396106719970703s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:53:00.076828 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:53:00.079937 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"
[0m09:53:00.080400 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:53:00.082402 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"
[0m09:53:00.082949 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.008697032928466797s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:53:00.083252 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.009006977081298828s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:53:00.083451 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"
[0m09:53:00.083678 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is null



      
    ) dbt_internal_test
[0m09:53:00.083878 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:53:00.241247 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Closing cursor
[0m09:53:00.242698 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is null



      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=7d6f027e-4fb2-404a-8e16-19e37f4a7148
[0m09:53:00.243702 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=3.0994415283203125e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:00.245726 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
[0m09:53:00.246045 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:00.246319 [error] [Thread-1 (]: 11 of 19 ERROR not_null_dim_sales_saleOrderID .................................. [[31mERROR[0m in 0.17s]
[0m09:53:00.246664 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:53:00.247067 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:53:00.247639 [info ] [Thread-1 (]: 12 of 19 START test not_null_dim_sales_sellStartDate ........................... [RUN]
[0m09:53:00.248391 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.0022509098052978516s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:53:00.248807 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, now test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118)
[0m09:53:00.249159 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.003117084503173828s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:53:00.249377 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0033431053161621094s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:53:00.249575 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:53:00.255548 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m09:53:00.256043 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:53:00.257779 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m09:53:00.258556 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.012484073638916016s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:53:00.258904 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.012840032577514648s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:53:00.259136 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m09:53:00.259454 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select sellStartDate
from `hive_metastore`.`saleslt`.`dim_sales`
where sellStartDate is null



      
    ) dbt_internal_test
[0m09:53:00.259755 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:53:00.459886 [debug] [Thread-1 (]: SQL status: OK in 0.200 seconds
[0m09:53:00.462804 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=ad007efb-b21e-44f4-94b6-bfbdf93174d9) - Closing cursor
[0m09:53:00.463353 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:00.463669 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:00.463948 [info ] [Thread-1 (]: 12 of 19 PASS not_null_dim_sales_sellStartDate ................................. [[32mPASS[0m in 0.22s]
[0m09:53:00.464279 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:53:00.464515 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:53:00.464791 [info ] [Thread-1 (]: 13 of 19 START test not_null_dim_sales_standardCost ............................ [RUN]
[0m09:53:00.465254 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.001542806625366211s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:53:00.465528 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, now test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3)
[0m09:53:00.465814 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0021126270294189453s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:53:00.466109 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0024077892303466797s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:53:00.466380 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:53:00.469925 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m09:53:00.470524 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:53:00.472237 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m09:53:00.472731 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.009044885635375977s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:53:00.472987 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.009305715560913086s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:53:00.473169 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m09:53:00.473430 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select standardCost
from `hive_metastore`.`saleslt`.`dim_sales`
where standardCost is null



      
    ) dbt_internal_test
[0m09:53:00.473705 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:53:00.677313 [debug] [Thread-1 (]: SQL status: OK in 0.200 seconds
[0m09:53:00.682144 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=fee9c7b8-022e-412a-b6e2-dd66f0239ed0) - Closing cursor
[0m09:53:00.682774 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:00.683107 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:00.683363 [info ] [Thread-1 (]: 13 of 19 PASS not_null_dim_sales_standardCost .................................. [[32mPASS[0m in 0.22s]
[0m09:53:00.683909 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:53:00.684370 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:53:00.684650 [info ] [Thread-1 (]: 14 of 19 START test not_null_dim_sales_subTotal ................................ [RUN]
[0m09:53:00.684988 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.001878976821899414s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:53:00.685173 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, now test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487)
[0m09:53:00.685394 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.0022881031036376953s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:53:00.685710 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.0025560855865478516s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:53:00.686028 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:53:00.690113 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m09:53:00.690534 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:53:00.695804 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m09:53:00.697859 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.01449894905090332s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:53:00.698702 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.015464067459106445s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:53:00.699114 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m09:53:00.700154 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select subTotal
from `hive_metastore`.`saleslt`.`dim_sales`
where subTotal is null



      
    ) dbt_internal_test
[0m09:53:00.701121 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:53:00.967135 [debug] [Thread-1 (]: SQL status: OK in 0.270 seconds
[0m09:53:00.971882 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=3b52cbb8-0fef-4d30-8431-59cdab58ba89) - Closing cursor
[0m09:53:00.972595 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:00.972953 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:00.973475 [info ] [Thread-1 (]: 14 of 19 PASS not_null_dim_sales_subTotal ...................................... [[32mPASS[0m in 0.29s]
[0m09:53:00.974107 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:53:00.974574 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:53:00.974846 [info ] [Thread-1 (]: 15 of 19 START test not_null_dim_sales_taxAmt .................................. [RUN]
[0m09:53:00.975228 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.0022542476654052734s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:53:00.975454 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, now test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a)
[0m09:53:00.975704 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.0027480125427246094s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:53:00.975923 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.002978086471557617s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:53:00.976113 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:53:00.979339 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m09:53:00.979958 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:53:00.982334 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m09:53:00.983055 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.010067939758300781s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:53:00.983381 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.010418891906738281s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:53:00.983539 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m09:53:00.983743 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select taxAmt
from `hive_metastore`.`saleslt`.`dim_sales`
where taxAmt is null



      
    ) dbt_internal_test
[0m09:53:00.983962 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:53:01.273101 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:53:01.275706 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=2c0b3c17-0ddd-4562-add6-984b4f2673d6) - Closing cursor
[0m09:53:01.276242 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:01.276610 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:01.276901 [info ] [Thread-1 (]: 15 of 19 PASS not_null_dim_sales_taxAmt ........................................ [[32mPASS[0m in 0.30s]
[0m09:53:01.277249 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:53:01.277487 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:53:01.277820 [info ] [Thread-1 (]: 16 of 19 START test not_null_dim_sales_totalDue ................................ [RUN]
[0m09:53:01.278240 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.0016307830810546875s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:53:01.278488 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, now test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023)
[0m09:53:01.278778 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.002167940139770508s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:53:01.279094 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.002488851547241211s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:53:01.279354 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:53:01.282769 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m09:53:01.283342 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:53:01.285447 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m09:53:01.286013 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.009398937225341797s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:53:01.286266 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.009680032730102539s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:53:01.286463 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m09:53:01.286717 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select totalDue
from `hive_metastore`.`saleslt`.`dim_sales`
where totalDue is null



      
    ) dbt_internal_test
[0m09:53:01.286972 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:53:01.517897 [debug] [Thread-1 (]: SQL status: OK in 0.230 seconds
[0m09:53:01.521096 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=0a551a8e-f461-4c4e-8824-f341332a5cb4) - Closing cursor
[0m09:53:01.521868 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=2.86102294921875e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:01.522466 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:01.522971 [info ] [Thread-1 (]: 16 of 19 PASS not_null_dim_sales_totalDue ...................................... [[32mPASS[0m in 0.24s]
[0m09:53:01.523513 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:53:01.523784 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:53:01.524037 [info ] [Thread-1 (]: 17 of 19 START test not_null_dim_sales_unitPrice ............................... [RUN]
[0m09:53:01.524331 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.001940011978149414s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:53:01.524503 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, now test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a)
[0m09:53:01.524706 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.002315044403076172s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:53:01.524916 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.002521038055419922s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:53:01.525103 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:53:01.531182 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m09:53:01.531843 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:53:01.533563 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m09:53:01.534160 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.011662006378173828s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:53:01.534595 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.012163162231445312s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:53:01.534890 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m09:53:01.535218 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select unitPrice
from `hive_metastore`.`saleslt`.`dim_sales`
where unitPrice is null



      
    ) dbt_internal_test
[0m09:53:01.535514 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:53:01.783055 [debug] [Thread-1 (]: SQL status: OK in 0.250 seconds
[0m09:53:01.785921 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=c5ca6323-fd39-4d94-82db-fca336d996b5) - Closing cursor
[0m09:53:01.786437 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=7.152557373046875e-07s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:01.786745 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:01.787010 [info ] [Thread-1 (]: 17 of 19 PASS not_null_dim_sales_unitPrice ..................................... [[32mPASS[0m in 0.26s]
[0m09:53:01.787370 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:53:01.787607 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:53:01.787856 [info ] [Thread-1 (]: 18 of 19 START test unique_dim_sales_saleOrderDetailID ......................... [RUN]
[0m09:53:01.788333 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.0015301704406738281s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:53:01.788617 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, now test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405)
[0m09:53:01.788955 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.002165079116821289s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:53:01.789292 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.0025031566619873047s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:53:01.789595 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:53:01.794950 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"
[0m09:53:01.795404 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:53:01.797080 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"
[0m09:53:01.797498 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.010735273361206055s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:53:01.797720 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.010981082916259766s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:53:01.798050 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"
[0m09:53:01.798315 [debug] [Thread-1 (]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderDetailID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is not null
group by saleOrderDetailID
having count(*) > 1



      
    ) dbt_internal_test
[0m09:53:01.798555 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:53:01.913842 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Closing cursor
[0m09:53:01.915497 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderDetailID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is not null
group by saleOrderDetailID
having count(*) > 1



      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=3cb7d1a4-9712-4823-a51e-d36abe4d3926
[0m09:53:01.916620 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=1.5974044799804688e-05s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:01.920808 [debug] [Thread-1 (]: Runtime Error in test unique_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
[0m09:53:01.921284 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=2.86102294921875e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:01.921577 [error] [Thread-1 (]: 18 of 19 ERROR unique_dim_sales_saleOrderDetailID .............................. [[31mERROR[0m in 0.13s]
[0m09:53:01.921944 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:53:01.922184 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:53:01.922590 [info ] [Thread-1 (]: 19 of 19 START test unique_dim_sales_saleOrderID ............................... [RUN]
[0m09:53:01.923229 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.0018990039825439453s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:53:01.923538 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, now test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c)
[0m09:53:01.923863 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.0025899410247802734s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:53:01.924084 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.0028188228607177734s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Acquired connection on thread (7054, 6196932608), using default compute resource for model 'None'
[0m09:53:01.924288 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:53:01.927536 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"
[0m09:53:01.928180 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:53:01.930039 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"
[0m09:53:01.930627 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.009326934814453125s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Checking idleness
[0m09:53:01.930946 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.009656906127929688s, acquire-count=1, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Retrieving connection
[0m09:53:01.931150 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"
[0m09:53:01.931467 [debug] [Thread-1 (]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is not null
group by saleOrderID
having count(*) > 1



      
    ) dbt_internal_test
[0m09:53:01.931761 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Created cursor
[0m09:53:02.090699 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, command-id=Unknown) - Closing cursor
[0m09:53:02.092097 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is not null
group by saleOrderID
having count(*) > 1



      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=9c3f23ed-5bdb-4660-9579-9cd116e62fc4
[0m09:53:02.093115 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=1.3828277587890625e-05s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:02.096202 [debug] [Thread-1 (]: Runtime Error in test unique_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
[0m09:53:02.096618 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=6070453904, session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7054, 6196932608), compute-name=) - Released connection
[0m09:53:02.096901 [error] [Thread-1 (]: 19 of 19 ERROR unique_dim_sales_saleOrderID .................................... [[31mERROR[0m in 0.17s]
[0m09:53:02.097263 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:53:02.098385 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=6084652240, session-id=None, name=master, idle-time=5.018882989883423s, acquire-count=0, language=None, thread-identifier=(7054, 8194199360), compute-name=) - Checking idleness
[0m09:53:02.098758 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=6084652240, session-id=None, name=master, idle-time=5.019241809844971s, acquire-count=0, language=None, thread-identifier=(7054, 8194199360), compute-name=) - Reusing connection previously named master
[0m09:53:02.099051 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=6084652240, session-id=None, name=master, idle-time=5.019547700881958s, acquire-count=1, language=None, thread-identifier=(7054, 8194199360), compute-name=) - Acquired connection on thread (7054, 8194199360), using default compute resource
[0m09:53:02.099353 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=6084652240, session-id=None, name=master, idle-time=5.01986289024353s, acquire-count=1, language=None, thread-identifier=(7054, 8194199360), compute-name=) - Checking idleness
[0m09:53:02.099640 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=6084652240, session-id=None, name=master, idle-time=5.020144701004028s, acquire-count=1, language=None, thread-identifier=(7054, 8194199360), compute-name=) - Retrieving connection
[0m09:53:02.099887 [debug] [MainThread]: On master: ROLLBACK
[0m09:53:02.100131 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:53:02.273427 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=6084652240, session-id=6cf388f4-00dd-48ad-8fcd-cd3fcbcfc112, name=master, idle-time=1.9073486328125e-06s, acquire-count=1, language=None, thread-identifier=(7054, 8194199360), compute-name=) - Connection created
[0m09:53:02.273723 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:53:02.273924 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=6084652240, session-id=6cf388f4-00dd-48ad-8fcd-cd3fcbcfc112, name=master, idle-time=0.0005469322204589844s, acquire-count=1, language=None, thread-identifier=(7054, 8194199360), compute-name=) - Checking idleness
[0m09:53:02.274101 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=6084652240, session-id=6cf388f4-00dd-48ad-8fcd-cd3fcbcfc112, name=master, idle-time=0.0007259845733642578s, acquire-count=1, language=None, thread-identifier=(7054, 8194199360), compute-name=) - Retrieving connection
[0m09:53:02.274254 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m09:53:02.274400 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m09:53:02.274557 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=6084652240, session-id=6cf388f4-00dd-48ad-8fcd-cd3fcbcfc112, name=master, idle-time=9.5367431640625e-07s, acquire-count=0, language=None, thread-identifier=(7054, 8194199360), compute-name=) - Released connection
[0m09:53:02.274802 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:53:02.275005 [debug] [MainThread]: On master: ROLLBACK
[0m09:53:02.275204 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:53:02.275359 [debug] [MainThread]: On master: Close
[0m09:53:02.275530 [debug] [MainThread]: Databricks adapter: Connection(session-id=6cf388f4-00dd-48ad-8fcd-cd3fcbcfc112) - Closing connection
[0m09:53:02.334287 [debug] [MainThread]: Connection 'test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c' was properly closed.
[0m09:53:02.335110 [debug] [MainThread]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c: ROLLBACK
[0m09:53:02.335524 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:53:02.335838 [debug] [MainThread]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c: Close
[0m09:53:02.336174 [debug] [MainThread]: Databricks adapter: Connection(session-id=e3d6d582-9d98-44ed-8931-980b95c91c6e) - Closing connection
[0m09:53:02.412462 [info ] [MainThread]: 
[0m09:53:02.413082 [info ] [MainThread]: Finished running 19 data tests in 0 hours 0 minutes and 7.99 seconds (7.99s).
[0m09:53:02.416106 [debug] [MainThread]: Command end result
[0m09:53:02.451078 [info ] [MainThread]: 
[0m09:53:02.451349 [info ] [MainThread]: [31mCompleted with 4 errors and 0 warnings:[0m
[0m09:53:02.451521 [info ] [MainThread]: 
[0m09:53:02.451727 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
[0m09:53:02.451894 [info ] [MainThread]: 
[0m09:53:02.452096 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
[0m09:53:02.452255 [info ] [MainThread]: 
[0m09:53:02.452443 [error] [MainThread]:   Runtime Error in test unique_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
[0m09:53:02.452606 [info ] [MainThread]: 
[0m09:53:02.452793 [error] [MainThread]:   Runtime Error in test unique_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
[0m09:53:02.452958 [info ] [MainThread]: 
[0m09:53:02.453120 [info ] [MainThread]: Done. PASS=15 WARN=0 ERROR=4 SKIP=0 TOTAL=19
[0m09:53:02.455743 [debug] [MainThread]: Resource report: {"command_name": "test", "command_wall_clock_time": 9.547475, "process_user_time": 2.81573, "process_kernel_time": 2.280606, "process_mem_max_rss": "223985664", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:53:02.456174 [debug] [MainThread]: Command `dbt test` failed at 09:53:02.456114 after 9.55 seconds
[0m09:53:02.456430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c57e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cadc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106caf490>]}
[0m09:53:02.456699 [debug] [MainThread]: Flushing usage events
[0m09:55:37.269931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10725de90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072c4b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072c5450>]}


============================== 09:55:37.273633 | 7b8e80b5-3cc3-493f-93b1-8e9a50c59fb3 ==============================
[0m09:55:37.273633 [info ] [MainThread]: Running with dbt=1.8.5
[0m09:55:37.274157 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/vaishnavitamilvanan/Documents/GW MS DS/Semester/Fall 2024/NLP/PycharmProjects/Medallion-Spark-Azure-DBT/medallion_dbt_spark/logs', 'profiles_dir': '/Users/vaishnavitamilvanan/.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt test', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:55:37.334870 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m09:55:37.335387 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m09:55:37.335613 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m09:55:38.346600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7b8e80b5-3cc3-493f-93b1-8e9a50c59fb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x15269a5d0>]}
[0m09:55:38.373422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7b8e80b5-3cc3-493f-93b1-8e9a50c59fb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x152716090>]}
[0m09:55:38.373836 [info ] [MainThread]: Registered adapter: databricks=1.8.5
[0m09:55:38.394243 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m09:55:38.588671 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:55:38.589037 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:55:38.593297 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.medallion_dbt_spark.example
[0m09:55:38.624065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7b8e80b5-3cc3-493f-93b1-8e9a50c59fb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x152986b90>]}
[0m09:55:38.721742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7b8e80b5-3cc3-493f-93b1-8e9a50c59fb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x152ec7c90>]}
[0m09:55:38.722197 [info ] [MainThread]: Found 7 snapshots, 3 models, 19 data tests, 9 sources, 590 macros
[0m09:55:38.722465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7b8e80b5-3cc3-493f-93b1-8e9a50c59fb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x152964110>]}
[0m09:55:38.724038 [info ] [MainThread]: 
[0m09:55:38.724514 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5681373200, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7101, 8194199360), compute-name=) - Creating connection
[0m09:55:38.724697 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m09:55:38.724873 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5681373200, session-id=None, name=master, idle-time=2.1457672119140625e-06s, acquire-count=1, language=None, thread-identifier=(7101, 8194199360), compute-name=) - Acquired connection on thread (7101, 8194199360), using default compute resource
[0m09:55:38.728910 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=None, name=list_hive_metastore_saleslt, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Creating connection
[0m09:55:38.729286 [debug] [ThreadPool]: Acquiring new databricks connection 'list_hive_metastore_saleslt'
[0m09:55:38.729541 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=None, name=list_hive_metastore_saleslt, idle-time=9.5367431640625e-07s, acquire-count=1, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource
[0m09:55:38.729804 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=None, name=list_hive_metastore_saleslt, idle-time=0.0002758502960205078s, acquire-count=1, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:38.729996 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=None, name=list_hive_metastore_saleslt, idle-time=0.0004837512969970703s, acquire-count=1, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:38.730155 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:55:38.730319 [debug] [ThreadPool]: On list_hive_metastore_saleslt: GetTables(database=hive_metastore, schema=saleslt, identifier=None)
[0m09:55:38.730467 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:55:39.059367 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_saleslt, idle-time=1.5020370483398438e-05s, acquire-count=1, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Connection created
[0m09:55:39.060483 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:39.362954 [debug] [ThreadPool]: SQL status: OK in 0.630 seconds
[0m09:55:39.373432 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=217cc9c6-1ed8-482b-a491-2d453962209a) - Closing cursor
[0m09:55:39.383370 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_saleslt, idle-time=0.32428503036499023s, acquire-count=1, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:39.383622 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_saleslt, idle-time=0.32456111907958984s, acquire-count=1, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:39.383826 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_saleslt, idle-time=0.3247721195220947s, acquire-count=1, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:39.384005 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_saleslt, idle-time=0.3249549865722656s, acquire-count=1, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:39.384157 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m09:55:39.384289 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:55:39.384446 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */

      select current_catalog()
  
[0m09:55:39.384610 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:39.491004 [debug] [ThreadPool]: SQL status: OK in 0.110 seconds
[0m09:55:39.492464 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=12097fcb-e16a-4db9-8ea8-82a969e69a8c) - Closing cursor
[0m09:55:39.496132 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_saleslt, idle-time=0.43706321716308594s, acquire-count=1, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:39.496355 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_saleslt, idle-time=0.437298059463501s, acquire-count=1, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:39.496516 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:55:39.496682 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */
show views in `hive_metastore`.`saleslt`
  
[0m09:55:39.496854 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:39.862200 [debug] [ThreadPool]: SQL status: OK in 0.370 seconds
[0m09:55:39.865084 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=e8852eca-87a7-4dac-8d86-ab93b594139d) - Closing cursor
[0m09:55:39.865885 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_saleslt, idle-time=2.86102294921875e-06s, acquire-count=0, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:39.866305 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_saleslt, idle-time=0.0004329681396484375s, acquire-count=0, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:39.868096 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_hive_metastore_saleslt, now list_hive_metastore_snapshots)
[0m09:55:39.868460 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_snapshots, idle-time=0.002541780471801758s, acquire-count=0, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named list_hive_metastore_saleslt
[0m09:55:39.868708 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_snapshots, idle-time=0.0028378963470458984s, acquire-count=1, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource
[0m09:55:39.868902 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_snapshots, idle-time=0.0030357837677001953s, acquire-count=1, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:39.869076 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_snapshots, idle-time=0.0032129287719726562s, acquire-count=1, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:39.869224 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:55:39.869376 [debug] [ThreadPool]: On list_hive_metastore_snapshots: GetTables(database=hive_metastore, schema=snapshots, identifier=None)
[0m09:55:39.869548 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:39.975481 [debug] [ThreadPool]: SQL status: OK in 0.110 seconds
[0m09:55:39.977755 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=304d9855-b8d9-4a99-b557-ac9e1c7e0972) - Closing cursor
[0m09:55:39.979486 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_snapshots, idle-time=0.11360478401184082s, acquire-count=1, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:39.979712 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_snapshots, idle-time=0.11384201049804688s, acquire-count=1, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:39.979875 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:55:39.980044 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */

      select current_catalog()
  
[0m09:55:39.980222 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:40.188160 [debug] [ThreadPool]: SQL status: OK in 0.210 seconds
[0m09:55:40.189961 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=324d58da-451c-4761-89a2-ca60ab08081b) - Closing cursor
[0m09:55:40.191924 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_snapshots, idle-time=0.3260350227355957s, acquire-count=1, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:40.192125 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_snapshots, idle-time=0.32625889778137207s, acquire-count=1, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:40.192284 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:55:40.192449 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */
show views in `hive_metastore`.`snapshots`
  
[0m09:55:40.192619 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:40.369957 [debug] [ThreadPool]: SQL status: OK in 0.180 seconds
[0m09:55:40.373367 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=e9f7f374-6007-42c7-8de6-862e65e67f40) - Closing cursor
[0m09:55:40.373915 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_snapshots, idle-time=2.1457672119140625e-06s, acquire-count=0, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:40.375374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7b8e80b5-3cc3-493f-93b1-8e9a50c59fb3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072ea8d0>]}
[0m09:55:40.376009 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5681373200, session-id=None, name=master, idle-time=1.6510882377624512s, acquire-count=1, language=None, thread-identifier=(7101, 8194199360), compute-name=) - Checking idleness
[0m09:55:40.376402 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5681373200, session-id=None, name=master, idle-time=1.6514952182769775s, acquire-count=1, language=None, thread-identifier=(7101, 8194199360), compute-name=) - Retrieving connection
[0m09:55:40.376656 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5681373200, session-id=None, name=master, idle-time=1.6517951488494873s, acquire-count=1, language=None, thread-identifier=(7101, 8194199360), compute-name=) - Checking idleness
[0m09:55:40.376819 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5681373200, session-id=None, name=master, idle-time=1.6519591808319092s, acquire-count=1, language=None, thread-identifier=(7101, 8194199360), compute-name=) - Retrieving connection
[0m09:55:40.376971 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m09:55:40.377115 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m09:55:40.377275 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5681373200, session-id=None, name=master, idle-time=2.1457672119140625e-06s, acquire-count=0, language=None, thread-identifier=(7101, 8194199360), compute-name=) - Released connection
[0m09:55:40.377523 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:55:40.377714 [info ] [MainThread]: 
[0m09:55:40.380627 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:55:40.380883 [info ] [Thread-1 (]: 1 of 19 START test not_null_dim_sales_customerID ............................... [RUN]
[0m09:55:40.381214 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=list_hive_metastore_snapshots, idle-time=0.007277011871337891s, acquire-count=0, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:40.381416 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_hive_metastore_snapshots, now test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5)
[0m09:55:40.381619 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.007689952850341797s, acquire-count=0, language=None, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named list_hive_metastore_snapshots
[0m09:55:40.381824 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.00789785385131836s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:40.382009 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:55:40.395157 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"
[0m09:55:40.395792 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:55:40.405484 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"
[0m09:55:40.406044 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.03210091590881348s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:40.406286 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.03235316276550293s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:40.406471 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"
[0m09:55:40.406722 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customerID
from `hive_metastore`.`saleslt`.`dim_sales`
where customerID is null



      
    ) dbt_internal_test
[0m09:55:40.406977 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:40.680502 [debug] [Thread-1 (]: SQL status: OK in 0.270 seconds
[0m09:55:40.684638 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=c5468e9e-4399-4be1-af14-d7109a72b185) - Closing cursor
[0m09:55:40.687791 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:40.688207 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:40.688535 [info ] [Thread-1 (]: 1 of 19 PASS not_null_dim_sales_customerID ..................................... [[32mPASS[0m in 0.31s]
[0m09:55:40.688928 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:55:40.689247 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:55:40.689652 [info ] [Thread-1 (]: 2 of 19 START test not_null_dim_sales_freight .................................. [RUN]
[0m09:55:40.690094 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.0019021034240722656s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:40.690294 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, now test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131)
[0m09:55:40.690509 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.002315998077392578s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:55:40.690726 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.0025391578674316406s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:40.690913 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:55:40.696044 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m09:55:40.696537 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:55:40.698331 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m09:55:40.698803 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.010604143142700195s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:40.699044 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.010859012603759766s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:40.699207 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m09:55:40.699420 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select freight
from `hive_metastore`.`saleslt`.`dim_sales`
where freight is null



      
    ) dbt_internal_test
[0m09:55:40.699639 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:40.988493 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:55:40.993256 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=4bed4e9a-6fa6-4787-a1f2-3abfd1225957) - Closing cursor
[0m09:55:40.994058 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=7.867813110351562e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:40.994740 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:40.995082 [info ] [Thread-1 (]: 2 of 19 PASS not_null_dim_sales_freight ........................................ [[32mPASS[0m in 0.30s]
[0m09:55:40.995445 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:55:40.995707 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:55:40.995976 [info ] [Thread-1 (]: 3 of 19 START test not_null_dim_sales_lineTotal ................................ [RUN]
[0m09:55:40.996291 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.0016639232635498047s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:40.996490 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, now test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8)
[0m09:55:40.996704 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.0020751953125s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:55:40.996919 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.002292156219482422s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:40.997105 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:55:41.001165 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m09:55:41.001792 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:55:41.004315 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m09:55:41.005363 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.010718822479248047s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:41.005649 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.01099705696105957s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:41.005876 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m09:55:41.006264 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select lineTotal
from `hive_metastore`.`saleslt`.`dim_sales`
where lineTotal is null



      
    ) dbt_internal_test
[0m09:55:41.006487 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:41.296437 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:55:41.300518 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=0b5986e1-a6b5-40f2-862c-b44c812dab57) - Closing cursor
[0m09:55:41.301119 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:41.301497 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:41.301787 [info ] [Thread-1 (]: 3 of 19 PASS not_null_dim_sales_lineTotal ...................................... [[32mPASS[0m in 0.31s]
[0m09:55:41.302141 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:55:41.302472 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:55:41.302801 [info ] [Thread-1 (]: 4 of 19 START test not_null_dim_sales_listPrice ................................ [RUN]
[0m09:55:41.303169 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.001676797866821289s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:41.303488 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, now test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f)
[0m09:55:41.303835 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.0022988319396972656s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:55:41.304187 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.0026569366455078125s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:41.304519 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:55:41.308531 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m09:55:41.309001 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:55:41.310740 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m09:55:41.311183 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.009660005569458008s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:41.311473 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.009968996047973633s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:41.311684 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m09:55:41.311965 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select listPrice
from `hive_metastore`.`saleslt`.`dim_sales`
where listPrice is null



      
    ) dbt_internal_test
[0m09:55:41.312256 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:41.601344 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:55:41.605572 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=a52e8464-fe5e-45c6-b0de-ff79aacc4807) - Closing cursor
[0m09:55:41.606806 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=2.86102294921875e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:41.607359 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:41.607696 [info ] [Thread-1 (]: 4 of 19 PASS not_null_dim_sales_listPrice ...................................... [[32mPASS[0m in 0.30s]
[0m09:55:41.608103 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:55:41.608381 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:55:41.608721 [info ] [Thread-1 (]: 5 of 19 START test not_null_dim_sales_name ..................................... [RUN]
[0m09:55:41.609105 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.001737833023071289s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:41.609393 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, now test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77)
[0m09:55:41.609755 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0023488998413085938s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:55:41.610095 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0027370452880859375s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:41.610296 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:55:41.613962 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m09:55:41.614713 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:55:41.616601 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m09:55:41.617018 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.009652853012084961s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:41.617319 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.009943008422851562s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:41.617531 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m09:55:41.617818 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select name
from `hive_metastore`.`saleslt`.`dim_sales`
where name is null



      
    ) dbt_internal_test
[0m09:55:41.618097 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:41.914003 [debug] [Thread-1 (]: SQL status: OK in 0.300 seconds
[0m09:55:41.918041 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=6010494d-e851-43ec-b634-fe769976ca16) - Closing cursor
[0m09:55:41.918808 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=3.0994415283203125e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:41.919495 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:41.920015 [info ] [Thread-1 (]: 5 of 19 PASS not_null_dim_sales_name ........................................... [[32mPASS[0m in 0.31s]
[0m09:55:41.920588 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:55:41.920851 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:55:41.921060 [info ] [Thread-1 (]: 6 of 19 START test not_null_dim_sales_orderDate ................................ [RUN]
[0m09:55:41.921437 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0019989013671875s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:41.921667 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, now test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3)
[0m09:55:41.921895 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0024640560150146484s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:55:41.922120 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.002692699432373047s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:41.922325 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:55:41.925853 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m09:55:41.926532 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:55:41.928982 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m09:55:41.929441 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.010019779205322266s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:41.929642 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.010228872299194336s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:41.929788 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m09:55:41.929993 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orderDate
from `hive_metastore`.`saleslt`.`dim_sales`
where orderDate is null



      
    ) dbt_internal_test
[0m09:55:41.930196 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:42.320425 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m09:55:42.323336 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=9a3f5b2e-307f-4a60-9177-97df482565cf) - Closing cursor
[0m09:55:42.323896 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:42.324239 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:42.324536 [info ] [Thread-1 (]: 6 of 19 PASS not_null_dim_sales_orderDate ...................................... [[32mPASS[0m in 0.40s]
[0m09:55:42.324889 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:55:42.325225 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:55:42.325695 [info ] [Thread-1 (]: 7 of 19 START test not_null_dim_sales_orderQty ................................. [RUN]
[0m09:55:42.326248 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0019481182098388672s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:42.326566 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, now test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596)
[0m09:55:42.326903 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.002629995346069336s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:55:42.327136 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.002897024154663086s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:42.327324 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:55:42.332377 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"
[0m09:55:42.332814 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:55:42.334811 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"
[0m09:55:42.335326 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.011049985885620117s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:42.335692 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.011412858963012695s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:42.335938 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"
[0m09:55:42.336238 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orderQty
from `hive_metastore`.`saleslt`.`dim_sales`
where orderQty is null



      
    ) dbt_internal_test
[0m09:55:42.336477 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:42.626384 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:55:42.629709 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=fedd9e17-24d1-4a41-956c-d977a7f2807e) - Closing cursor
[0m09:55:42.630622 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=5.245208740234375e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:42.631260 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:42.631707 [info ] [Thread-1 (]: 7 of 19 PASS not_null_dim_sales_orderQty ....................................... [[32mPASS[0m in 0.31s]
[0m09:55:42.632047 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:55:42.632303 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:55:42.632516 [info ] [Thread-1 (]: 8 of 19 START test not_null_dim_sales_productID ................................ [RUN]
[0m09:55:42.632892 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.0016880035400390625s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:42.633097 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, now test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890)
[0m09:55:42.633312 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0021200180053710938s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:55:42.633529 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0023360252380371094s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:42.633742 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:55:42.637648 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m09:55:42.638197 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:55:42.640262 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m09:55:42.640633 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.009443998336791992s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:42.640839 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.009652137756347656s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:42.640992 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m09:55:42.641195 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select productID
from `hive_metastore`.`saleslt`.`dim_sales`
where productID is null



      
    ) dbt_internal_test
[0m09:55:42.641412 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:42.933681 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:55:42.938153 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=1bb2719d-69dd-4565-acdd-e8881192e656) - Closing cursor
[0m09:55:42.938903 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=7.152557373046875e-07s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:42.939442 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=7.152557373046875e-07s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:42.939724 [info ] [Thread-1 (]: 8 of 19 PASS not_null_dim_sales_productID ...................................... [[32mPASS[0m in 0.31s]
[0m09:55:42.940068 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:55:42.940339 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:55:42.940635 [info ] [Thread-1 (]: 9 of 19 START test not_null_dim_sales_productNumber ............................ [RUN]
[0m09:55:42.940987 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0015397071838378906s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:42.941196 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, now test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd)
[0m09:55:42.941411 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.001965761184692383s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:55:42.941619 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.0021839141845703125s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:42.941836 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:55:42.945849 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m09:55:42.946367 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:55:42.948343 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m09:55:42.948706 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.009268045425415039s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:42.948902 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.009473800659179688s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:42.949047 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m09:55:42.949255 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select productNumber
from `hive_metastore`.`saleslt`.`dim_sales`
where productNumber is null



      
    ) dbt_internal_test
[0m09:55:42.949465 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:43.344363 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m09:55:43.347158 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=819da473-c26e-4a75-863c-9869c6997484) - Closing cursor
[0m09:55:43.347769 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:43.348118 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:43.348401 [info ] [Thread-1 (]: 9 of 19 PASS not_null_dim_sales_productNumber .................................. [[32mPASS[0m in 0.41s]
[0m09:55:43.348738 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:55:43.348976 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:55:43.349298 [info ] [Thread-1 (]: 10 of 19 START test not_null_dim_sales_saleOrderDetailID ....................... [RUN]
[0m09:55:43.349840 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.0016620159149169922s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:43.350143 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, now test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a)
[0m09:55:43.350505 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.002328157424926758s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:55:43.350844 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.002686023712158203s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:43.351151 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:55:43.354719 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"
[0m09:55:43.355283 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:55:43.356882 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"
[0m09:55:43.357277 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.009154081344604492s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:43.357490 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.009376049041748047s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:43.357635 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"
[0m09:55:43.357839 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderDetailID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is null



      
    ) dbt_internal_test
[0m09:55:43.358041 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:43.463469 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Closing cursor
[0m09:55:43.464920 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderDetailID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is null



      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=2ee7086a-ce2f-4c33-84ba-764222201ab0
[0m09:55:43.465983 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=4.0531158447265625e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:43.476426 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
[0m09:55:43.476906 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=8.106231689453125e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:43.477210 [error] [Thread-1 (]: 10 of 19 ERROR not_null_dim_sales_saleOrderDetailID ............................ [[31mERROR[0m in 0.13s]
[0m09:55:43.477579 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:55:43.477839 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:55:43.478121 [info ] [Thread-1 (]: 11 of 19 START test not_null_dim_sales_saleOrderID ............................. [RUN]
[0m09:55:43.478459 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.0015921592712402344s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:43.478651 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, now test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3)
[0m09:55:43.478881 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.002007007598876953s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:55:43.479119 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.0022530555725097656s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:43.479322 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:55:43.482940 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"
[0m09:55:43.483430 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:55:43.485513 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"
[0m09:55:43.485913 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.009051084518432617s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:43.486113 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.009263038635253906s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:43.486259 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"
[0m09:55:43.486464 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is null



      
    ) dbt_internal_test
[0m09:55:43.486660 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:43.648843 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Closing cursor
[0m09:55:43.650144 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is null



      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=33261b87-b3e3-4c8e-907b-189a61cf019b
[0m09:55:43.651200 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=5.9604644775390625e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:43.655369 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
[0m09:55:43.656192 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=3.0994415283203125e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:43.656569 [error] [Thread-1 (]: 11 of 19 ERROR not_null_dim_sales_saleOrderID .................................. [[31mERROR[0m in 0.18s]
[0m09:55:43.656975 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:55:43.657253 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:55:43.657586 [info ] [Thread-1 (]: 12 of 19 START test not_null_dim_sales_sellStartDate ........................... [RUN]
[0m09:55:43.658032 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.0018918514251708984s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:43.658247 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, now test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118)
[0m09:55:43.658565 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0023970603942871094s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:55:43.658920 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0027599334716796875s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:43.659168 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:55:43.665264 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m09:55:43.665764 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:55:43.668015 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m09:55:43.668707 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.012559890747070312s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:43.669050 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.012883901596069336s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:43.669268 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m09:55:43.669590 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select sellStartDate
from `hive_metastore`.`saleslt`.`dim_sales`
where sellStartDate is null



      
    ) dbt_internal_test
[0m09:55:43.669841 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:43.852098 [debug] [Thread-1 (]: SQL status: OK in 0.180 seconds
[0m09:55:43.856892 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=3c8dd6e4-fceb-48ef-926d-1b5bf25cef81) - Closing cursor
[0m09:55:43.857533 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:43.857880 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:43.858166 [info ] [Thread-1 (]: 12 of 19 PASS not_null_dim_sales_sellStartDate ................................. [[32mPASS[0m in 0.20s]
[0m09:55:43.858510 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:55:43.858741 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:55:43.858991 [info ] [Thread-1 (]: 13 of 19 START test not_null_dim_sales_standardCost ............................ [RUN]
[0m09:55:43.859380 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0015101432800292969s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:43.859562 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, now test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3)
[0m09:55:43.859767 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0018951892852783203s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:55:43.859978 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0021119117736816406s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:43.860167 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:55:43.863594 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m09:55:43.864300 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:55:43.866216 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m09:55:43.866646 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.008765220642089844s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:43.866864 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.008993148803710938s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:43.867176 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m09:55:43.867474 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select standardCost
from `hive_metastore`.`saleslt`.`dim_sales`
where standardCost is null



      
    ) dbt_internal_test
[0m09:55:43.867828 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:44.075158 [debug] [Thread-1 (]: SQL status: OK in 0.210 seconds
[0m09:55:44.079171 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=a17e3703-4da7-4a28-810c-e52022a16a7c) - Closing cursor
[0m09:55:44.079692 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=7.152557373046875e-07s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:44.080004 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:44.080259 [info ] [Thread-1 (]: 13 of 19 PASS not_null_dim_sales_standardCost .................................. [[32mPASS[0m in 0.22s]
[0m09:55:44.080762 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:55:44.081193 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:55:44.081674 [info ] [Thread-1 (]: 14 of 19 START test not_null_dim_sales_subTotal ................................ [RUN]
[0m09:55:44.082321 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0022389888763427734s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:44.082631 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, now test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487)
[0m09:55:44.082915 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.002905130386352539s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:55:44.083134 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.0031299591064453125s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:44.083332 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:55:44.087011 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m09:55:44.087513 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:55:44.089345 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m09:55:44.089752 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.009729862213134766s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:44.089981 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.009981155395507812s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:44.090129 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m09:55:44.090341 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select subTotal
from `hive_metastore`.`saleslt`.`dim_sales`
where subTotal is null



      
    ) dbt_internal_test
[0m09:55:44.090554 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:44.320827 [debug] [Thread-1 (]: SQL status: OK in 0.230 seconds
[0m09:55:44.325678 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=8514ef30-93e5-4933-8690-4f80a3d6996d) - Closing cursor
[0m09:55:44.326719 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=3.0994415283203125e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:44.327234 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:44.327532 [info ] [Thread-1 (]: 14 of 19 PASS not_null_dim_sales_subTotal ...................................... [[32mPASS[0m in 0.25s]
[0m09:55:44.327873 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:55:44.328136 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:55:44.328430 [info ] [Thread-1 (]: 15 of 19 START test not_null_dim_sales_taxAmt .................................. [RUN]
[0m09:55:44.328820 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.001600027084350586s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:44.329026 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, now test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a)
[0m09:55:44.329261 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.0020532608032226562s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:55:44.329496 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.002289295196533203s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:44.329687 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:55:44.332728 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m09:55:44.333316 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:55:44.335594 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m09:55:44.336294 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.009055376052856445s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:44.336586 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.009356021881103516s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:44.336817 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m09:55:44.337088 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select taxAmt
from `hive_metastore`.`saleslt`.`dim_sales`
where taxAmt is null



      
    ) dbt_internal_test
[0m09:55:44.337313 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:44.563791 [debug] [Thread-1 (]: SQL status: OK in 0.230 seconds
[0m09:55:44.567090 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=a4ef3ba1-a208-4c81-a4a6-86a4da461407) - Closing cursor
[0m09:55:44.567967 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=7.152557373046875e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:44.568607 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:44.569134 [info ] [Thread-1 (]: 15 of 19 PASS not_null_dim_sales_taxAmt ........................................ [[32mPASS[0m in 0.24s]
[0m09:55:44.569674 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:55:44.569968 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:55:44.570259 [info ] [Thread-1 (]: 16 of 19 START test not_null_dim_sales_totalDue ................................ [RUN]
[0m09:55:44.570684 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.0021049976348876953s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:44.570908 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, now test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023)
[0m09:55:44.571304 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.0026581287384033203s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:55:44.571752 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.003114938735961914s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:44.572156 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:55:44.576178 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m09:55:44.576754 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:55:44.578500 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m09:55:44.579016 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.01040506362915039s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:44.579248 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.010694026947021484s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:44.579401 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m09:55:44.579605 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select totalDue
from `hive_metastore`.`saleslt`.`dim_sales`
where totalDue is null



      
    ) dbt_internal_test
[0m09:55:44.579818 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:44.878385 [debug] [Thread-1 (]: SQL status: OK in 0.300 seconds
[0m09:55:44.880493 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=12c87ec3-f204-495d-9f94-2f9e8b1f9e0c) - Closing cursor
[0m09:55:44.881063 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:44.881404 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:44.881682 [info ] [Thread-1 (]: 16 of 19 PASS not_null_dim_sales_totalDue ...................................... [[32mPASS[0m in 0.31s]
[0m09:55:44.882088 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:55:44.882457 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:55:44.882882 [info ] [Thread-1 (]: 17 of 19 START test not_null_dim_sales_unitPrice ............................... [RUN]
[0m09:55:44.883449 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.001987934112548828s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:44.883772 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, now test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a)
[0m09:55:44.884020 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.0026137828826904297s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:55:44.884248 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.0028460025787353516s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:44.884443 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:55:44.890232 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m09:55:44.890850 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:55:44.893001 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m09:55:44.893768 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.01235198974609375s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:44.894092 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.012666940689086914s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:44.894325 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m09:55:44.894721 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select unitPrice
from `hive_metastore`.`saleslt`.`dim_sales`
where unitPrice is null



      
    ) dbt_internal_test
[0m09:55:44.895048 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:45.187981 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:55:45.192692 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=30529a40-2acc-47fe-8894-3e69bb3ed361) - Closing cursor
[0m09:55:45.193292 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:45.193636 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:45.194038 [info ] [Thread-1 (]: 17 of 19 PASS not_null_dim_sales_unitPrice ..................................... [[32mPASS[0m in 0.31s]
[0m09:55:45.194648 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:55:45.194932 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:55:45.195186 [info ] [Thread-1 (]: 18 of 19 START test unique_dim_sales_saleOrderDetailID ......................... [RUN]
[0m09:55:45.195496 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.0018620491027832031s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:45.195678 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, now test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405)
[0m09:55:45.195898 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.0022611618041992188s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:55:45.196106 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.0024771690368652344s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:45.196300 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:55:45.202206 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"
[0m09:55:45.202916 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:55:45.204648 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"
[0m09:55:45.205261 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.011519193649291992s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:45.205639 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.011955022811889648s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:45.205854 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"
[0m09:55:45.206126 [debug] [Thread-1 (]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderDetailID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is not null
group by saleOrderDetailID
having count(*) > 1



      
    ) dbt_internal_test
[0m09:55:45.206348 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:45.328290 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Closing cursor
[0m09:55:45.329810 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderDetailID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is not null
group by saleOrderDetailID
having count(*) > 1



      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=264a3597-d859-404b-b03a-023b38a3a36d
[0m09:55:45.330808 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=1.1920928955078125e-05s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:45.333823 [debug] [Thread-1 (]: Runtime Error in test unique_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
[0m09:55:45.334200 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:45.334572 [error] [Thread-1 (]: 18 of 19 ERROR unique_dim_sales_saleOrderDetailID .............................. [[31mERROR[0m in 0.14s]
[0m09:55:45.335258 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:55:45.335759 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:55:45.336382 [info ] [Thread-1 (]: 19 of 19 START test unique_dim_sales_saleOrderID ............................... [RUN]
[0m09:55:45.336870 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.002680063247680664s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:45.337077 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, now test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c)
[0m09:55:45.337301 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.003112316131591797s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:55:45.337522 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.003342151641845703s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Acquired connection on thread (7101, 6181711872), using default compute resource for model 'None'
[0m09:55:45.337717 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:55:45.341386 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"
[0m09:55:45.341840 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:55:45.343547 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"
[0m09:55:45.344030 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.009826183319091797s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Checking idleness
[0m09:55:45.344296 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.010106325149536133s, acquire-count=1, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Retrieving connection
[0m09:55:45.344485 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"
[0m09:55:45.344717 [debug] [Thread-1 (]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is not null
group by saleOrderID
having count(*) > 1



      
    ) dbt_internal_test
[0m09:55:45.344940 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Created cursor
[0m09:55:45.460042 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, command-id=Unknown) - Closing cursor
[0m09:55:45.461498 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is not null
group by saleOrderID
having count(*) > 1



      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=e0137f37-19e9-4fd5-84da-7aa1ce3ad9a4
[0m09:55:45.462153 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:45.464151 [debug] [Thread-1 (]: Runtime Error in test unique_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
[0m09:55:45.464434 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5686169104, session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7101, 6181711872), compute-name=) - Released connection
[0m09:55:45.464687 [error] [Thread-1 (]: 19 of 19 ERROR unique_dim_sales_saleOrderID .................................... [[31mERROR[0m in 0.13s]
[0m09:55:45.465021 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:55:45.466198 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5681373200, session-id=None, name=master, idle-time=5.088865041732788s, acquire-count=0, language=None, thread-identifier=(7101, 8194199360), compute-name=) - Checking idleness
[0m09:55:45.466590 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5681373200, session-id=None, name=master, idle-time=5.089285850524902s, acquire-count=0, language=None, thread-identifier=(7101, 8194199360), compute-name=) - Reusing connection previously named master
[0m09:55:45.466882 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5681373200, session-id=None, name=master, idle-time=5.089580059051514s, acquire-count=1, language=None, thread-identifier=(7101, 8194199360), compute-name=) - Acquired connection on thread (7101, 8194199360), using default compute resource
[0m09:55:45.467183 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5681373200, session-id=None, name=master, idle-time=5.089889049530029s, acquire-count=1, language=None, thread-identifier=(7101, 8194199360), compute-name=) - Checking idleness
[0m09:55:45.467347 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5681373200, session-id=None, name=master, idle-time=5.090076923370361s, acquire-count=1, language=None, thread-identifier=(7101, 8194199360), compute-name=) - Retrieving connection
[0m09:55:45.467504 [debug] [MainThread]: On master: ROLLBACK
[0m09:55:45.467651 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:55:45.652317 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5681373200, session-id=1b5c434a-46ff-4330-87ca-a649aa663914, name=master, idle-time=1.6689300537109375e-06s, acquire-count=1, language=None, thread-identifier=(7101, 8194199360), compute-name=) - Connection created
[0m09:55:45.652672 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:55:45.652952 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5681373200, session-id=1b5c434a-46ff-4330-87ca-a649aa663914, name=master, idle-time=0.0006518363952636719s, acquire-count=1, language=None, thread-identifier=(7101, 8194199360), compute-name=) - Checking idleness
[0m09:55:45.653234 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5681373200, session-id=1b5c434a-46ff-4330-87ca-a649aa663914, name=master, idle-time=0.0009737014770507812s, acquire-count=1, language=None, thread-identifier=(7101, 8194199360), compute-name=) - Retrieving connection
[0m09:55:45.653415 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m09:55:45.653576 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m09:55:45.653760 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5681373200, session-id=1b5c434a-46ff-4330-87ca-a649aa663914, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(7101, 8194199360), compute-name=) - Released connection
[0m09:55:45.653999 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:55:45.654165 [debug] [MainThread]: On master: ROLLBACK
[0m09:55:45.654325 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:55:45.654472 [debug] [MainThread]: On master: Close
[0m09:55:45.654648 [debug] [MainThread]: Databricks adapter: Connection(session-id=1b5c434a-46ff-4330-87ca-a649aa663914) - Closing connection
[0m09:55:45.719236 [debug] [MainThread]: Connection 'test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c' was properly closed.
[0m09:55:45.719432 [debug] [MainThread]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c: ROLLBACK
[0m09:55:45.719589 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:55:45.719734 [debug] [MainThread]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c: Close
[0m09:55:45.719889 [debug] [MainThread]: Databricks adapter: Connection(session-id=0f1702c2-2fc9-4847-95f5-61e3954f5f4e) - Closing connection
[0m09:55:45.786417 [info ] [MainThread]: 
[0m09:55:45.787278 [info ] [MainThread]: Finished running 19 data tests in 0 hours 0 minutes and 7.06 seconds (7.06s).
[0m09:55:45.790036 [debug] [MainThread]: Command end result
[0m09:55:45.823283 [info ] [MainThread]: 
[0m09:55:45.823571 [info ] [MainThread]: [31mCompleted with 4 errors and 0 warnings:[0m
[0m09:55:45.823740 [info ] [MainThread]: 
[0m09:55:45.823959 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
[0m09:55:45.824129 [info ] [MainThread]: 
[0m09:55:45.824313 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
[0m09:55:45.824466 [info ] [MainThread]: 
[0m09:55:45.824653 [error] [MainThread]:   Runtime Error in test unique_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
[0m09:55:45.824803 [info ] [MainThread]: 
[0m09:55:45.824979 [error] [MainThread]:   Runtime Error in test unique_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
[0m09:55:45.825146 [info ] [MainThread]: 
[0m09:55:45.825306 [info ] [MainThread]: Done. PASS=15 WARN=0 ERROR=4 SKIP=0 TOTAL=19
[0m09:55:45.827603 [debug] [MainThread]: Resource report: {"command_name": "test", "command_wall_clock_time": 8.628958, "process_user_time": 2.880198, "process_kernel_time": 2.197592, "process_mem_max_rss": "223641600", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:55:45.827908 [debug] [MainThread]: Command `dbt test` failed at 09:55:45.827854 after 8.63 seconds
[0m09:55:45.828118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107257d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072c41d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x160528f10>]}
[0m09:55:45.828339 [debug] [MainThread]: Flushing usage events
[0m09:58:12.933709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074a2b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074afc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074b9350>]}


============================== 09:58:12.938019 | f91fa45f-8198-4dcc-aef7-ceeb02f76739 ==============================
[0m09:58:12.938019 [info ] [MainThread]: Running with dbt=1.8.5
[0m09:58:12.938539 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/vaishnavitamilvanan/.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/vaishnavitamilvanan/Documents/GW MS DS/Semester/Fall 2024/NLP/PycharmProjects/Medallion-Spark-Azure-DBT/medallion_dbt_spark/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt test', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:58:13.043834 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m09:58:13.044403 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m09:58:13.044634 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m09:58:14.199021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f91fa45f-8198-4dcc-aef7-ceeb02f76739', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074b8d50>]}
[0m09:58:14.226958 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f91fa45f-8198-4dcc-aef7-ceeb02f76739', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x141f16050>]}
[0m09:58:14.227390 [info ] [MainThread]: Registered adapter: databricks=1.8.5
[0m09:58:14.250523 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m09:58:14.459515 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m09:58:14.459897 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m09:58:14.463929 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.medallion_dbt_spark.example
[0m09:58:14.494734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f91fa45f-8198-4dcc-aef7-ceeb02f76739', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1422af690>]}
[0m09:58:14.588693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f91fa45f-8198-4dcc-aef7-ceeb02f76739', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1425c7d10>]}
[0m09:58:14.589055 [info ] [MainThread]: Found 7 snapshots, 3 models, 19 data tests, 9 sources, 590 macros
[0m09:58:14.589272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f91fa45f-8198-4dcc-aef7-ceeb02f76739', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14213f550>]}
[0m09:58:14.590752 [info ] [MainThread]: 
[0m09:58:14.591186 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5403505744, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7144, 8194199360), compute-name=) - Creating connection
[0m09:58:14.591374 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m09:58:14.591558 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5403505744, session-id=None, name=master, idle-time=1.9073486328125e-06s, acquire-count=1, language=None, thread-identifier=(7144, 8194199360), compute-name=) - Acquired connection on thread (7144, 8194199360), using default compute resource
[0m09:58:14.595493 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=None, name=list_hive_metastore_saleslt, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Creating connection
[0m09:58:14.595858 [debug] [ThreadPool]: Acquiring new databricks connection 'list_hive_metastore_saleslt'
[0m09:58:14.596089 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=None, name=list_hive_metastore_saleslt, idle-time=2.1457672119140625e-06s, acquire-count=1, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource
[0m09:58:14.596310 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=None, name=list_hive_metastore_saleslt, idle-time=0.00023293495178222656s, acquire-count=1, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:14.596481 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=None, name=list_hive_metastore_saleslt, idle-time=0.00041103363037109375s, acquire-count=1, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:14.596635 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:58:14.596803 [debug] [ThreadPool]: On list_hive_metastore_saleslt: GetTables(database=hive_metastore, schema=saleslt, identifier=None)
[0m09:58:14.596964 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:58:15.097873 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_saleslt, idle-time=1.5020370483398438e-05s, acquire-count=1, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Connection created
[0m09:58:15.098905 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:15.823078 [debug] [ThreadPool]: SQL status: OK in 1.230 seconds
[0m09:58:15.840010 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=0d7c98ae-01c8-4220-b93f-54e049fd6a4f) - Closing cursor
[0m09:58:15.848144 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_saleslt, idle-time=0.7505910396575928s, acquire-count=1, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:15.848423 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_saleslt, idle-time=0.7509028911590576s, acquire-count=1, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:15.848620 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_saleslt, idle-time=0.751105785369873s, acquire-count=1, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:15.848794 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_saleslt, idle-time=0.7512829303741455s, acquire-count=1, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:15.848946 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m09:58:15.849084 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:58:15.849248 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */

      select current_catalog()
  
[0m09:58:15.849443 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:15.987640 [debug] [ThreadPool]: SQL status: OK in 0.140 seconds
[0m09:58:15.989389 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=58a01c17-8787-4e57-80ec-96751e221a72) - Closing cursor
[0m09:58:15.992975 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_saleslt, idle-time=0.8954358100891113s, acquire-count=1, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:15.993232 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_saleslt, idle-time=0.8957068920135498s, acquire-count=1, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:15.993426 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:58:15.993628 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */
show views in `hive_metastore`.`saleslt`
  
[0m09:58:15.993840 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:16.328329 [debug] [ThreadPool]: SQL status: OK in 0.330 seconds
[0m09:58:16.332930 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=cd729539-7c8c-4fbe-b881-931846afff6e) - Closing cursor
[0m09:58:16.333527 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_saleslt, idle-time=3.0994415283203125e-06s, acquire-count=0, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:16.333982 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_saleslt, idle-time=0.0004661083221435547s, acquire-count=0, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:16.335785 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_hive_metastore_saleslt, now list_hive_metastore_snapshots)
[0m09:58:16.336115 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_snapshots, idle-time=0.0025720596313476562s, acquire-count=0, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named list_hive_metastore_saleslt
[0m09:58:16.336423 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_snapshots, idle-time=0.0028841495513916016s, acquire-count=1, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource
[0m09:58:16.336736 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_snapshots, idle-time=0.0032072067260742188s, acquire-count=1, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:16.337014 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_snapshots, idle-time=0.0034868717193603516s, acquire-count=1, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:16.337215 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:58:16.337368 [debug] [ThreadPool]: On list_hive_metastore_snapshots: GetTables(database=hive_metastore, schema=snapshots, identifier=None)
[0m09:58:16.337530 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:16.439903 [debug] [ThreadPool]: SQL status: OK in 0.100 seconds
[0m09:58:16.443192 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=a47c7ca7-8f7a-462e-82bd-216fa56fdc9a) - Closing cursor
[0m09:58:16.445557 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_snapshots, idle-time=0.11202287673950195s, acquire-count=1, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:16.445785 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_snapshots, idle-time=0.11227607727050781s, acquire-count=1, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:16.445960 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:58:16.446144 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */

      select current_catalog()
  
[0m09:58:16.446328 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:16.735758 [debug] [ThreadPool]: SQL status: OK in 0.290 seconds
[0m09:58:16.740461 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=41f36b9b-8a8a-40d6-8d43-4c1804a93e52) - Closing cursor
[0m09:58:16.742508 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_snapshots, idle-time=0.4089829921722412s, acquire-count=1, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:16.742716 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_snapshots, idle-time=0.4092068672180176s, acquire-count=1, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:16.742879 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:58:16.743054 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */
show views in `hive_metastore`.`snapshots`
  
[0m09:58:16.743221 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:16.928048 [debug] [ThreadPool]: SQL status: OK in 0.180 seconds
[0m09:58:16.929941 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=f8967f9e-25ec-4c04-9c52-cfb74b367b3d) - Closing cursor
[0m09:58:16.930426 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_snapshots, idle-time=2.1457672119140625e-06s, acquire-count=0, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:16.932206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f91fa45f-8198-4dcc-aef7-ceeb02f76739', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1420d4350>]}
[0m09:58:16.932560 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5403505744, session-id=None, name=master, idle-time=2.3410019874572754s, acquire-count=1, language=None, thread-identifier=(7144, 8194199360), compute-name=) - Checking idleness
[0m09:58:16.932766 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5403505744, session-id=None, name=master, idle-time=2.341217041015625s, acquire-count=1, language=None, thread-identifier=(7144, 8194199360), compute-name=) - Retrieving connection
[0m09:58:16.932954 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5403505744, session-id=None, name=master, idle-time=2.3414080142974854s, acquire-count=1, language=None, thread-identifier=(7144, 8194199360), compute-name=) - Checking idleness
[0m09:58:16.933119 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5403505744, session-id=None, name=master, idle-time=2.341575860977173s, acquire-count=1, language=None, thread-identifier=(7144, 8194199360), compute-name=) - Retrieving connection
[0m09:58:16.933268 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m09:58:16.933424 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m09:58:16.933613 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5403505744, session-id=None, name=master, idle-time=9.5367431640625e-07s, acquire-count=0, language=None, thread-identifier=(7144, 8194199360), compute-name=) - Released connection
[0m09:58:16.933846 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:58:16.934056 [info ] [MainThread]: 
[0m09:58:16.936801 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:58:16.937052 [info ] [Thread-1 (]: 1 of 19 START test not_null_dim_sales_customerID ............................... [RUN]
[0m09:58:16.937382 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=list_hive_metastore_snapshots, idle-time=0.006935834884643555s, acquire-count=0, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:16.937564 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_hive_metastore_snapshots, now test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5)
[0m09:58:16.937768 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.0073239803314208984s, acquire-count=0, language=None, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named list_hive_metastore_snapshots
[0m09:58:16.938011 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.007557868957519531s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:16.938216 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:58:16.950489 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"
[0m09:58:16.951562 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:58:16.960626 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"
[0m09:58:16.961147 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.030684947967529297s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:16.961438 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.030965089797973633s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:16.961685 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"
[0m09:58:16.961922 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customerID
from `hive_metastore`.`saleslt`.`dim_sales`
where customerID is null



      
    ) dbt_internal_test
[0m09:58:16.962171 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:17.229831 [debug] [Thread-1 (]: SQL status: OK in 0.270 seconds
[0m09:58:17.236721 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=93c508fc-66de-4ac1-9de1-a7f995b59708) - Closing cursor
[0m09:58:17.240122 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:17.240495 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:17.240797 [info ] [Thread-1 (]: 1 of 19 PASS not_null_dim_sales_customerID ..................................... [[32mPASS[0m in 0.30s]
[0m09:58:17.241225 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:58:17.241623 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:58:17.242027 [info ] [Thread-1 (]: 2 of 19 START test not_null_dim_sales_freight .................................. [RUN]
[0m09:58:17.242557 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, idle-time=0.0020208358764648438s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:17.242825 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5, now test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131)
[0m09:58:17.243042 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.0025479793548583984s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_customerID.60b0993af5
[0m09:58:17.243262 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.002768993377685547s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:17.243443 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:58:17.248324 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m09:58:17.249193 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:58:17.251246 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m09:58:17.251939 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.011427164077758789s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:17.252215 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.011723995208740234s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:17.252383 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m09:58:17.252605 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select freight
from `hive_metastore`.`saleslt`.`dim_sales`
where freight is null



      
    ) dbt_internal_test
[0m09:58:17.252861 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:17.557585 [debug] [Thread-1 (]: SQL status: OK in 0.300 seconds
[0m09:58:17.561791 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=ed1cf656-3054-4ec0-8681-08b3f0413e3a) - Closing cursor
[0m09:58:17.562523 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:17.563143 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:17.563681 [info ] [Thread-1 (]: 2 of 19 PASS not_null_dim_sales_freight ........................................ [[32mPASS[0m in 0.32s]
[0m09:58:17.564326 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:58:17.564698 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:58:17.565052 [info ] [Thread-1 (]: 3 of 19 START test not_null_dim_sales_lineTotal ................................ [RUN]
[0m09:58:17.565409 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.0023360252380371094s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:17.565608 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, now test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8)
[0m09:58:17.565823 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.002752065658569336s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:58:17.566039 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.0029702186584472656s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:17.566230 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:58:17.569930 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m09:58:17.570802 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:58:17.572552 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m09:58:17.572960 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.009886980056762695s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:17.573177 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.010113000869750977s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:17.573328 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m09:58:17.573537 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select lineTotal
from `hive_metastore`.`saleslt`.`dim_sales`
where lineTotal is null



      
    ) dbt_internal_test
[0m09:58:17.573744 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:17.968171 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m09:58:17.972931 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=caf10950-5210-4691-8b84-309e85d44dc4) - Closing cursor
[0m09:58:17.973879 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:17.974335 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:17.974682 [info ] [Thread-1 (]: 3 of 19 PASS not_null_dim_sales_lineTotal ...................................... [[32mPASS[0m in 0.41s]
[0m09:58:17.975047 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:58:17.975513 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:58:17.976021 [info ] [Thread-1 (]: 4 of 19 START test not_null_dim_sales_listPrice ................................ [RUN]
[0m09:58:17.976685 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.002290964126586914s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:17.977053 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, now test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f)
[0m09:58:17.977278 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.0029630661010742188s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:58:17.977499 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.003192901611328125s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:17.977693 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:58:17.980800 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m09:58:17.981281 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:58:17.983280 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m09:58:17.984346 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.009968042373657227s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:17.984722 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.010398149490356445s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:17.984943 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m09:58:17.985220 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select listPrice
from `hive_metastore`.`saleslt`.`dim_sales`
where listPrice is null



      
    ) dbt_internal_test
[0m09:58:17.985515 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:18.273266 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:58:18.275436 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=df717434-e58f-4eb6-afe6-e95bc5c8a728) - Closing cursor
[0m09:58:18.275979 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=5.0067901611328125e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:18.276353 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:18.276649 [info ] [Thread-1 (]: 4 of 19 PASS not_null_dim_sales_listPrice ...................................... [[32mPASS[0m in 0.30s]
[0m09:58:18.277033 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:58:18.277426 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:58:18.277838 [info ] [Thread-1 (]: 5 of 19 START test not_null_dim_sales_name ..................................... [RUN]
[0m09:58:18.278358 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.001965045928955078s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:18.278666 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, now test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77)
[0m09:58:18.278992 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0026421546936035156s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:58:18.279212 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0028688907623291016s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:18.279394 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:58:18.282673 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m09:58:18.283131 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:58:18.284906 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m09:58:18.285587 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.00919198989868164s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:18.285921 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.009541988372802734s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:18.286152 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m09:58:18.286452 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select name
from `hive_metastore`.`saleslt`.`dim_sales`
where name is null



      
    ) dbt_internal_test
[0m09:58:18.286749 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:18.579634 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:58:18.583604 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=edfce6a3-0c8e-46c7-beb2-eb85bafaac2a) - Closing cursor
[0m09:58:18.584407 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=3.0994415283203125e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:18.585052 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:18.585599 [info ] [Thread-1 (]: 5 of 19 PASS not_null_dim_sales_name ........................................... [[32mPASS[0m in 0.31s]
[0m09:58:18.586228 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:58:18.586608 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:58:18.586815 [info ] [Thread-1 (]: 6 of 19 START test not_null_dim_sales_orderDate ................................ [RUN]
[0m09:58:18.587215 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.002216815948486328s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:18.587449 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, now test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3)
[0m09:58:18.587678 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0027017593383789062s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:58:18.587900 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0029249191284179688s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:18.588111 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:58:18.591680 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m09:58:18.592308 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:58:18.594080 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m09:58:18.594541 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.009561777114868164s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:18.594751 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.009788751602172852s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:18.594898 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m09:58:18.595102 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orderDate
from `hive_metastore`.`saleslt`.`dim_sales`
where orderDate is null



      
    ) dbt_internal_test
[0m09:58:18.595307 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:18.775092 [debug] [Thread-1 (]: SQL status: OK in 0.180 seconds
[0m09:58:18.779073 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=72703ccd-9dc7-4cef-9c65-1b7d0cc19905) - Closing cursor
[0m09:58:18.779666 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:18.780007 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:18.780293 [info ] [Thread-1 (]: 6 of 19 PASS not_null_dim_sales_orderDate ...................................... [[32mPASS[0m in 0.19s]
[0m09:58:18.780656 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:58:18.780892 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:58:18.781205 [info ] [Thread-1 (]: 7 of 19 START test not_null_dim_sales_orderQty ................................. [RUN]
[0m09:58:18.781800 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0017299652099609375s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:18.782114 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, now test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596)
[0m09:58:18.782490 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.0024199485778808594s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:58:18.782842 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.0027871131896972656s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:18.783161 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:58:18.789671 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"
[0m09:58:18.791362 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:58:18.793447 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"
[0m09:58:18.794107 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.014055967330932617s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:18.794446 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.014406204223632812s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:18.794664 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"
[0m09:58:18.794950 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orderQty
from `hive_metastore`.`saleslt`.`dim_sales`
where orderQty is null



      
    ) dbt_internal_test
[0m09:58:18.795210 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:19.092442 [debug] [Thread-1 (]: SQL status: OK in 0.300 seconds
[0m09:58:19.096678 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=b946e326-714c-4e47-9e4a-385b9a2d18ac) - Closing cursor
[0m09:58:19.097212 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:19.097520 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:19.097787 [info ] [Thread-1 (]: 7 of 19 PASS not_null_dim_sales_orderQty ....................................... [[32mPASS[0m in 0.32s]
[0m09:58:19.098403 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:58:19.098864 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:58:19.099355 [info ] [Thread-1 (]: 8 of 19 START test not_null_dim_sales_productID ................................ [RUN]
[0m09:58:19.099943 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, idle-time=0.002370119094848633s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:19.100263 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596, now test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890)
[0m09:58:19.100480 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.002962350845336914s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_orderQty.66af966596
[0m09:58:19.100697 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.003178119659423828s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:19.100916 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:58:19.104628 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m09:58:19.105141 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:58:19.106866 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m09:58:19.107261 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.009732246398925781s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:19.107470 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.009958267211914062s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:19.107630 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m09:58:19.107836 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select productID
from `hive_metastore`.`saleslt`.`dim_sales`
where productID is null



      
    ) dbt_internal_test
[0m09:58:19.108047 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:19.292435 [debug] [Thread-1 (]: SQL status: OK in 0.180 seconds
[0m09:58:19.296897 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=cf5455ae-504a-43c5-be55-df6f6f2625a5) - Closing cursor
[0m09:58:19.298062 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=3.0994415283203125e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:19.298623 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=2.6226043701171875e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:19.298972 [info ] [Thread-1 (]: 8 of 19 PASS not_null_dim_sales_productID ...................................... [[32mPASS[0m in 0.20s]
[0m09:58:19.299366 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:58:19.299647 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:58:19.299996 [info ] [Thread-1 (]: 9 of 19 START test not_null_dim_sales_productNumber ............................ [RUN]
[0m09:58:19.300692 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.002049684524536133s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:19.300946 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, now test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd)
[0m09:58:19.301197 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.002585887908935547s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:58:19.301420 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.0028150081634521484s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:19.301633 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:58:19.306426 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m09:58:19.308112 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:58:19.310322 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m09:58:19.311153 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.012476921081542969s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:19.311514 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.012903928756713867s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:19.311826 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m09:58:19.312182 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select productNumber
from `hive_metastore`.`saleslt`.`dim_sales`
where productNumber is null



      
    ) dbt_internal_test
[0m09:58:19.312402 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:19.604412 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:58:19.607416 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=2b7908e5-b9f7-4d4d-afac-e8762b6e4b0a) - Closing cursor
[0m09:58:19.608002 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:19.608352 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:19.608626 [info ] [Thread-1 (]: 9 of 19 PASS not_null_dim_sales_productNumber .................................. [[32mPASS[0m in 0.31s]
[0m09:58:19.608974 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:58:19.609229 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:58:19.609635 [info ] [Thread-1 (]: 10 of 19 START test not_null_dim_sales_saleOrderDetailID ....................... [RUN]
[0m09:58:19.610175 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.0017709732055664062s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:19.610479 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, now test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a)
[0m09:58:19.610824 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.0024309158325195312s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:58:19.611164 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.0027761459350585938s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:19.611366 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:58:19.614718 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"
[0m09:58:19.615163 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:58:19.616767 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"
[0m09:58:19.617156 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.008793115615844727s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:19.617469 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.009101152420043945s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:19.617707 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"
[0m09:58:19.617996 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderDetailID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is null



      
    ) dbt_internal_test
[0m09:58:19.618287 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:19.720218 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Closing cursor
[0m09:58:19.721621 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderDetailID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is null



      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=4bad6633-3240-4682-9ad7-108c64ec2ba9
[0m09:58:19.722404 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:19.732663 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
[0m09:58:19.732990 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:19.733292 [error] [Thread-1 (]: 10 of 19 ERROR not_null_dim_sales_saleOrderDetailID ............................ [[31mERROR[0m in 0.12s]
[0m09:58:19.733763 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:58:19.734087 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:58:19.734466 [info ] [Thread-1 (]: 11 of 19 START test not_null_dim_sales_saleOrderID ............................. [RUN]
[0m09:58:19.734886 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, idle-time=0.0018689632415771484s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:19.735129 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a, now test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3)
[0m09:58:19.735418 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.0024089813232421875s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_saleOrderDetailID.a60664de3a
[0m09:58:19.735708 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.0026979446411132812s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:19.735961 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:58:19.739771 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"
[0m09:58:19.740688 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:58:19.742746 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"
[0m09:58:19.743506 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.010498046875s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:19.743780 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.010798215866088867s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:19.743946 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"
[0m09:58:19.744167 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is null



      
    ) dbt_internal_test
[0m09:58:19.744391 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:19.861838 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Closing cursor
[0m09:58:19.863144 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select saleOrderID
from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is null



      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=716dcd2d-8b31-4712-830f-c1111cdd3b50
[0m09:58:19.863991 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:19.865984 [debug] [Thread-1 (]: Runtime Error in test not_null_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
[0m09:58:19.866247 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:19.866497 [error] [Thread-1 (]: 11 of 19 ERROR not_null_dim_sales_saleOrderID .................................. [[31mERROR[0m in 0.13s]
[0m09:58:19.866853 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:58:19.867093 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:58:19.867381 [info ] [Thread-1 (]: 12 of 19 START test not_null_dim_sales_sellStartDate ........................... [RUN]
[0m09:58:19.867920 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, idle-time=0.001600027084350586s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:19.868237 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3, now test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118)
[0m09:58:19.868614 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0023119449615478516s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_saleOrderID.48ce11e7f3
[0m09:58:19.868971 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0026879310607910156s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:19.869299 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:58:19.874128 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m09:58:19.874547 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:58:19.876307 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m09:58:19.876881 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.010579824447631836s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:19.877190 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.010931968688964844s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:19.877496 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m09:58:19.877873 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select sellStartDate
from `hive_metastore`.`saleslt`.`dim_sales`
where sellStartDate is null



      
    ) dbt_internal_test
[0m09:58:19.878237 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:20.322405 [debug] [Thread-1 (]: SQL status: OK in 0.440 seconds
[0m09:58:20.327449 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=2305bb78-e395-4b1e-984c-c9c9944b6c29) - Closing cursor
[0m09:58:20.328263 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:20.328589 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:20.328854 [info ] [Thread-1 (]: 12 of 19 PASS not_null_dim_sales_sellStartDate ................................. [[32mPASS[0m in 0.46s]
[0m09:58:20.329196 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:58:20.329448 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:58:20.329696 [info ] [Thread-1 (]: 13 of 19 START test not_null_dim_sales_standardCost ............................ [RUN]
[0m09:58:20.330211 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0015690326690673828s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:20.330518 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, now test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3)
[0m09:58:20.330867 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0022249221801757812s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:58:20.331109 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0025260448455810547s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:20.331295 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:58:20.334492 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m09:58:20.335052 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:58:20.336899 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m09:58:20.337336 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.008744001388549805s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:20.337551 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.008970975875854492s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:20.337699 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m09:58:20.337981 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select standardCost
from `hive_metastore`.`saleslt`.`dim_sales`
where standardCost is null



      
    ) dbt_internal_test
[0m09:58:20.338279 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:20.526723 [debug] [Thread-1 (]: SQL status: OK in 0.190 seconds
[0m09:58:20.530029 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=4124ff3a-2377-432b-b206-651a987bd2ee) - Closing cursor
[0m09:58:20.530619 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:20.530996 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:20.531274 [info ] [Thread-1 (]: 13 of 19 PASS not_null_dim_sales_standardCost .................................. [[32mPASS[0m in 0.20s]
[0m09:58:20.531611 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:58:20.531926 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:58:20.532341 [info ] [Thread-1 (]: 14 of 19 START test not_null_dim_sales_subTotal ................................ [RUN]
[0m09:58:20.532900 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0018701553344726562s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:20.533210 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, now test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487)
[0m09:58:20.533589 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.0025489330291748047s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:58:20.534014 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.002946138381958008s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:20.534314 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:58:20.538240 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m09:58:20.538714 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:58:20.540359 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m09:58:20.541487 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.010486125946044922s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:20.541757 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.010784149169921875s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:20.541923 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m09:58:20.542142 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select subTotal
from `hive_metastore`.`saleslt`.`dim_sales`
where subTotal is null



      
    ) dbt_internal_test
[0m09:58:20.542349 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:20.833297 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:58:20.838976 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=bcd92eb2-df51-4d11-b5db-59453e04622b) - Closing cursor
[0m09:58:20.839543 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:20.839898 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:20.840275 [info ] [Thread-1 (]: 14 of 19 PASS not_null_dim_sales_subTotal ...................................... [[32mPASS[0m in 0.31s]
[0m09:58:20.840875 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:58:20.841333 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:58:20.841803 [info ] [Thread-1 (]: 15 of 19 START test not_null_dim_sales_taxAmt .................................. [RUN]
[0m09:58:20.842128 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.0022249221801757812s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:20.842310 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, now test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a)
[0m09:58:20.842518 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.0026199817657470703s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:58:20.842729 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.0028328895568847656s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:20.842915 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:58:20.846220 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m09:58:20.847972 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:58:20.850312 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m09:58:20.851164 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.011248111724853516s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:20.851404 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.011501073837280273s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:20.851568 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m09:58:20.851817 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select taxAmt
from `hive_metastore`.`saleslt`.`dim_sales`
where taxAmt is null



      
    ) dbt_internal_test
[0m09:58:20.852095 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:21.141328 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:58:21.144423 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=9ce9aaf1-a6af-4814-bad6-43fd0bb741ba) - Closing cursor
[0m09:58:21.145224 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=4.0531158447265625e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:21.145838 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:21.146342 [info ] [Thread-1 (]: 15 of 19 PASS not_null_dim_sales_taxAmt ........................................ [[32mPASS[0m in 0.30s]
[0m09:58:21.146773 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:58:21.147018 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:58:21.147283 [info ] [Thread-1 (]: 16 of 19 START test not_null_dim_sales_totalDue ................................ [RUN]
[0m09:58:21.147628 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.0018589496612548828s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:21.147823 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, now test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023)
[0m09:58:21.148028 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.0022618770599365234s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:58:21.148245 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.0024819374084472656s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:21.148439 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:58:21.151949 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m09:58:21.152486 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:58:21.155017 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m09:58:21.155478 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.009706974029541016s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:21.155685 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.009925127029418945s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:21.155841 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m09:58:21.156052 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select totalDue
from `hive_metastore`.`saleslt`.`dim_sales`
where totalDue is null



      
    ) dbt_internal_test
[0m09:58:21.156258 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:21.448479 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:58:21.450563 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=caba8d55-1271-40a0-bb92-47fd8b44ac81) - Closing cursor
[0m09:58:21.451088 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:21.451467 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:21.451750 [info ] [Thread-1 (]: 16 of 19 PASS not_null_dim_sales_totalDue ...................................... [[32mPASS[0m in 0.30s]
[0m09:58:21.452117 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:58:21.452369 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:58:21.452753 [info ] [Thread-1 (]: 17 of 19 START test not_null_dim_sales_unitPrice ............................... [RUN]
[0m09:58:21.453245 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.0017380714416503906s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:21.453516 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, now test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a)
[0m09:58:21.453828 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.0023279190063476562s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:58:21.454151 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.0026488304138183594s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:21.454366 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:58:21.459646 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m09:58:21.460095 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:58:21.461851 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m09:58:21.462586 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.011097908020019531s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:21.462869 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.011395931243896484s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:21.463017 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m09:58:21.463221 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select unitPrice
from `hive_metastore`.`saleslt`.`dim_sales`
where unitPrice is null



      
    ) dbt_internal_test
[0m09:58:21.463420 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:21.637540 [debug] [Thread-1 (]: SQL status: OK in 0.170 seconds
[0m09:58:21.639741 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=7335d6b9-1137-47f2-b831-ccfb656de87f) - Closing cursor
[0m09:58:21.640318 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:21.640665 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:21.640951 [info ] [Thread-1 (]: 17 of 19 PASS not_null_dim_sales_unitPrice ..................................... [[32mPASS[0m in 0.19s]
[0m09:58:21.641477 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:58:21.641848 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:58:21.642292 [info ] [Thread-1 (]: 18 of 19 START test unique_dim_sales_saleOrderDetailID ......................... [RUN]
[0m09:58:21.642866 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.002130270004272461s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:21.643074 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, now test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405)
[0m09:58:21.643291 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.002621173858642578s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:58:21.643505 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.0028409957885742188s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:21.643695 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:58:21.648497 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"
[0m09:58:21.649823 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:58:21.652032 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"
[0m09:58:21.652525 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.011834144592285156s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:21.652763 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.012104272842407227s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:21.652947 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"
[0m09:58:21.653218 [debug] [Thread-1 (]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderDetailID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is not null
group by saleOrderDetailID
having count(*) > 1



      
    ) dbt_internal_test
[0m09:58:21.653476 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:21.773632 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Closing cursor
[0m09:58:21.775160 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderDetailID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderDetailID is not null
group by saleOrderDetailID
having count(*) > 1



      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=53c5be01-6348-449a-8797-a722bb64455a
[0m09:58:21.776420 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=3.0994415283203125e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:21.778525 [debug] [Thread-1 (]: Runtime Error in test unique_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
[0m09:58:21.778804 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:21.779069 [error] [Thread-1 (]: 18 of 19 ERROR unique_dim_sales_saleOrderDetailID .............................. [[31mERROR[0m in 0.14s]
[0m09:58:21.779393 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:58:21.779766 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:58:21.780183 [info ] [Thread-1 (]: 19 of 19 START test unique_dim_sales_saleOrderID ............................... [RUN]
[0m09:58:21.780696 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, idle-time=0.0018360614776611328s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:21.781007 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405, now test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c)
[0m09:58:21.781346 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.002499103546142578s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.unique_dim_sales_saleOrderDetailID.343b942405
[0m09:58:21.781691 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.00284576416015625s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Acquired connection on thread (7144, 6152073216), using default compute resource for model 'None'
[0m09:58:21.782004 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:58:21.785732 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"
[0m09:58:21.787334 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:58:21.789279 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"
[0m09:58:21.789764 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.010947942733764648s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Checking idleness
[0m09:58:21.790002 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=0.01120305061340332s, acquire-count=1, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Retrieving connection
[0m09:58:21.790170 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"
[0m09:58:21.790407 [debug] [Thread-1 (]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is not null
group by saleOrderID
having count(*) > 1



      
    ) dbt_internal_test
[0m09:58:21.790702 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Created cursor
[0m09:58:21.897595 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, command-id=Unknown) - Closing cursor
[0m09:58:21.898172 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    saleOrderID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where saleOrderID is not null
group by saleOrderID
having count(*) > 1



      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:715)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:559)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:403)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)
	at com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)
	at com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:72)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:172)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:603)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:612)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:491)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:489)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:67)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:381)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:367)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:415)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:685)
	... 35 more
, operation-id=32c4508a-1bd8-4225-b594-3b20d027db70
[0m09:58:21.898730 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:21.900792 [debug] [Thread-1 (]: Runtime Error in test unique_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
[0m09:58:21.901186 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5403507984, session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7, name=test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7144, 6152073216), compute-name=) - Released connection
[0m09:58:21.901453 [error] [Thread-1 (]: 19 of 19 ERROR unique_dim_sales_saleOrderID .................................... [[31mERROR[0m in 0.12s]
[0m09:58:21.901820 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c
[0m09:58:21.902673 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5403505744, session-id=None, name=master, idle-time=4.969054937362671s, acquire-count=0, language=None, thread-identifier=(7144, 8194199360), compute-name=) - Checking idleness
[0m09:58:21.902929 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5403505744, session-id=None, name=master, idle-time=4.969316005706787s, acquire-count=0, language=None, thread-identifier=(7144, 8194199360), compute-name=) - Reusing connection previously named master
[0m09:58:21.903119 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5403505744, session-id=None, name=master, idle-time=4.969514846801758s, acquire-count=1, language=None, thread-identifier=(7144, 8194199360), compute-name=) - Acquired connection on thread (7144, 8194199360), using default compute resource
[0m09:58:21.903317 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5403505744, session-id=None, name=master, idle-time=4.969720125198364s, acquire-count=1, language=None, thread-identifier=(7144, 8194199360), compute-name=) - Checking idleness
[0m09:58:21.903484 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5403505744, session-id=None, name=master, idle-time=4.969887018203735s, acquire-count=1, language=None, thread-identifier=(7144, 8194199360), compute-name=) - Retrieving connection
[0m09:58:21.903630 [debug] [MainThread]: On master: ROLLBACK
[0m09:58:21.903776 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:58:22.110785 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5403505744, session-id=a80e92c0-2c82-4c07-94de-5ba02554ac26, name=master, idle-time=1.9073486328125e-06s, acquire-count=1, language=None, thread-identifier=(7144, 8194199360), compute-name=) - Connection created
[0m09:58:22.111079 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:58:22.111276 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5403505744, session-id=a80e92c0-2c82-4c07-94de-5ba02554ac26, name=master, idle-time=0.0005350112915039062s, acquire-count=1, language=None, thread-identifier=(7144, 8194199360), compute-name=) - Checking idleness
[0m09:58:22.111459 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5403505744, session-id=a80e92c0-2c82-4c07-94de-5ba02554ac26, name=master, idle-time=0.0007197856903076172s, acquire-count=1, language=None, thread-identifier=(7144, 8194199360), compute-name=) - Retrieving connection
[0m09:58:22.111613 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m09:58:22.111755 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m09:58:22.111913 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5403505744, session-id=a80e92c0-2c82-4c07-94de-5ba02554ac26, name=master, idle-time=0.0s, acquire-count=0, language=None, thread-identifier=(7144, 8194199360), compute-name=) - Released connection
[0m09:58:22.112140 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:58:22.112301 [debug] [MainThread]: On master: ROLLBACK
[0m09:58:22.112451 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:58:22.112594 [debug] [MainThread]: On master: Close
[0m09:58:22.112747 [debug] [MainThread]: Databricks adapter: Connection(session-id=a80e92c0-2c82-4c07-94de-5ba02554ac26) - Closing connection
[0m09:58:22.170596 [debug] [MainThread]: Connection 'test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c' was properly closed.
[0m09:58:22.171477 [debug] [MainThread]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c: ROLLBACK
[0m09:58:22.171977 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:58:22.172523 [debug] [MainThread]: On test.medallion_dbt_spark.unique_dim_sales_saleOrderID.810c5f247c: Close
[0m09:58:22.173096 [debug] [MainThread]: Databricks adapter: Connection(session-id=9e4a0566-193c-4996-9b2f-8d0aef683cb7) - Closing connection
[0m09:58:22.268562 [info ] [MainThread]: 
[0m09:58:22.268877 [info ] [MainThread]: Finished running 19 data tests in 0 hours 0 minutes and 7.68 seconds (7.68s).
[0m09:58:22.270501 [debug] [MainThread]: Command end result
[0m09:58:22.306800 [info ] [MainThread]: 
[0m09:58:22.307085 [info ] [MainThread]: [31mCompleted with 4 errors and 0 warnings:[0m
[0m09:58:22.307257 [info ] [MainThread]: 
[0m09:58:22.307494 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 15 pos 6
[0m09:58:22.307689 [info ] [MainThread]: 
[0m09:58:22.307884 [error] [MainThread]:   Runtime Error in test not_null_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 15 pos 6
[0m09:58:22.308071 [info ] [MainThread]: 
[0m09:58:22.308263 [error] [MainThread]:   Runtime Error in test unique_dim_sales_saleOrderDetailID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderDetailID` cannot be resolved. Did you mean one of the following? [`SalesOrderDetailID`, `OrderDate`, `SalesOrderID`, `OrderQty`, `SalesOrderNumber`]. SQLSTATE: 42703; line 16 pos 6
[0m09:58:22.308422 [info ] [MainThread]: 
[0m09:58:22.308606 [error] [MainThread]:   Runtime Error in test unique_dim_sales_saleOrderID (models/marts/sales/dim_sales.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `saleOrderID` cannot be resolved. Did you mean one of the following? [`SalesOrderID`, `CustomerID`, `OrderQty`, `DueDate`, `OrderDate`]. SQLSTATE: 42703; line 16 pos 6
[0m09:58:22.308772 [info ] [MainThread]: 
[0m09:58:22.308932 [info ] [MainThread]: Done. PASS=15 WARN=0 ERROR=4 SKIP=0 TOTAL=19
[0m09:58:22.311523 [debug] [MainThread]: Resource report: {"command_name": "test", "command_wall_clock_time": 9.457047, "process_user_time": 2.760891, "process_kernel_time": 2.387213, "process_mem_max_rss": "223772672", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:58:22.311888 [debug] [MainThread]: Command `dbt test` failed at 09:58:22.311832 after 9.46 seconds
[0m09:58:22.312125 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074ac290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074b92d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10344ebd0>]}
[0m09:58:22.312351 [debug] [MainThread]: Flushing usage events
[0m09:58:58.844018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a80750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10671c290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106af54d0>]}


============================== 09:58:58.848410 | 5694a1a4-9ed3-44e5-8db7-ab25deea648b ==============================
[0m09:58:58.848410 [info ] [MainThread]: Running with dbt=1.8.5
[0m09:58:58.849032 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/vaishnavitamilvanan/.dbt', 'log_path': '/Users/vaishnavitamilvanan/Documents/GW MS DS/Semester/Fall 2024/NLP/PycharmProjects/Medallion-Spark-Azure-DBT/medallion_dbt_spark/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt test', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:58:58.912204 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m09:58:58.912733 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m09:58:58.912954 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m09:58:59.932622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5694a1a4-9ed3-44e5-8db7-ab25deea648b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14866a090>]}
[0m09:58:59.959524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5694a1a4-9ed3-44e5-8db7-ab25deea648b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x148616050>]}
[0m09:58:59.959906 [info ] [MainThread]: Registered adapter: databricks=1.8.5
[0m09:58:59.980440 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m09:59:00.174598 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:59:00.175310 [debug] [MainThread]: Partial parsing: updated file: medallion_dbt_spark://models/marts/sales/dim_sales.yml
[0m09:59:00.297807 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m09:59:00.298182 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '5694a1a4-9ed3-44e5-8db7-ab25deea648b', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x148743310>]}
[0m09:59:00.429245 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.medallion_dbt_spark.example
[0m09:59:00.437104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5694a1a4-9ed3-44e5-8db7-ab25deea648b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x148a58210>]}
[0m09:59:00.529860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5694a1a4-9ed3-44e5-8db7-ab25deea648b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x14ba6bf90>]}
[0m09:59:00.530270 [info ] [MainThread]: Found 7 snapshots, 3 models, 19 data tests, 9 sources, 590 macros
[0m09:59:00.530493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5694a1a4-9ed3-44e5-8db7-ab25deea648b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x148d78ed0>]}
[0m09:59:00.532047 [info ] [MainThread]: 
[0m09:59:00.532598 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5564136144, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7203, 8194199360), compute-name=) - Creating connection
[0m09:59:00.532836 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m09:59:00.533035 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5564136144, session-id=None, name=master, idle-time=2.1457672119140625e-06s, acquire-count=1, language=None, thread-identifier=(7203, 8194199360), compute-name=) - Acquired connection on thread (7203, 8194199360), using default compute resource
[0m09:59:00.536828 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=None, name=list_hive_metastore_snapshots, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Creating connection
[0m09:59:00.537242 [debug] [ThreadPool]: Acquiring new databricks connection 'list_hive_metastore_snapshots'
[0m09:59:00.537471 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=None, name=list_hive_metastore_snapshots, idle-time=1.9073486328125e-06s, acquire-count=1, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource
[0m09:59:00.537780 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=None, name=list_hive_metastore_snapshots, idle-time=0.0003247261047363281s, acquire-count=1, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:00.537972 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=None, name=list_hive_metastore_snapshots, idle-time=0.0005350112915039062s, acquire-count=1, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:00.538125 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:59:00.538293 [debug] [ThreadPool]: On list_hive_metastore_snapshots: GetTables(database=hive_metastore, schema=snapshots, identifier=None)
[0m09:59:00.538437 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:59:00.777598 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_snapshots, idle-time=3.814697265625e-06s, acquire-count=1, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Connection created
[0m09:59:00.777985 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:00.883358 [debug] [ThreadPool]: SQL status: OK in 0.340 seconds
[0m09:59:00.893738 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=4fb69b12-0af7-4805-a647-18a179e6c15c) - Closing cursor
[0m09:59:00.900339 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_snapshots, idle-time=0.12277603149414062s, acquire-count=1, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:00.900590 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_snapshots, idle-time=0.12304997444152832s, acquire-count=1, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:00.900792 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_snapshots, idle-time=0.12325763702392578s, acquire-count=1, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:00.900978 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_snapshots, idle-time=0.12344598770141602s, acquire-count=1, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:00.901141 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m09:59:00.901294 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:59:00.901462 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */

      select current_catalog()
  
[0m09:59:00.901643 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:01.009919 [debug] [ThreadPool]: SQL status: OK in 0.110 seconds
[0m09:59:01.011193 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=cc86d2d8-2ffd-46e5-8a1a-51720c22c368) - Closing cursor
[0m09:59:01.014741 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_snapshots, idle-time=0.23719501495361328s, acquire-count=1, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:01.014954 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_snapshots, idle-time=0.23741674423217773s, acquire-count=1, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:01.015106 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m09:59:01.015330 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */
show views in `hive_metastore`.`snapshots`
  
[0m09:59:01.015600 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:01.180319 [debug] [ThreadPool]: SQL status: OK in 0.160 seconds
[0m09:59:01.181734 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=4069968e-e602-469d-9c34-e5535845b9e6) - Closing cursor
[0m09:59:01.182125 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_snapshots, idle-time=1.6689300537109375e-06s, acquire-count=0, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:01.182504 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_snapshots, idle-time=0.0003867149353027344s, acquire-count=0, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:01.183265 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_hive_metastore_snapshots, now list_hive_metastore_saleslt)
[0m09:59:01.183460 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_saleslt, idle-time=0.0013418197631835938s, acquire-count=0, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named list_hive_metastore_snapshots
[0m09:59:01.183651 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_saleslt, idle-time=0.0015349388122558594s, acquire-count=1, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource
[0m09:59:01.183842 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_saleslt, idle-time=0.0017328262329101562s, acquire-count=1, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:01.184009 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_saleslt, idle-time=0.001898050308227539s, acquire-count=1, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:01.184152 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:59:01.184349 [debug] [ThreadPool]: On list_hive_metastore_saleslt: GetTables(database=hive_metastore, schema=saleslt, identifier=None)
[0m09:59:01.184606 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:01.292303 [debug] [ThreadPool]: SQL status: OK in 0.110 seconds
[0m09:59:01.295116 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=c983efe3-2823-4ed1-81ba-7f25369f2e04) - Closing cursor
[0m09:59:01.297165 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_saleslt, idle-time=0.1150369644165039s, acquire-count=1, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:01.297382 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_saleslt, idle-time=0.115264892578125s, acquire-count=1, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:01.297549 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:59:01.297720 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */

      select current_catalog()
  
[0m09:59:01.297897 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:01.485189 [debug] [ThreadPool]: SQL status: OK in 0.190 seconds
[0m09:59:01.488546 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=b5148c0d-633f-48c0-878f-ba8e03f3b326) - Closing cursor
[0m09:59:01.492505 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_saleslt, idle-time=0.3103597164154053s, acquire-count=1, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:01.492786 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_saleslt, idle-time=0.3106679916381836s, acquire-count=1, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:01.492960 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m09:59:01.493126 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */
show views in `hive_metastore`.`saleslt`
  
[0m09:59:01.493376 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:01.672239 [debug] [ThreadPool]: SQL status: OK in 0.180 seconds
[0m09:59:01.674826 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=be13c07a-c060-4c0a-8880-3ad318fc8131) - Closing cursor
[0m09:59:01.675376 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_saleslt, idle-time=2.1457672119140625e-06s, acquire-count=0, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:01.676745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5694a1a4-9ed3-44e5-8db7-ab25deea648b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x148cbd810>]}
[0m09:59:01.677199 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5564136144, session-id=None, name=master, idle-time=1.1441121101379395s, acquire-count=1, language=None, thread-identifier=(7203, 8194199360), compute-name=) - Checking idleness
[0m09:59:01.677543 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5564136144, session-id=None, name=master, idle-time=1.1444990634918213s, acquire-count=1, language=None, thread-identifier=(7203, 8194199360), compute-name=) - Retrieving connection
[0m09:59:01.677836 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5564136144, session-id=None, name=master, idle-time=1.1448020935058594s, acquire-count=1, language=None, thread-identifier=(7203, 8194199360), compute-name=) - Checking idleness
[0m09:59:01.678100 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5564136144, session-id=None, name=master, idle-time=1.1450679302215576s, acquire-count=1, language=None, thread-identifier=(7203, 8194199360), compute-name=) - Retrieving connection
[0m09:59:01.678347 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m09:59:01.678577 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m09:59:01.678841 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5564136144, session-id=None, name=master, idle-time=2.1457672119140625e-06s, acquire-count=0, language=None, thread-identifier=(7203, 8194199360), compute-name=) - Released connection
[0m09:59:01.679234 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:59:01.679548 [info ] [MainThread]: 
[0m09:59:01.682204 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0
[0m09:59:01.682515 [info ] [Thread-1 (]: 1 of 19 START test not_null_dim_sales_CustomerID ............................... [RUN]
[0m09:59:01.682852 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=list_hive_metastore_saleslt, idle-time=0.007428169250488281s, acquire-count=0, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:01.683086 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_hive_metastore_saleslt, now test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0)
[0m09:59:01.683310 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=0.007908821105957031s, acquire-count=0, language=None, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named list_hive_metastore_saleslt
[0m09:59:01.683529 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=0.008137941360473633s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:01.683726 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0
[0m09:59:01.694875 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0"
[0m09:59:01.695402 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0
[0m09:59:01.704598 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0"
[0m09:59:01.705197 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=0.029785871505737305s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:01.705453 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=0.03006601333618164s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:01.705619 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0"
[0m09:59:01.705840 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select CustomerID
from `hive_metastore`.`saleslt`.`dim_sales`
where CustomerID is null



      
    ) dbt_internal_test
[0m09:59:01.706062 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:02.000478 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:59:02.005096 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=5c2061eb-8b7f-405b-9ad8-5c2a1566b830) - Closing cursor
[0m09:59:02.007941 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=3.0994415283203125e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:02.008317 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:02.008640 [info ] [Thread-1 (]: 1 of 19 PASS not_null_dim_sales_CustomerID ..................................... [[32mPASS[0m in 0.33s]
[0m09:59:02.009017 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0
[0m09:59:02.009274 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411
[0m09:59:02.009572 [info ] [Thread-1 (]: 2 of 19 START test not_null_dim_sales_OrderQty ................................. [RUN]
[0m09:59:02.009986 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=0.0016369819641113281s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:02.010274 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, now test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411)
[0m09:59:02.010555 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=0.002239227294921875s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0
[0m09:59:02.010796 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=0.002482175827026367s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:02.010994 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411
[0m09:59:02.014203 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411"
[0m09:59:02.014783 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411
[0m09:59:02.016910 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411"
[0m09:59:02.017493 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=0.009161949157714844s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:02.017732 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=0.009423017501831055s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:02.017932 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411"
[0m09:59:02.018184 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select OrderQty
from `hive_metastore`.`saleslt`.`dim_sales`
where OrderQty is null



      
    ) dbt_internal_test
[0m09:59:02.018441 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:02.305753 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:59:02.309190 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=01e94829-2569-4693-bb42-4f1455cf5de5) - Closing cursor
[0m09:59:02.309825 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=3.0994415283203125e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:02.310181 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:02.310456 [info ] [Thread-1 (]: 2 of 19 PASS not_null_dim_sales_OrderQty ....................................... [[32mPASS[0m in 0.30s]
[0m09:59:02.310820 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411
[0m09:59:02.311226 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb
[0m09:59:02.311682 [info ] [Thread-1 (]: 3 of 19 START test not_null_dim_sales_SalesOrderDetailID ....................... [RUN]
[0m09:59:02.312292 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=0.0020389556884765625s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:02.312504 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, now test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb)
[0m09:59:02.312736 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=0.002543926239013672s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411
[0m09:59:02.312972 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=0.002785921096801758s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:02.313162 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb
[0m09:59:02.316453 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb"
[0m09:59:02.317068 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb
[0m09:59:02.318870 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb"
[0m09:59:02.319578 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=0.009362936019897461s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:02.319874 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=0.009674072265625s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:02.320103 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb"
[0m09:59:02.320408 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select SalesOrderDetailID
from `hive_metastore`.`saleslt`.`dim_sales`
where SalesOrderDetailID is null



      
    ) dbt_internal_test
[0m09:59:02.320717 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:02.612331 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:59:02.618910 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=89e5ab4b-5d82-4c35-8926-9aa85cfecdb9) - Closing cursor
[0m09:59:02.620282 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=4.0531158447265625e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:02.620728 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:02.621041 [info ] [Thread-1 (]: 3 of 19 PASS not_null_dim_sales_SalesOrderDetailID ............................. [[32mPASS[0m in 0.31s]
[0m09:59:02.621424 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb
[0m09:59:02.621686 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6
[0m09:59:02.621972 [info ] [Thread-1 (]: 4 of 19 START test not_null_dim_sales_SalesOrderID ............................. [RUN]
[0m09:59:02.622353 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=0.001622915267944336s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:02.622570 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, now test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6)
[0m09:59:02.622792 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=0.002064943313598633s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb
[0m09:59:02.623023 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=0.002296924591064453s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:02.623227 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6
[0m09:59:02.628140 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6"
[0m09:59:02.629490 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6
[0m09:59:02.633517 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6"
[0m09:59:02.634089 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=0.013354778289794922s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:02.634466 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=0.013727188110351562s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:02.634662 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6"
[0m09:59:02.634896 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select SalesOrderID
from `hive_metastore`.`saleslt`.`dim_sales`
where SalesOrderID is null



      
    ) dbt_internal_test
[0m09:59:02.635142 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:02.919829 [debug] [Thread-1 (]: SQL status: OK in 0.280 seconds
[0m09:59:02.923462 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=77cb61d5-c1d5-4a25-b57a-5f8e94fc9db3) - Closing cursor
[0m09:59:02.924477 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=6.198883056640625e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:02.925058 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:02.925524 [info ] [Thread-1 (]: 4 of 19 PASS not_null_dim_sales_SalesOrderID ................................... [[32mPASS[0m in 0.30s]
[0m09:59:02.926379 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6
[0m09:59:02.926746 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:59:02.927131 [info ] [Thread-1 (]: 5 of 19 START test not_null_dim_sales_freight .................................. [RUN]
[0m09:59:02.927658 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=0.0025818347930908203s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:02.927858 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, now test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131)
[0m09:59:02.928075 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.0030558109283447266s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6
[0m09:59:02.928294 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.0032808780670166016s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:02.928490 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:59:02.932073 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m09:59:02.932776 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:59:02.934486 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m09:59:02.934925 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.009895801544189453s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:02.935179 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.010150909423828125s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:02.935340 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m09:59:02.935559 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select freight
from `hive_metastore`.`saleslt`.`dim_sales`
where freight is null



      
    ) dbt_internal_test
[0m09:59:02.935848 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:03.227176 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:59:03.230497 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=9c894ad2-ed98-4de4-b570-46c116caac55) - Closing cursor
[0m09:59:03.231103 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=1.6689300537109375e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:03.231461 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:03.231742 [info ] [Thread-1 (]: 5 of 19 PASS not_null_dim_sales_freight ........................................ [[32mPASS[0m in 0.30s]
[0m09:59:03.232089 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:59:03.232363 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:59:03.232641 [info ] [Thread-1 (]: 6 of 19 START test not_null_dim_sales_lineTotal ................................ [RUN]
[0m09:59:03.233027 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.0015599727630615234s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:03.233338 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, now test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8)
[0m09:59:03.233722 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.0021982192993164062s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m09:59:03.234082 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.0025758743286132812s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:03.234392 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:59:03.238314 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m09:59:03.238925 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:59:03.240661 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m09:59:03.241473 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.009979963302612305s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:03.241755 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.010298967361450195s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:03.241923 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m09:59:03.242234 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select lineTotal
from `hive_metastore`.`saleslt`.`dim_sales`
where lineTotal is null



      
    ) dbt_internal_test
[0m09:59:03.242496 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:03.430711 [debug] [Thread-1 (]: SQL status: OK in 0.190 seconds
[0m09:59:03.434479 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=60bc049b-2e8c-4b2a-9d1d-6e7bf523bf40) - Closing cursor
[0m09:59:03.435089 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:03.435424 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:03.435719 [info ] [Thread-1 (]: 6 of 19 PASS not_null_dim_sales_lineTotal ...................................... [[32mPASS[0m in 0.20s]
[0m09:59:03.436098 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:59:03.436372 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:59:03.436700 [info ] [Thread-1 (]: 7 of 19 START test not_null_dim_sales_listPrice ................................ [RUN]
[0m09:59:03.437227 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.0017518997192382812s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:03.437525 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, now test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f)
[0m09:59:03.437875 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.002399921417236328s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m09:59:03.438221 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.0027539730072021484s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:03.438534 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:59:03.442144 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m09:59:03.442731 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:59:03.444618 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m09:59:03.445211 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.009749889373779297s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:03.445513 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.010069847106933594s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:03.445727 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m09:59:03.446013 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select listPrice
from `hive_metastore`.`saleslt`.`dim_sales`
where listPrice is null



      
    ) dbt_internal_test
[0m09:59:03.446301 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:03.739870 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m09:59:03.741927 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=7495b079-2a29-4b0f-b5d9-ac4a839e1725) - Closing cursor
[0m09:59:03.742405 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:03.742745 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:03.743014 [info ] [Thread-1 (]: 7 of 19 PASS not_null_dim_sales_listPrice ...................................... [[32mPASS[0m in 0.31s]
[0m09:59:03.743465 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:59:03.743924 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:59:03.744335 [info ] [Thread-1 (]: 8 of 19 START test not_null_dim_sales_name ..................................... [RUN]
[0m09:59:03.744822 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.0020351409912109375s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:03.745116 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, now test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77)
[0m09:59:03.745445 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.002657175064086914s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m09:59:03.745820 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.003033161163330078s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:03.746164 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:59:03.749995 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m09:59:03.750467 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:59:03.752371 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m09:59:03.752833 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.010076284408569336s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:03.753075 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.010328054428100586s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:03.753255 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m09:59:03.753462 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select name
from `hive_metastore`.`saleslt`.`dim_sales`
where name is null



      
    ) dbt_internal_test
[0m09:59:03.753687 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:03.937314 [debug] [Thread-1 (]: SQL status: OK in 0.180 seconds
[0m09:59:03.939333 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=7aa64131-6d4a-4056-b0d1-0fdb0baeb8b6) - Closing cursor
[0m09:59:03.939870 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:03.940315 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:03.940703 [info ] [Thread-1 (]: 8 of 19 PASS not_null_dim_sales_name ........................................... [[32mPASS[0m in 0.20s]
[0m09:59:03.941041 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:59:03.941279 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:59:03.941547 [info ] [Thread-1 (]: 9 of 19 START test not_null_dim_sales_orderDate ................................ [RUN]
[0m09:59:03.941937 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0016598701477050781s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:03.942136 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, now test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3)
[0m09:59:03.942354 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0020949840545654297s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m09:59:03.942573 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0023119449615478516s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:03.942766 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:59:03.946896 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m09:59:03.947321 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:59:03.950565 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m09:59:03.950937 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.010671854019165039s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:03.951179 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.010915756225585938s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:03.951335 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m09:59:03.951640 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orderDate
from `hive_metastore`.`saleslt`.`dim_sales`
where orderDate is null



      
    ) dbt_internal_test
[0m09:59:03.952033 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:04.161077 [debug] [Thread-1 (]: SQL status: OK in 0.210 seconds
[0m09:59:04.164859 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=d78de791-4497-4efc-bbb2-4ec86863155a) - Closing cursor
[0m09:59:04.165427 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:04.165770 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=5.0067901611328125e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:04.166048 [info ] [Thread-1 (]: 9 of 19 PASS not_null_dim_sales_orderDate ...................................... [[32mPASS[0m in 0.22s]
[0m09:59:04.166394 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:59:04.166629 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:59:04.166853 [info ] [Thread-1 (]: 10 of 19 START test not_null_dim_sales_productID ............................... [RUN]
[0m09:59:04.167446 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0015549659729003906s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:04.167833 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, now test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890)
[0m09:59:04.168258 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.002418994903564453s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m09:59:04.168680 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0028510093688964844s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:04.169052 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:59:04.173497 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m09:59:04.173947 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:59:04.175621 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m09:59:04.176032 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.010252237319946289s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:04.176246 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.010490894317626953s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:04.176394 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m09:59:04.176616 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select productID
from `hive_metastore`.`saleslt`.`dim_sales`
where productID is null



      
    ) dbt_internal_test
[0m09:59:04.176849 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:04.371646 [debug] [Thread-1 (]: SQL status: OK in 0.190 seconds
[0m09:59:04.376256 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=f2405656-9216-45a8-80fb-116caf4607a9) - Closing cursor
[0m09:59:04.376933 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:04.377300 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:04.377586 [info ] [Thread-1 (]: 10 of 19 PASS not_null_dim_sales_productID ..................................... [[32mPASS[0m in 0.21s]
[0m09:59:04.377965 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:59:04.378215 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:59:04.378485 [info ] [Thread-1 (]: 11 of 19 START test not_null_dim_sales_productNumber ........................... [RUN]
[0m09:59:04.378868 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0015370845794677734s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:04.379052 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, now test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd)
[0m09:59:04.379259 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.001961231231689453s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m09:59:04.379593 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.0022530555725097656s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:04.379897 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:59:04.384265 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m09:59:04.384836 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:59:04.386495 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m09:59:04.386884 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.009574174880981445s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:04.387093 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.00980520248413086s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:04.387275 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m09:59:04.387556 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select productNumber
from `hive_metastore`.`saleslt`.`dim_sales`
where productNumber is null



      
    ) dbt_internal_test
[0m09:59:04.387757 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:04.698456 [debug] [Thread-1 (]: SQL status: OK in 0.310 seconds
[0m09:59:04.702000 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=cf2d24c6-fa5a-4b0c-ba14-75abfde1c7a2) - Closing cursor
[0m09:59:04.702970 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=3.0994415283203125e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:04.703616 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:04.704056 [info ] [Thread-1 (]: 11 of 19 PASS not_null_dim_sales_productNumber ................................. [[32mPASS[0m in 0.33s]
[0m09:59:04.704407 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:59:04.704661 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:59:04.704924 [info ] [Thread-1 (]: 12 of 19 START test not_null_dim_sales_sellStartDate ........................... [RUN]
[0m09:59:04.705289 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.0017580986022949219s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:04.705485 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, now test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118)
[0m09:59:04.705704 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0021703243255615234s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m09:59:04.705921 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0023941993713378906s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:04.706246 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:59:04.709588 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m09:59:04.710407 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:59:04.712698 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m09:59:04.713093 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.009560108184814453s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:04.713301 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.009785175323486328s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:04.713455 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m09:59:04.713671 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select sellStartDate
from `hive_metastore`.`saleslt`.`dim_sales`
where sellStartDate is null



      
    ) dbt_internal_test
[0m09:59:04.713890 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:04.982465 [debug] [Thread-1 (]: SQL status: OK in 0.270 seconds
[0m09:59:04.984653 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=dc087c60-6b7d-427d-8ae9-768f258c3928) - Closing cursor
[0m09:59:04.985161 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:04.985497 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:04.985766 [info ] [Thread-1 (]: 12 of 19 PASS not_null_dim_sales_sellStartDate ................................. [[32mPASS[0m in 0.28s]
[0m09:59:04.986370 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:59:04.986816 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:59:04.987288 [info ] [Thread-1 (]: 13 of 19 START test not_null_dim_sales_standardCost ............................ [RUN]
[0m09:59:04.987889 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0023469924926757812s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:04.988189 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, now test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3)
[0m09:59:04.988487 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0029938220977783203s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m09:59:04.988704 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0032129287719726562s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:04.988890 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:59:04.992536 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m09:59:04.993160 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:59:04.994981 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m09:59:04.995379 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.009881973266601562s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:04.995607 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.010125875473022461s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:04.995768 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m09:59:04.995992 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select standardCost
from `hive_metastore`.`saleslt`.`dim_sales`
where standardCost is null



      
    ) dbt_internal_test
[0m09:59:04.996220 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:05.192708 [debug] [Thread-1 (]: SQL status: OK in 0.200 seconds
[0m09:59:05.196466 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=fd7397e4-3643-4dee-bb57-43b804ec764e) - Closing cursor
[0m09:59:05.197086 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:05.197486 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:05.197803 [info ] [Thread-1 (]: 13 of 19 PASS not_null_dim_sales_standardCost .................................. [[32mPASS[0m in 0.21s]
[0m09:59:05.198215 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:59:05.198478 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:59:05.198709 [info ] [Thread-1 (]: 14 of 19 START test not_null_dim_sales_subTotal ................................ [RUN]
[0m09:59:05.199088 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0016100406646728516s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:05.199292 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, now test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487)
[0m09:59:05.199509 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.00203704833984375s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m09:59:05.199707 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.0022530555725097656s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:05.199907 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:59:05.202989 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m09:59:05.203442 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:59:05.206781 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m09:59:05.207212 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.009736061096191406s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:05.207429 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.009971141815185547s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:05.207583 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m09:59:05.207792 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select subTotal
from `hive_metastore`.`saleslt`.`dim_sales`
where subTotal is null



      
    ) dbt_internal_test
[0m09:59:05.208005 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:05.479237 [debug] [Thread-1 (]: SQL status: OK in 0.270 seconds
[0m09:59:05.481722 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=1d633f4b-9e6f-44eb-8a56-869a21202d7a) - Closing cursor
[0m09:59:05.482411 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=1.6689300537109375e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:05.482968 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:05.483423 [info ] [Thread-1 (]: 14 of 19 PASS not_null_dim_sales_subTotal ...................................... [[32mPASS[0m in 0.28s]
[0m09:59:05.484016 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:59:05.484392 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:59:05.484826 [info ] [Thread-1 (]: 15 of 19 START test not_null_dim_sales_taxAmt .................................. [RUN]
[0m09:59:05.485226 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.0023009777069091797s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:05.485445 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, now test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a)
[0m09:59:05.485703 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.002782106399536133s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m09:59:05.485939 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.003022909164428711s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:05.486159 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:59:05.490215 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m09:59:05.490898 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:59:05.492550 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m09:59:05.492984 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.010059118270874023s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:05.493203 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.010296821594238281s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:05.493359 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m09:59:05.493563 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select taxAmt
from `hive_metastore`.`saleslt`.`dim_sales`
where taxAmt is null



      
    ) dbt_internal_test
[0m09:59:05.493768 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:05.801541 [debug] [Thread-1 (]: SQL status: OK in 0.310 seconds
[0m09:59:05.805726 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=56c899d0-d774-406d-ac02-0a3c5581a9b6) - Closing cursor
[0m09:59:05.806306 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:05.806646 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:05.806932 [info ] [Thread-1 (]: 15 of 19 PASS not_null_dim_sales_taxAmt ........................................ [[32mPASS[0m in 0.32s]
[0m09:59:05.807273 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:59:05.807584 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:59:05.808056 [info ] [Thread-1 (]: 16 of 19 START test not_null_dim_sales_totalDue ................................ [RUN]
[0m09:59:05.808710 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.001984119415283203s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:05.809070 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, now test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023)
[0m09:59:05.809463 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.002769947052001953s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m09:59:05.809816 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.003119945526123047s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:05.810003 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:59:05.813789 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m09:59:05.814264 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:59:05.815955 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m09:59:05.816364 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.009703874588012695s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:05.816600 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.009953022003173828s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:05.816750 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m09:59:05.816953 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select totalDue
from `hive_metastore`.`saleslt`.`dim_sales`
where totalDue is null



      
    ) dbt_internal_test
[0m09:59:05.817164 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:06.095576 [debug] [Thread-1 (]: SQL status: OK in 0.280 seconds
[0m09:59:06.100547 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=c5d58049-5d03-4e7d-8c1e-196993bce96d) - Closing cursor
[0m09:59:06.101096 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:06.101430 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:06.101695 [info ] [Thread-1 (]: 16 of 19 PASS not_null_dim_sales_totalDue ...................................... [[32mPASS[0m in 0.29s]
[0m09:59:06.102044 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:59:06.102280 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:59:06.102599 [info ] [Thread-1 (]: 17 of 19 START test not_null_dim_sales_unitPrice ............................... [RUN]
[0m09:59:06.102981 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.0015418529510498047s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:06.103187 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, now test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a)
[0m09:59:06.103420 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.0019659996032714844s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m09:59:06.103769 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.0022962093353271484s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:06.104094 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:59:06.108192 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m09:59:06.108788 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:59:06.110425 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m09:59:06.110808 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.009377002716064453s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:06.111025 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.009603261947631836s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:06.111195 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m09:59:06.111477 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select unitPrice
from `hive_metastore`.`saleslt`.`dim_sales`
where unitPrice is null



      
    ) dbt_internal_test
[0m09:59:06.111716 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:06.298749 [debug] [Thread-1 (]: SQL status: OK in 0.190 seconds
[0m09:59:06.304069 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=4da171b0-0627-4fc4-9415-8172ea5f6ec5) - Closing cursor
[0m09:59:06.304670 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:06.305027 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=7.152557373046875e-07s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:06.305295 [info ] [Thread-1 (]: 17 of 19 PASS not_null_dim_sales_unitPrice ..................................... [[32mPASS[0m in 0.20s]
[0m09:59:06.305630 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:59:06.306076 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108
[0m09:59:06.306373 [info ] [Thread-1 (]: 18 of 19 START test unique_dim_sales_SalesOrderDetailID ........................ [RUN]
[0m09:59:06.306763 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.0017180442810058594s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:06.306961 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, now test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108)
[0m09:59:06.307187 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=0.002154111862182617s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m09:59:06.307404 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=0.002376079559326172s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:06.307591 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108
[0m09:59:06.313055 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108"
[0m09:59:06.313530 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108
[0m09:59:06.315504 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108"
[0m09:59:06.315979 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=0.010927915573120117s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:06.316204 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=0.011181831359863281s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:06.316395 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108"
[0m09:59:06.316619 [debug] [Thread-1 (]: On test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    SalesOrderDetailID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where SalesOrderDetailID is not null
group by SalesOrderDetailID
having count(*) > 1



      
    ) dbt_internal_test
[0m09:59:06.316835 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:06.811114 [debug] [Thread-1 (]: SQL status: OK in 0.490 seconds
[0m09:59:06.815373 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=98dd216f-075e-427f-ad5f-aba202e1f2f1) - Closing cursor
[0m09:59:06.816170 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=2.86102294921875e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:06.816772 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=7.152557373046875e-07s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:06.817153 [info ] [Thread-1 (]: 18 of 19 PASS unique_dim_sales_SalesOrderDetailID .............................. [[32mPASS[0m in 0.51s]
[0m09:59:06.817510 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108
[0m09:59:06.817770 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef
[0m09:59:06.818032 [info ] [Thread-1 (]: 19 of 19 START test unique_dim_sales_SalesOrderID .............................. [RUN]
[0m09:59:06.818356 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=0.0016536712646484375s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:06.818545 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, now test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef)
[0m09:59:06.818763 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef, idle-time=0.002054929733276367s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108
[0m09:59:06.818974 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef, idle-time=0.0022788047790527344s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Acquired connection on thread (7203, 6325039104), using default compute resource for model 'None'
[0m09:59:06.819160 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef
[0m09:59:06.824306 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef"
[0m09:59:06.825096 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef
[0m09:59:06.826878 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef"
[0m09:59:06.827377 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef, idle-time=0.010670900344848633s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Checking idleness
[0m09:59:06.827635 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef, idle-time=0.010919809341430664s, acquire-count=1, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Retrieving connection
[0m09:59:06.827840 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef"
[0m09:59:06.828184 [debug] [Thread-1 (]: On test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    SalesOrderID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where SalesOrderID is not null
group by SalesOrderID
having count(*) > 1



      
    ) dbt_internal_test
[0m09:59:06.828580 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=Unknown) - Created cursor
[0m09:59:07.221039 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m09:59:07.225269 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=38d049b6-d516-4906-9607-855e714c9f43, command-id=cabc8e28-9b57-4781-9366-3c48cb8cb8fc) - Closing cursor
[0m09:59:07.226100 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef, idle-time=4.0531158447265625e-06s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:07.226485 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5564161424, session-id=38d049b6-d516-4906-9607-855e714c9f43, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7203, 6325039104), compute-name=) - Released connection
[0m09:59:07.226789 [error] [Thread-1 (]: 19 of 19 FAIL 28 unique_dim_sales_SalesOrderID ................................. [[31mFAIL 28[0m in 0.41s]
[0m09:59:07.227168 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef
[0m09:59:07.228043 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5564136144, session-id=None, name=master, idle-time=5.549201011657715s, acquire-count=0, language=None, thread-identifier=(7203, 8194199360), compute-name=) - Checking idleness
[0m09:59:07.228295 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5564136144, session-id=None, name=master, idle-time=5.549458980560303s, acquire-count=0, language=None, thread-identifier=(7203, 8194199360), compute-name=) - Reusing connection previously named master
[0m09:59:07.228480 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5564136144, session-id=None, name=master, idle-time=5.54965615272522s, acquire-count=1, language=None, thread-identifier=(7203, 8194199360), compute-name=) - Acquired connection on thread (7203, 8194199360), using default compute resource
[0m09:59:07.228671 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5564136144, session-id=None, name=master, idle-time=5.549855947494507s, acquire-count=1, language=None, thread-identifier=(7203, 8194199360), compute-name=) - Checking idleness
[0m09:59:07.228841 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5564136144, session-id=None, name=master, idle-time=5.550025939941406s, acquire-count=1, language=None, thread-identifier=(7203, 8194199360), compute-name=) - Retrieving connection
[0m09:59:07.228990 [debug] [MainThread]: On master: ROLLBACK
[0m09:59:07.229141 [debug] [MainThread]: Opening a new connection, currently in state init
[0m09:59:07.526057 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5564136144, session-id=d39970c9-2a36-41cf-b122-ab4950c35e2e, name=master, idle-time=1.6927719116210938e-05s, acquire-count=1, language=None, thread-identifier=(7203, 8194199360), compute-name=) - Connection created
[0m09:59:07.527051 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:59:07.527471 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5564136144, session-id=d39970c9-2a36-41cf-b122-ab4950c35e2e, name=master, idle-time=0.0017049312591552734s, acquire-count=1, language=None, thread-identifier=(7203, 8194199360), compute-name=) - Checking idleness
[0m09:59:07.527831 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5564136144, session-id=d39970c9-2a36-41cf-b122-ab4950c35e2e, name=master, idle-time=0.0020668506622314453s, acquire-count=1, language=None, thread-identifier=(7203, 8194199360), compute-name=) - Retrieving connection
[0m09:59:07.528157 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m09:59:07.528423 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m09:59:07.528734 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5564136144, session-id=d39970c9-2a36-41cf-b122-ab4950c35e2e, name=master, idle-time=1.9073486328125e-06s, acquire-count=0, language=None, thread-identifier=(7203, 8194199360), compute-name=) - Released connection
[0m09:59:07.529339 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:59:07.529657 [debug] [MainThread]: On master: ROLLBACK
[0m09:59:07.529928 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:59:07.530201 [debug] [MainThread]: On master: Close
[0m09:59:07.530526 [debug] [MainThread]: Databricks adapter: Connection(session-id=d39970c9-2a36-41cf-b122-ab4950c35e2e) - Closing connection
[0m09:59:07.601121 [debug] [MainThread]: Connection 'test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef' was properly closed.
[0m09:59:07.602453 [debug] [MainThread]: On test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef: ROLLBACK
[0m09:59:07.603337 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m09:59:07.603774 [debug] [MainThread]: On test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef: Close
[0m09:59:07.604118 [debug] [MainThread]: Databricks adapter: Connection(session-id=38d049b6-d516-4906-9607-855e714c9f43) - Closing connection
[0m09:59:07.670180 [info ] [MainThread]: 
[0m09:59:07.670561 [info ] [MainThread]: Finished running 19 data tests in 0 hours 0 minutes and 7.14 seconds (7.14s).
[0m09:59:07.672116 [debug] [MainThread]: Command end result
[0m09:59:07.765065 [info ] [MainThread]: 
[0m09:59:07.765474 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m09:59:07.765664 [info ] [MainThread]: 
[0m09:59:07.765900 [error] [MainThread]: [31mFailure in test unique_dim_sales_SalesOrderID (models/marts/sales/dim_sales.yml)[0m
[0m09:59:07.766108 [error] [MainThread]:   Got 28 results, configured to fail if != 0
[0m09:59:07.766256 [info ] [MainThread]: 
[0m09:59:07.766438 [info ] [MainThread]:   compiled code at target/compiled/medallion_dbt_spark/models/marts/sales/dim_sales.yml/unique_dim_sales_SalesOrderID.sql
[0m09:59:07.766607 [info ] [MainThread]: 
[0m09:59:07.766777 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m09:59:07.769934 [debug] [MainThread]: Resource report: {"command_name": "test", "command_wall_clock_time": 9.001416, "process_user_time": 3.059903, "process_kernel_time": 2.28677, "process_mem_max_rss": "229064704", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m09:59:07.770338 [debug] [MainThread]: Command `dbt test` failed at 09:59:07.770280 after 9.00 seconds
[0m09:59:07.770598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102a7e050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102a7ef10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102a26810>]}
[0m09:59:07.770827 [debug] [MainThread]: Flushing usage events
[0m10:06:44.371663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b40f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b41c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b4ffd0>]}


============================== 10:06:44.375008 | d213a36b-82f2-4133-93a6-95adfb05c7c5 ==============================
[0m10:06:44.375008 [info ] [MainThread]: Running with dbt=1.8.5
[0m10:06:44.375444 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/vaishnavitamilvanan/Documents/GW MS DS/Semester/Fall 2024/NLP/PycharmProjects/Medallion-Spark-Azure-DBT/medallion_dbt_spark/logs', 'version_check': 'True', 'profiles_dir': '/Users/vaishnavitamilvanan/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:06:44.476616 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m10:06:44.477144 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m10:06:44.477367 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m10:06:45.621455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd213a36b-82f2-4133-93a6-95adfb05c7c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b64e50>]}
[0m10:06:45.649690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd213a36b-82f2-4133-93a6-95adfb05c7c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12469e090>]}
[0m10:06:45.650127 [info ] [MainThread]: Registered adapter: databricks=1.8.5
[0m10:06:45.671114 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m10:06:45.870720 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:06:45.871060 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:06:45.874909 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.medallion_dbt_spark.example
[0m10:06:45.906437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd213a36b-82f2-4133-93a6-95adfb05c7c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12474cc50>]}
[0m10:06:46.004465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd213a36b-82f2-4133-93a6-95adfb05c7c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124d5e550>]}
[0m10:06:46.004882 [info ] [MainThread]: Found 7 snapshots, 3 models, 19 data tests, 9 sources, 590 macros
[0m10:06:46.005115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd213a36b-82f2-4133-93a6-95adfb05c7c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124d4ba10>]}
[0m10:06:46.006684 [info ] [MainThread]: 
[0m10:06:46.007179 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4908180048, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7268, 8194199360), compute-name=) - Creating connection
[0m10:06:46.007380 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:06:46.007578 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4908180048, session-id=None, name=master, idle-time=2.1457672119140625e-06s, acquire-count=1, language=None, thread-identifier=(7268, 8194199360), compute-name=) - Acquired connection on thread (7268, 8194199360), using default compute resource
[0m10:06:46.011509 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=None, name=list_hive_metastore_snapshots, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Creating connection
[0m10:06:46.011833 [debug] [ThreadPool]: Acquiring new databricks connection 'list_hive_metastore_snapshots'
[0m10:06:46.012130 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=None, name=list_hive_metastore_snapshots, idle-time=3.814697265625e-06s, acquire-count=1, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource
[0m10:06:46.012357 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=None, name=list_hive_metastore_snapshots, idle-time=0.0002460479736328125s, acquire-count=1, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:46.012530 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=None, name=list_hive_metastore_snapshots, idle-time=0.00042700767517089844s, acquire-count=1, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:46.012687 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m10:06:46.012878 [debug] [ThreadPool]: On list_hive_metastore_snapshots: GetTables(database=hive_metastore, schema=snapshots, identifier=None)
[0m10:06:46.013036 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:06:46.690507 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_snapshots, idle-time=8.821487426757812e-06s, acquire-count=1, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Connection created
[0m10:06:46.691730 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:47.419254 [debug] [ThreadPool]: SQL status: OK in 1.410 seconds
[0m10:06:47.430080 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=ebbc3ba5-27ea-4756-b0ad-c8609fc19182) - Closing cursor
[0m10:06:47.440330 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_snapshots, idle-time=0.7501270771026611s, acquire-count=1, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:47.440573 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_snapshots, idle-time=0.7503900527954102s, acquire-count=1, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:47.440778 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_snapshots, idle-time=0.7506000995635986s, acquire-count=1, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:47.440954 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_snapshots, idle-time=0.7507779598236084s, acquire-count=1, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:47.441113 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m10:06:47.441257 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m10:06:47.441421 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */

      select current_catalog()
  
[0m10:06:47.441600 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:47.717647 [debug] [ThreadPool]: SQL status: OK in 0.280 seconds
[0m10:06:47.719662 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=43a725d0-9f16-409c-a7a3-a9d847f47f60) - Closing cursor
[0m10:06:47.724507 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_snapshots, idle-time=1.0343079566955566s, acquire-count=1, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:47.724752 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_snapshots, idle-time=1.0345690250396729s, acquire-count=1, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:47.724923 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m10:06:47.725104 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */
show views in `hive_metastore`.`snapshots`
  
[0m10:06:47.725404 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:47.912884 [debug] [ThreadPool]: SQL status: OK in 0.190 seconds
[0m10:06:47.917125 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=434f8ae4-83f1-4a2f-895b-bd5514ce8233) - Closing cursor
[0m10:06:47.918211 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_snapshots, idle-time=1.0967254638671875e-05s, acquire-count=0, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:47.918773 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_snapshots, idle-time=0.0006039142608642578s, acquire-count=0, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:47.919578 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_hive_metastore_snapshots, now list_hive_metastore_saleslt)
[0m10:06:47.919778 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_saleslt, idle-time=0.0016319751739501953s, acquire-count=0, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named list_hive_metastore_snapshots
[0m10:06:47.919972 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_saleslt, idle-time=0.0018198490142822266s, acquire-count=1, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource
[0m10:06:47.920169 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_saleslt, idle-time=0.0020318031311035156s, acquire-count=1, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:47.920467 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_saleslt, idle-time=0.0022878646850585938s, acquire-count=1, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:47.920765 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m10:06:47.921083 [debug] [ThreadPool]: On list_hive_metastore_saleslt: GetTables(database=hive_metastore, schema=saleslt, identifier=None)
[0m10:06:47.921341 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:48.034742 [debug] [ThreadPool]: SQL status: OK in 0.110 seconds
[0m10:06:48.036481 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=0c33c765-e495-449e-ada1-c0f7c9a626be) - Closing cursor
[0m10:06:48.038123 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_saleslt, idle-time=0.11993908882141113s, acquire-count=1, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:48.038442 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_saleslt, idle-time=0.12027597427368164s, acquire-count=1, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:48.038720 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m10:06:48.038984 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */

      select current_catalog()
  
[0m10:06:48.039252 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:48.326241 [debug] [ThreadPool]: SQL status: OK in 0.290 seconds
[0m10:06:48.327549 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=a2180031-164e-4663-a52e-11dbdaa5ed4f) - Closing cursor
[0m10:06:48.329128 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_saleslt, idle-time=0.4109649658203125s, acquire-count=1, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:48.329373 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_saleslt, idle-time=0.4112229347229004s, acquire-count=1, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:48.329566 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m10:06:48.329766 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */
show views in `hive_metastore`.`saleslt`
  
[0m10:06:48.329966 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:48.636040 [debug] [ThreadPool]: SQL status: OK in 0.310 seconds
[0m10:06:48.639145 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=a946ea13-b7e2-427e-9874-c2bf143bab5c) - Closing cursor
[0m10:06:48.639609 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_saleslt, idle-time=1.1920928955078125e-06s, acquire-count=0, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:48.640884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd213a36b-82f2-4133-93a6-95adfb05c7c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1248ccc50>]}
[0m10:06:48.641199 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4908180048, session-id=None, name=master, idle-time=2.633639335632324s, acquire-count=1, language=None, thread-identifier=(7268, 8194199360), compute-name=) - Checking idleness
[0m10:06:48.641393 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4908180048, session-id=None, name=master, idle-time=2.633838176727295s, acquire-count=1, language=None, thread-identifier=(7268, 8194199360), compute-name=) - Retrieving connection
[0m10:06:48.641579 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4908180048, session-id=None, name=master, idle-time=2.634026050567627s, acquire-count=1, language=None, thread-identifier=(7268, 8194199360), compute-name=) - Checking idleness
[0m10:06:48.641744 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4908180048, session-id=None, name=master, idle-time=2.6341941356658936s, acquire-count=1, language=None, thread-identifier=(7268, 8194199360), compute-name=) - Retrieving connection
[0m10:06:48.641898 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m10:06:48.642043 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m10:06:48.642277 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4908180048, session-id=None, name=master, idle-time=1.9073486328125e-06s, acquire-count=0, language=None, thread-identifier=(7268, 8194199360), compute-name=) - Released connection
[0m10:06:48.642652 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:06:48.642952 [info ] [MainThread]: 
[0m10:06:48.645828 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0
[0m10:06:48.646087 [info ] [Thread-1 (]: 1 of 19 START test not_null_dim_sales_CustomerID ............................... [RUN]
[0m10:06:48.646509 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=list_hive_metastore_saleslt, idle-time=0.00684809684753418s, acquire-count=0, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:48.646744 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_hive_metastore_saleslt, now test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0)
[0m10:06:48.646983 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=0.007354259490966797s, acquire-count=0, language=None, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named list_hive_metastore_saleslt
[0m10:06:48.647187 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=0.0075571537017822266s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:48.647376 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0
[0m10:06:48.659442 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0"
[0m10:06:48.660390 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0
[0m10:06:48.669961 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0"
[0m10:06:48.670580 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=0.03092503547668457s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:48.670835 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=0.031203031539916992s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:48.671000 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0"
[0m10:06:48.671215 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select CustomerID
from `hive_metastore`.`saleslt`.`dim_sales`
where CustomerID is null



      
    ) dbt_internal_test
[0m10:06:48.671513 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:49.045678 [debug] [Thread-1 (]: SQL status: OK in 0.370 seconds
[0m10:06:49.052107 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=aa762a15-68db-4d76-a6ed-44a432ce9e24) - Closing cursor
[0m10:06:49.055007 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=2.86102294921875e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:49.055577 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:49.056018 [info ] [Thread-1 (]: 1 of 19 PASS not_null_dim_sales_CustomerID ..................................... [[32mPASS[0m in 0.41s]
[0m10:06:49.056435 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0
[0m10:06:49.056700 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411
[0m10:06:49.056980 [info ] [Thread-1 (]: 2 of 19 START test not_null_dim_sales_OrderQty ................................. [RUN]
[0m10:06:49.057359 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=0.0018239021301269531s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:49.057562 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, now test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411)
[0m10:06:49.057780 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=0.0022590160369873047s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0
[0m10:06:49.058006 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=0.0024819374084472656s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:49.058210 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411
[0m10:06:49.061401 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411"
[0m10:06:49.062273 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411
[0m10:06:49.065752 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411"
[0m10:06:49.066265 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=0.01073312759399414s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:49.066520 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=0.010980844497680664s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:49.066724 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411"
[0m10:06:49.066988 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select OrderQty
from `hive_metastore`.`saleslt`.`dim_sales`
where OrderQty is null



      
    ) dbt_internal_test
[0m10:06:49.067273 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:49.354588 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m10:06:49.357250 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=f9fb4a4a-8702-433b-95aa-11cdfda266d3) - Closing cursor
[0m10:06:49.357813 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:49.358158 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:49.358433 [info ] [Thread-1 (]: 2 of 19 PASS not_null_dim_sales_OrderQty ....................................... [[32mPASS[0m in 0.30s]
[0m10:06:49.358786 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411
[0m10:06:49.359071 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb
[0m10:06:49.359493 [info ] [Thread-1 (]: 3 of 19 START test not_null_dim_sales_SalesOrderDetailID ....................... [RUN]
[0m10:06:49.360024 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=0.0018107891082763672s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:49.360337 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, now test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb)
[0m10:06:49.360686 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=0.0024847984313964844s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411
[0m10:06:49.360984 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=0.0028247833251953125s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:49.361173 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb
[0m10:06:49.364561 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb"
[0m10:06:49.366459 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb
[0m10:06:49.368749 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb"
[0m10:06:49.369359 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=0.011168956756591797s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:49.369646 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=0.011487960815429688s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:49.369812 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb"
[0m10:06:49.370028 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select SalesOrderDetailID
from `hive_metastore`.`saleslt`.`dim_sales`
where SalesOrderDetailID is null



      
    ) dbt_internal_test
[0m10:06:49.370240 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:49.667242 [debug] [Thread-1 (]: SQL status: OK in 0.300 seconds
[0m10:06:49.671686 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=abcc2096-b9d9-4389-8f5f-921adf6a60f9) - Closing cursor
[0m10:06:49.672317 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:49.672877 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:49.673393 [info ] [Thread-1 (]: 3 of 19 PASS not_null_dim_sales_SalesOrderDetailID ............................. [[32mPASS[0m in 0.31s]
[0m10:06:49.674024 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb
[0m10:06:49.674418 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6
[0m10:06:49.674624 [info ] [Thread-1 (]: 4 of 19 START test not_null_dim_sales_SalesOrderID ............................. [RUN]
[0m10:06:49.674986 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=0.0021660327911376953s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:49.675223 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, now test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6)
[0m10:06:49.675465 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=0.002657175064086914s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb
[0m10:06:49.675688 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=0.0028879642486572266s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:49.675885 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6
[0m10:06:49.679256 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6"
[0m10:06:49.681072 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6
[0m10:06:49.683409 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6"
[0m10:06:49.683894 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=0.011092185974121094s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:49.684119 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=0.011323928833007812s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:49.684284 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6"
[0m10:06:49.684574 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select SalesOrderID
from `hive_metastore`.`saleslt`.`dim_sales`
where SalesOrderID is null



      
    ) dbt_internal_test
[0m10:06:49.684861 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:49.892182 [debug] [Thread-1 (]: SQL status: OK in 0.210 seconds
[0m10:06:49.895610 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=0e710e7e-6060-4264-a6e5-bc8a38b828e6) - Closing cursor
[0m10:06:49.896456 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=5.245208740234375e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:49.897094 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:49.897618 [info ] [Thread-1 (]: 4 of 19 PASS not_null_dim_sales_SalesOrderID ................................... [[32mPASS[0m in 0.22s]
[0m10:06:49.898066 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6
[0m10:06:49.898315 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m10:06:49.898588 [info ] [Thread-1 (]: 5 of 19 START test not_null_dim_sales_freight .................................. [RUN]
[0m10:06:49.898932 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=0.0019030570983886719s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:49.899120 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, now test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131)
[0m10:06:49.899344 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.002318143844604492s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6
[0m10:06:49.899567 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.0025451183319091797s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:49.899795 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m10:06:49.903246 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m10:06:49.905498 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m10:06:49.907427 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m10:06:49.908260 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.011188030242919922s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:49.908685 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.011633157730102539s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:49.908973 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m10:06:49.909311 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select freight
from `hive_metastore`.`saleslt`.`dim_sales`
where freight is null



      
    ) dbt_internal_test
[0m10:06:49.909579 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:50.173560 [debug] [Thread-1 (]: SQL status: OK in 0.260 seconds
[0m10:06:50.175550 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=2aa786a3-5287-4275-b263-a9ce99539367) - Closing cursor
[0m10:06:50.176006 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:50.176314 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:50.176576 [info ] [Thread-1 (]: 5 of 19 PASS not_null_dim_sales_freight ........................................ [[32mPASS[0m in 0.28s]
[0m10:06:50.176904 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m10:06:50.177151 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m10:06:50.177467 [info ] [Thread-1 (]: 6 of 19 START test not_null_dim_sales_lineTotal ................................ [RUN]
[0m10:06:50.178022 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.0016460418701171875s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:50.178329 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, now test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8)
[0m10:06:50.178688 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.002318859100341797s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m10:06:50.179047 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.0026848316192626953s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:50.179391 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m10:06:50.182644 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m10:06:50.183201 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m10:06:50.185021 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m10:06:50.185883 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.009503841400146484s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:50.186237 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.009898900985717773s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:50.186501 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m10:06:50.186835 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select lineTotal
from `hive_metastore`.`saleslt`.`dim_sales`
where lineTotal is null



      
    ) dbt_internal_test
[0m10:06:50.187129 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:50.480790 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m10:06:50.484472 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=32f8fd4c-5cc9-4b93-a314-ae9f9c868374) - Closing cursor
[0m10:06:50.485058 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:50.485398 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:50.485825 [info ] [Thread-1 (]: 6 of 19 PASS not_null_dim_sales_lineTotal ...................................... [[32mPASS[0m in 0.31s]
[0m10:06:50.486363 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m10:06:50.486745 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m10:06:50.487122 [info ] [Thread-1 (]: 7 of 19 START test not_null_dim_sales_listPrice ................................ [RUN]
[0m10:06:50.487486 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.0020759105682373047s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:50.487674 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, now test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f)
[0m10:06:50.487894 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.002499103546142578s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m10:06:50.488113 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.0027151107788085938s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:50.488311 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m10:06:50.491540 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m10:06:50.492081 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m10:06:50.495804 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m10:06:50.496261 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.01086115837097168s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:50.496482 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.011092901229858398s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:50.496640 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m10:06:50.496861 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select listPrice
from `hive_metastore`.`saleslt`.`dim_sales`
where listPrice is null



      
    ) dbt_internal_test
[0m10:06:50.497167 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:50.707080 [debug] [Thread-1 (]: SQL status: OK in 0.210 seconds
[0m10:06:50.711252 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=f451bf53-902e-4774-9686-8b969dc80fa4) - Closing cursor
[0m10:06:50.711811 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:50.712132 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:50.712387 [info ] [Thread-1 (]: 7 of 19 PASS not_null_dim_sales_listPrice ...................................... [[32mPASS[0m in 0.22s]
[0m10:06:50.712725 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m10:06:50.712985 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m10:06:50.713303 [info ] [Thread-1 (]: 8 of 19 START test not_null_dim_sales_name ..................................... [RUN]
[0m10:06:50.713710 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.0015642642974853516s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:50.713928 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, now test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77)
[0m10:06:50.714281 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0020961761474609375s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m10:06:50.714632 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.002457141876220703s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:50.714949 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m10:06:50.719303 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m10:06:50.719750 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m10:06:50.721356 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m10:06:50.721749 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.009612083435058594s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:50.722004 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.009851217269897461s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:50.722199 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m10:06:50.722403 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select name
from `hive_metastore`.`saleslt`.`dim_sales`
where name is null



      
    ) dbt_internal_test
[0m10:06:50.722611 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:50.993193 [debug] [Thread-1 (]: SQL status: OK in 0.270 seconds
[0m10:06:50.996665 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=ca6d255f-8877-4d7d-8cce-db55c0aa6a52) - Closing cursor
[0m10:06:50.997335 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=3.0994415283203125e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:50.997918 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:50.998191 [info ] [Thread-1 (]: 8 of 19 PASS not_null_dim_sales_name ........................................... [[32mPASS[0m in 0.28s]
[0m10:06:50.998565 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m10:06:50.998814 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m10:06:50.999093 [info ] [Thread-1 (]: 9 of 19 START test not_null_dim_sales_orderDate ................................ [RUN]
[0m10:06:50.999472 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0015778541564941406s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:50.999677 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, now test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3)
[0m10:06:50.999897 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.002009153366088867s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m10:06:51.000117 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0022351741790771484s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:51.000314 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m10:06:51.004484 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m10:06:51.004896 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m10:06:51.006728 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m10:06:51.007650 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.009204864501953125s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:51.009624 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.011077165603637695s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:51.010377 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m10:06:51.011230 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orderDate
from `hive_metastore`.`saleslt`.`dim_sales`
where orderDate is null



      
    ) dbt_internal_test
[0m10:06:51.012093 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:51.187000 [debug] [Thread-1 (]: SQL status: OK in 0.170 seconds
[0m10:06:51.189101 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=c796fb11-a11e-49ea-a7cd-dcdd476d88a4) - Closing cursor
[0m10:06:51.189794 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:51.190161 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:51.190438 [info ] [Thread-1 (]: 9 of 19 PASS not_null_dim_sales_orderDate ...................................... [[32mPASS[0m in 0.19s]
[0m10:06:51.190777 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m10:06:51.191018 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m10:06:51.191261 [info ] [Thread-1 (]: 10 of 19 START test not_null_dim_sales_productID ............................... [RUN]
[0m10:06:51.191594 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.001435995101928711s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:51.191779 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, now test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890)
[0m10:06:51.191986 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0018320083618164062s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m10:06:51.192211 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0020570755004882812s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:51.192416 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m10:06:51.196081 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m10:06:51.196713 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m10:06:51.198987 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m10:06:51.199499 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.009333133697509766s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:51.199723 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.00957179069519043s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:51.199880 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m10:06:51.200091 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select productID
from `hive_metastore`.`saleslt`.`dim_sales`
where productID is null



      
    ) dbt_internal_test
[0m10:06:51.200314 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:51.414139 [debug] [Thread-1 (]: SQL status: OK in 0.210 seconds
[0m10:06:51.418680 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=d699e8da-8f10-4e85-bc98-469de5b6163b) - Closing cursor
[0m10:06:51.419264 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:51.419608 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:51.420024 [info ] [Thread-1 (]: 10 of 19 PASS not_null_dim_sales_productID ..................................... [[32mPASS[0m in 0.23s]
[0m10:06:51.420627 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m10:06:51.421063 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m10:06:51.421581 [info ] [Thread-1 (]: 11 of 19 START test not_null_dim_sales_productNumber ........................... [RUN]
[0m10:06:51.421979 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0023610591888427734s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:51.422199 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, now test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd)
[0m10:06:51.422421 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.002810955047607422s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m10:06:51.422640 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.003030061721801758s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:51.422833 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m10:06:51.426191 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m10:06:51.426645 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m10:06:51.428509 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m10:06:51.429096 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.009457111358642578s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:51.429387 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.009763002395629883s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:51.429596 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m10:06:51.429885 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select productNumber
from `hive_metastore`.`saleslt`.`dim_sales`
where productNumber is null



      
    ) dbt_internal_test
[0m10:06:51.430164 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:51.810024 [debug] [Thread-1 (]: SQL status: OK in 0.380 seconds
[0m10:06:51.812477 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=fafe380d-7384-4b4f-b650-3cca3cbec915) - Closing cursor
[0m10:06:51.813062 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:51.813438 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:51.813735 [info ] [Thread-1 (]: 11 of 19 PASS not_null_dim_sales_productNumber ................................. [[32mPASS[0m in 0.39s]
[0m10:06:51.814083 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m10:06:51.814323 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m10:06:51.814647 [info ] [Thread-1 (]: 12 of 19 START test not_null_dim_sales_sellStartDate ........................... [RUN]
[0m10:06:51.815175 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.001714944839477539s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:51.815475 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, now test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118)
[0m10:06:51.815830 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0023758411407470703s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m10:06:51.816176 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0027251243591308594s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:51.816486 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m10:06:51.819890 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m10:06:51.821233 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m10:06:51.825374 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m10:06:51.825998 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.012560844421386719s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:51.826244 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.012839794158935547s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:51.826483 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m10:06:51.826787 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select sellStartDate
from `hive_metastore`.`saleslt`.`dim_sales`
where sellStartDate is null



      
    ) dbt_internal_test
[0m10:06:51.827085 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:52.012230 [debug] [Thread-1 (]: SQL status: OK in 0.180 seconds
[0m10:06:52.018373 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=690fa75c-8077-4883-8639-03aa968cb7dd) - Closing cursor
[0m10:06:52.019599 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=2.86102294921875e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:52.020058 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:52.020314 [info ] [Thread-1 (]: 12 of 19 PASS not_null_dim_sales_sellStartDate ................................. [[32mPASS[0m in 0.21s]
[0m10:06:52.020649 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m10:06:52.020896 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m10:06:52.021142 [info ] [Thread-1 (]: 13 of 19 START test not_null_dim_sales_standardCost ............................ [RUN]
[0m10:06:52.021489 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.001435995101928711s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:52.021676 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, now test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3)
[0m10:06:52.021889 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0018420219421386719s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m10:06:52.022096 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0020580291748046875s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:52.022282 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m10:06:52.026129 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m10:06:52.026738 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m10:06:52.029018 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m10:06:52.029457 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.009406089782714844s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:52.029670 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.009636163711547852s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:52.029821 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m10:06:52.030026 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select standardCost
from `hive_metastore`.`saleslt`.`dim_sales`
where standardCost is null



      
    ) dbt_internal_test
[0m10:06:52.030229 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:52.527596 [debug] [Thread-1 (]: SQL status: OK in 0.500 seconds
[0m10:06:52.531841 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=05034d8c-02e7-428f-a1d8-c473fab85ba4) - Closing cursor
[0m10:06:52.532456 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=6.9141387939453125e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:52.532792 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:52.533069 [info ] [Thread-1 (]: 13 of 19 PASS not_null_dim_sales_standardCost .................................. [[32mPASS[0m in 0.51s]
[0m10:06:52.533409 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m10:06:52.533656 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m10:06:52.533864 [info ] [Thread-1 (]: 14 of 19 START test not_null_dim_sales_subTotal ................................ [RUN]
[0m10:06:52.534152 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0013599395751953125s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:52.534480 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, now test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487)
[0m10:06:52.534883 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.0020411014556884766s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m10:06:52.535247 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.0024139881134033203s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:52.535567 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m10:06:52.539099 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m10:06:52.539650 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m10:06:52.541314 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m10:06:52.542889 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.010043859481811523s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:52.543232 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.010419845581054688s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:52.543448 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m10:06:52.543754 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select subTotal
from `hive_metastore`.`saleslt`.`dim_sales`
where subTotal is null



      
    ) dbt_internal_test
[0m10:06:52.544039 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:52.834710 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m10:06:52.839011 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=604cbff5-a21b-4cd2-bd84-2bceca98388d) - Closing cursor
[0m10:06:52.839620 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=7.152557373046875e-07s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:52.839957 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:52.840239 [info ] [Thread-1 (]: 14 of 19 PASS not_null_dim_sales_subTotal ...................................... [[32mPASS[0m in 0.31s]
[0m10:06:52.840585 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m10:06:52.840839 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m10:06:52.841119 [info ] [Thread-1 (]: 15 of 19 START test not_null_dim_sales_taxAmt .................................. [RUN]
[0m10:06:52.841477 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.0015060901641845703s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:52.841663 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, now test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a)
[0m10:06:52.842003 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.0019998550415039062s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m10:06:52.842355 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.0023517608642578125s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:52.842676 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m10:06:52.846420 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m10:06:52.847042 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m10:06:52.848933 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m10:06:52.849608 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.00962519645690918s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:52.849845 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.009886980056762695s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:52.850009 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m10:06:52.850224 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select taxAmt
from `hive_metastore`.`saleslt`.`dim_sales`
where taxAmt is null



      
    ) dbt_internal_test
[0m10:06:52.850436 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:53.246482 [debug] [Thread-1 (]: SQL status: OK in 0.400 seconds
[0m10:06:53.251248 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=60f7be6b-c006-47da-9fd6-3030cb5a4ee0) - Closing cursor
[0m10:06:53.251813 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:53.252217 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:53.252713 [info ] [Thread-1 (]: 15 of 19 PASS not_null_dim_sales_taxAmt ........................................ [[32mPASS[0m in 0.41s]
[0m10:06:53.253219 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m10:06:53.253455 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m10:06:53.253713 [info ] [Thread-1 (]: 16 of 19 START test not_null_dim_sales_totalDue ................................ [RUN]
[0m10:06:53.254070 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.0019121170043945312s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:53.254264 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, now test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023)
[0m10:06:53.254481 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.0023331642150878906s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m10:06:53.254701 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.0025582313537597656s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:53.254900 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m10:06:53.258443 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m10:06:53.259088 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m10:06:53.260884 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m10:06:53.261429 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.009238004684448242s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:53.261728 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.009566307067871094s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:53.261885 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m10:06:53.262092 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select totalDue
from `hive_metastore`.`saleslt`.`dim_sales`
where totalDue is null



      
    ) dbt_internal_test
[0m10:06:53.262297 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:53.550863 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m10:06:53.554194 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=38952f74-6964-4bbd-a213-2d1aefb5e10a) - Closing cursor
[0m10:06:53.554898 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=2.86102294921875e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:53.555271 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:53.555559 [info ] [Thread-1 (]: 16 of 19 PASS not_null_dim_sales_totalDue ...................................... [[32mPASS[0m in 0.30s]
[0m10:06:53.555912 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m10:06:53.556312 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m10:06:53.556738 [info ] [Thread-1 (]: 17 of 19 START test not_null_dim_sales_unitPrice ............................... [RUN]
[0m10:06:53.557320 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.0019903182983398438s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:53.557628 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, now test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a)
[0m10:06:53.557929 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.0026559829711914062s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m10:06:53.558144 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.0028760433197021484s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:53.558337 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m10:06:53.562056 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m10:06:53.563571 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m10:06:53.567864 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m10:06:53.568723 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.013412237167358398s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:53.569018 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.013735055923461914s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:53.569209 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m10:06:53.569487 [debug] [Thread-1 (]: On test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select unitPrice
from `hive_metastore`.`saleslt`.`dim_sales`
where unitPrice is null



      
    ) dbt_internal_test
[0m10:06:53.569732 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:53.859877 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m10:06:53.863972 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=98156599-46f5-4eb5-acf4-00ebf183b278) - Closing cursor
[0m10:06:53.864531 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:53.864848 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:53.865121 [info ] [Thread-1 (]: 17 of 19 PASS not_null_dim_sales_unitPrice ..................................... [[32mPASS[0m in 0.31s]
[0m10:06:53.865652 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m10:06:53.865941 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108
[0m10:06:53.866195 [info ] [Thread-1 (]: 18 of 19 START test unique_dim_sales_SalesOrderDetailID ........................ [RUN]
[0m10:06:53.866498 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.00164794921875s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:53.866671 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, now test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108)
[0m10:06:53.866877 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=0.002023935317993164s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m10:06:53.867082 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=0.002234220504760742s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:53.867274 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108
[0m10:06:53.872820 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108"
[0m10:06:53.873558 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108
[0m10:06:53.875471 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108"
[0m10:06:53.876260 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=0.011364221572875977s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:53.876599 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=0.011751890182495117s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:53.876755 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108"
[0m10:06:53.876984 [debug] [Thread-1 (]: On test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    SalesOrderDetailID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where SalesOrderDetailID is not null
group by SalesOrderDetailID
having count(*) > 1



      
    ) dbt_internal_test
[0m10:06:53.877316 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:54.165939 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m10:06:54.169548 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=728a33e1-ef8a-4edd-a3bf-34f2f20ce3c3) - Closing cursor
[0m10:06:54.170299 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:54.170644 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:54.170933 [info ] [Thread-1 (]: 18 of 19 PASS unique_dim_sales_SalesOrderDetailID .............................. [[32mPASS[0m in 0.30s]
[0m10:06:54.171277 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108
[0m10:06:54.171537 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef
[0m10:06:54.171795 [info ] [Thread-1 (]: 19 of 19 START test unique_dim_sales_SalesOrderID .............................. [RUN]
[0m10:06:54.172134 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=0.0014958381652832031s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:54.172316 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, now test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef)
[0m10:06:54.172528 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef, idle-time=0.0018868446350097656s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108
[0m10:06:54.172737 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef, idle-time=0.0021038055419921875s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Acquired connection on thread (7268, 6161903616), using default compute resource for model 'None'
[0m10:06:54.172934 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef
[0m10:06:54.176693 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef"
[0m10:06:54.178310 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef
[0m10:06:54.180298 [debug] [Thread-1 (]: Writing runtime sql for node "test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef"
[0m10:06:54.180749 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef, idle-time=0.010082721710205078s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Checking idleness
[0m10:06:54.180989 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef, idle-time=0.01034688949584961s, acquire-count=1, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Retrieving connection
[0m10:06:54.181159 [debug] [Thread-1 (]: Using databricks connection "test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef"
[0m10:06:54.181372 [debug] [Thread-1 (]: On test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "node_id": "test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    SalesOrderID as unique_field,
    count(*) as n_records

from `hive_metastore`.`saleslt`.`dim_sales`
where SalesOrderID is not null
group by SalesOrderID
having count(*) > 1



      
    ) dbt_internal_test
[0m10:06:54.181590 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=Unknown) - Created cursor
[0m10:06:54.472384 [debug] [Thread-1 (]: SQL status: OK in 0.290 seconds
[0m10:06:54.475914 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=2bc15786-1c0e-4133-aca3-098020a55bec, command-id=f555bfbc-e521-4e1f-abe3-ac8070c3b451) - Closing cursor
[0m10:06:54.476733 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef, idle-time=1.9073486328125e-06s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:54.477335 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=4910864720, session-id=2bc15786-1c0e-4133-aca3-098020a55bec, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7268, 6161903616), compute-name=) - Released connection
[0m10:06:54.477845 [error] [Thread-1 (]: 19 of 19 FAIL 28 unique_dim_sales_SalesOrderID ................................. [[31mFAIL 28[0m in 0.31s]
[0m10:06:54.478212 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef
[0m10:06:54.479189 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4908180048, session-id=None, name=master, idle-time=5.83688497543335s, acquire-count=0, language=None, thread-identifier=(7268, 8194199360), compute-name=) - Checking idleness
[0m10:06:54.479573 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4908180048, session-id=None, name=master, idle-time=5.83730411529541s, acquire-count=0, language=None, thread-identifier=(7268, 8194199360), compute-name=) - Reusing connection previously named master
[0m10:06:54.479792 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4908180048, session-id=None, name=master, idle-time=5.837524890899658s, acquire-count=1, language=None, thread-identifier=(7268, 8194199360), compute-name=) - Acquired connection on thread (7268, 8194199360), using default compute resource
[0m10:06:54.480100 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4908180048, session-id=None, name=master, idle-time=5.837822914123535s, acquire-count=1, language=None, thread-identifier=(7268, 8194199360), compute-name=) - Checking idleness
[0m10:06:54.480389 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4908180048, session-id=None, name=master, idle-time=5.838106870651245s, acquire-count=1, language=None, thread-identifier=(7268, 8194199360), compute-name=) - Retrieving connection
[0m10:06:54.480646 [debug] [MainThread]: On master: ROLLBACK
[0m10:06:54.480875 [debug] [MainThread]: Opening a new connection, currently in state init
[0m10:06:54.657776 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4908180048, session-id=263c266f-f1eb-4ec1-816c-341e016c84f1, name=master, idle-time=4.0531158447265625e-06s, acquire-count=1, language=None, thread-identifier=(7268, 8194199360), compute-name=) - Connection created
[0m10:06:54.658108 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m10:06:54.658307 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4908180048, session-id=263c266f-f1eb-4ec1-816c-341e016c84f1, name=master, idle-time=0.0006160736083984375s, acquire-count=1, language=None, thread-identifier=(7268, 8194199360), compute-name=) - Checking idleness
[0m10:06:54.658494 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4908180048, session-id=263c266f-f1eb-4ec1-816c-341e016c84f1, name=master, idle-time=0.0008060932159423828s, acquire-count=1, language=None, thread-identifier=(7268, 8194199360), compute-name=) - Retrieving connection
[0m10:06:54.658650 [debug] [MainThread]: Spark adapter: NotImplemented: add_begin_query
[0m10:06:54.658794 [debug] [MainThread]: Spark adapter: NotImplemented: commit
[0m10:06:54.658962 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4908180048, session-id=263c266f-f1eb-4ec1-816c-341e016c84f1, name=master, idle-time=9.5367431640625e-07s, acquire-count=0, language=None, thread-identifier=(7268, 8194199360), compute-name=) - Released connection
[0m10:06:54.659193 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:06:54.659352 [debug] [MainThread]: On master: ROLLBACK
[0m10:06:54.659494 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m10:06:54.659633 [debug] [MainThread]: On master: Close
[0m10:06:54.659840 [debug] [MainThread]: Databricks adapter: Connection(session-id=263c266f-f1eb-4ec1-816c-341e016c84f1) - Closing connection
[0m10:06:54.715101 [debug] [MainThread]: Connection 'test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef' was properly closed.
[0m10:06:54.716000 [debug] [MainThread]: On test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef: ROLLBACK
[0m10:06:54.716436 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m10:06:54.716773 [debug] [MainThread]: On test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef: Close
[0m10:06:54.717117 [debug] [MainThread]: Databricks adapter: Connection(session-id=2bc15786-1c0e-4133-aca3-098020a55bec) - Closing connection
[0m10:06:54.772755 [info ] [MainThread]: 
[0m10:06:54.773430 [info ] [MainThread]: Finished running 19 data tests in 0 hours 0 minutes and 8.77 seconds (8.77s).
[0m10:06:54.776693 [debug] [MainThread]: Command end result
[0m10:06:54.810385 [info ] [MainThread]: 
[0m10:06:54.810676 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m10:06:54.810854 [info ] [MainThread]: 
[0m10:06:54.811077 [error] [MainThread]: [31mFailure in test unique_dim_sales_SalesOrderID (models/marts/sales/dim_sales.yml)[0m
[0m10:06:54.811270 [error] [MainThread]:   Got 28 results, configured to fail if != 0
[0m10:06:54.811424 [info ] [MainThread]: 
[0m10:06:54.811611 [info ] [MainThread]:   compiled code at target/compiled/medallion_dbt_spark/models/marts/sales/dim_sales.yml/unique_dim_sales_SalesOrderID.sql
[0m10:06:54.811784 [info ] [MainThread]: 
[0m10:06:54.811945 [info ] [MainThread]: Done. PASS=18 WARN=0 ERROR=1 SKIP=0 TOTAL=19
[0m10:06:54.814324 [debug] [MainThread]: Resource report: {"command_name": "test", "command_wall_clock_time": 10.510817, "process_user_time": 2.916506, "process_kernel_time": 2.18223, "process_mem_max_rss": "222789632", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m10:06:54.814699 [debug] [MainThread]: Command `dbt test` failed at 10:06:54.814643 after 10.51 seconds
[0m10:06:54.814944 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b4fe10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ae7e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102aeebd0>]}
[0m10:06:54.815177 [debug] [MainThread]: Flushing usage events
[0m10:44:11.540302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110959610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110959990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109d19d0>]}


============================== 10:44:11.544286 | 9116e986-78e6-4467-8646-17bf90dd5761 ==============================
[0m10:44:11.544286 [info ] [MainThread]: Running with dbt=1.8.5
[0m10:44:11.544790 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/vaishnavitamilvanan/Documents/GW MS DS/Semester/Fall 2024/NLP/PycharmProjects/Medallion-Spark-Azure-DBT/medallion_dbt_spark/logs', 'profiles_dir': '/Users/vaishnavitamilvanan/.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt docs generate', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:44:11.645743 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m10:44:11.646319 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m10:44:11.646546 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m10:44:12.937443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9116e986-78e6-4467-8646-17bf90dd5761', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x153f8fcd0>]}
[0m10:44:12.965893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9116e986-78e6-4467-8646-17bf90dd5761', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x153f16610>]}
[0m10:44:12.966341 [info ] [MainThread]: Registered adapter: databricks=1.8.5
[0m10:44:13.008070 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m10:44:13.212473 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:44:13.212837 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:44:13.216792 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.medallion_dbt_spark.example
[0m10:44:13.248619 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9116e986-78e6-4467-8646-17bf90dd5761', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1541fb510>]}
[0m10:44:13.264489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9116e986-78e6-4467-8646-17bf90dd5761', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1540a1f50>]}
[0m10:44:13.264887 [info ] [MainThread]: Found 7 snapshots, 3 models, 19 data tests, 9 sources, 590 macros
[0m10:44:13.265125 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9116e986-78e6-4467-8646-17bf90dd5761', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110953f90>]}
[0m10:44:13.266679 [info ] [MainThread]: 
[0m10:44:13.267149 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5704909392, session-id=None, name=master, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7390, 8194199360), compute-name=) - Creating connection
[0m10:44:13.267355 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:44:13.267541 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5704909392, session-id=None, name=master, idle-time=1.9073486328125e-06s, acquire-count=1, language=None, thread-identifier=(7390, 8194199360), compute-name=) - Acquired connection on thread (7390, 8194199360), using default compute resource
[0m10:44:13.271515 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=None, name=list_hive_metastore_saleslt, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Creating connection
[0m10:44:13.271860 [debug] [ThreadPool]: Acquiring new databricks connection 'list_hive_metastore_saleslt'
[0m10:44:13.272113 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=None, name=list_hive_metastore_saleslt, idle-time=5.0067901611328125e-06s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource
[0m10:44:13.272416 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=None, name=list_hive_metastore_saleslt, idle-time=0.0003428459167480469s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:13.272610 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=None, name=list_hive_metastore_saleslt, idle-time=0.0005469322204589844s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Retrieving connection
[0m10:44:13.272764 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m10:44:13.272926 [debug] [ThreadPool]: On list_hive_metastore_saleslt: GetTables(database=hive_metastore, schema=saleslt, identifier=None)
[0m10:44:13.273081 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:44:13.777080 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_saleslt, idle-time=4.0531158447265625e-06s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Connection created
[0m10:44:13.777654 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, command-id=Unknown) - Created cursor
[0m10:44:14.519044 [debug] [ThreadPool]: SQL status: OK in 1.250 seconds
[0m10:44:14.530324 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, command-id=66599867-fcf7-4ac9-9efc-59db1d0d7c03) - Closing cursor
[0m10:44:14.539935 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_saleslt, idle-time=0.7629520893096924s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:14.540310 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_saleslt, idle-time=0.7633240222930908s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Retrieving connection
[0m10:44:14.540557 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_saleslt, idle-time=0.7636070251464844s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:14.540753 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_saleslt, idle-time=0.7638101577758789s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Retrieving connection
[0m10:44:14.540918 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m10:44:14.541060 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m10:44:14.541233 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */

      select current_catalog()
  
[0m10:44:14.541431 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, command-id=Unknown) - Created cursor
[0m10:44:14.886783 [debug] [ThreadPool]: SQL status: OK in 0.350 seconds
[0m10:44:14.889234 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, command-id=6d4619a0-c672-4821-957d-1e7d582f2d2a) - Closing cursor
[0m10:44:14.893400 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_saleslt, idle-time=1.1164228916168213s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:14.893672 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_saleslt, idle-time=1.116718053817749s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Retrieving connection
[0m10:44:14.893924 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_saleslt"
[0m10:44:14.894153 [debug] [ThreadPool]: On list_hive_metastore_saleslt: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_saleslt"} */
show views in `hive_metastore`.`saleslt`
  
[0m10:44:14.894352 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, command-id=Unknown) - Created cursor
[0m10:44:15.316023 [debug] [ThreadPool]: SQL status: OK in 0.420 seconds
[0m10:44:15.319592 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, command-id=acac437f-7c76-41e3-afea-37613718820f) - Closing cursor
[0m10:44:15.320559 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_saleslt, idle-time=3.0994415283203125e-06s, acquire-count=0, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.321134 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_saleslt, idle-time=0.0006341934204101562s, acquire-count=0, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.322361 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_hive_metastore_saleslt, now list_hive_metastore_snapshots)
[0m10:44:15.322573 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_snapshots, idle-time=0.0020830631256103516s, acquire-count=0, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named list_hive_metastore_saleslt
[0m10:44:15.322785 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_snapshots, idle-time=0.0022840499877929688s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource
[0m10:44:15.322990 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_snapshots, idle-time=0.0025119781494140625s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.323179 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_snapshots, idle-time=0.002701997756958008s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Retrieving connection
[0m10:44:15.323335 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m10:44:15.323543 [debug] [ThreadPool]: On list_hive_metastore_snapshots: GetTables(database=hive_metastore, schema=snapshots, identifier=None)
[0m10:44:15.323742 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, command-id=Unknown) - Created cursor
[0m10:44:15.584178 [debug] [ThreadPool]: SQL status: OK in 0.260 seconds
[0m10:44:15.587696 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, command-id=d3f24a14-123e-43b3-bbbe-e63227c4b2a4) - Closing cursor
[0m10:44:15.590450 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_snapshots, idle-time=0.2698850631713867s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.590741 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_snapshots, idle-time=0.27025413513183594s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Retrieving connection
[0m10:44:15.590908 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m10:44:15.591075 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */

      select current_catalog()
  
[0m10:44:15.591248 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, command-id=Unknown) - Created cursor
[0m10:44:15.680686 [debug] [ThreadPool]: SQL status: OK in 0.090 seconds
[0m10:44:15.683538 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, command-id=b0d8ea57-12cb-4a32-9513-d30fe0d1d0d3) - Closing cursor
[0m10:44:15.685118 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_snapshots, idle-time=0.3646199703216553s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.685342 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_snapshots, idle-time=0.3648569583892822s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Retrieving connection
[0m10:44:15.685500 [debug] [ThreadPool]: Using databricks connection "list_hive_metastore_snapshots"
[0m10:44:15.685664 [debug] [ThreadPool]: On list_hive_metastore_snapshots: /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "list_hive_metastore_snapshots"} */
show views in `hive_metastore`.`snapshots`
  
[0m10:44:15.685831 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, command-id=Unknown) - Created cursor
[0m10:44:15.854201 [debug] [ThreadPool]: SQL status: OK in 0.170 seconds
[0m10:44:15.858381 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, command-id=00b5b573-c4c7-4789-901d-53abd4cf01e0) - Closing cursor
[0m10:44:15.858987 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_snapshots, idle-time=3.0994415283203125e-06s, acquire-count=0, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.860118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9116e986-78e6-4467-8646-17bf90dd5761', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1547113d0>]}
[0m10:44:15.860676 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=5704909392, session-id=None, name=master, idle-time=2.1457672119140625e-06s, acquire-count=0, language=None, thread-identifier=(7390, 8194199360), compute-name=) - Released connection
[0m10:44:15.860968 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:44:15.861176 [info ] [MainThread]: 
[0m10:44:15.864204 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.address_snapshot
[0m10:44:15.864731 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=list_hive_metastore_snapshots, idle-time=0.005672931671142578s, acquire-count=0, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.865032 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_hive_metastore_snapshots, now snapshot.medallion_dbt_spark.address_snapshot)
[0m10:44:15.865366 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.006325960159301758s, acquire-count=0, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named list_hive_metastore_snapshots
[0m10:44:15.865720 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.006665945053100586s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model '`hive_metastore`.`snapshots`.`address_snapshot`'
[0m10:44:15.866057 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.address_snapshot
[0m10:44:15.872598 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.address_snapshot
[0m10:44:15.873027 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.873381 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.873725 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.address_snapshot
[0m10:44:15.873965 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.customer_snapshot
[0m10:44:15.874486 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.address_snapshot, idle-time=0.0011091232299804688s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.874687 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.address_snapshot, now snapshot.medallion_dbt_spark.customer_snapshot)
[0m10:44:15.874896 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.0015239715576171875s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.address_snapshot
[0m10:44:15.875099 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.0017299652099609375s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model '`hive_metastore`.`snapshots`.`customer_snapshot`'
[0m10:44:15.875291 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.customer_snapshot
[0m10:44:15.877810 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.customer_snapshot
[0m10:44:15.878076 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.878331 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.878608 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.customer_snapshot
[0m10:44:15.878817 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m10:44:15.879070 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.customer_snapshot, idle-time=0.0007410049438476562s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.879306 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.customer_snapshot, now snapshot.medallion_dbt_spark.customeraddress_snapshot)
[0m10:44:15.879518 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.0011870861053466797s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.customer_snapshot
[0m10:44:15.879725 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.0013871192932128906s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model '`hive_metastore`.`snapshots`.`customeraddress_snapshot`'
[0m10:44:15.879945 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m10:44:15.882083 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m10:44:15.882323 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.882572 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.882838 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m10:44:15.883036 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.product_snapshot
[0m10:44:15.883491 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.customeraddress_snapshot, idle-time=0.0008771419525146484s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.883752 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.customeraddress_snapshot, now snapshot.medallion_dbt_spark.product_snapshot)
[0m10:44:15.883997 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.001413106918334961s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.customeraddress_snapshot
[0m10:44:15.884233 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.0016541481018066406s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model '`hive_metastore`.`snapshots`.`product_snapshot`'
[0m10:44:15.884430 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.product_snapshot
[0m10:44:15.888433 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.product_snapshot
[0m10:44:15.888799 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.889131 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.889499 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.product_snapshot
[0m10:44:15.889783 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.productmodel_snapshot
[0m10:44:15.890123 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.product_snapshot, idle-time=0.0009720325469970703s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.890358 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.product_snapshot, now snapshot.medallion_dbt_spark.productmodel_snapshot)
[0m10:44:15.890651 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.0014820098876953125s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.product_snapshot
[0m10:44:15.890967 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.0018198490142822266s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model '`hive_metastore`.`snapshots`.`productmodel_snapshot`'
[0m10:44:15.891193 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.productmodel_snapshot
[0m10:44:15.893571 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.productmodel_snapshot
[0m10:44:15.893868 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=7.152557373046875e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.894162 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.894463 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.productmodel_snapshot
[0m10:44:15.894702 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m10:44:15.894971 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.productmodel_snapshot, idle-time=0.0008168220520019531s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.895149 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.productmodel_snapshot, now snapshot.medallion_dbt_spark.salesorderdetail_snapshot)
[0m10:44:15.895495 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.001306772232055664s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.productmodel_snapshot
[0m10:44:15.895795 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.0016279220581054688s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model '`hive_metastore`.`snapshots`.`salesorderdetail_snapshot`'
[0m10:44:15.895996 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m10:44:15.898391 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m10:44:15.898651 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.898926 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.899234 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m10:44:15.899452 [debug] [Thread-1 (]: Began running node snapshot.medallion_dbt_spark.salesorderheader_snapshot
[0m10:44:15.899801 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.salesorderdetail_snapshot, idle-time=0.0008628368377685547s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.899998 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.salesorderdetail_snapshot, now snapshot.medallion_dbt_spark.salesorderheader_snapshot)
[0m10:44:15.900212 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=0.0012788772583007812s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.salesorderdetail_snapshot
[0m10:44:15.900420 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=0.0014939308166503906s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model '`hive_metastore`.`snapshots`.`salesorderheader_snapshot`'
[0m10:44:15.900608 [debug] [Thread-1 (]: Began compiling node snapshot.medallion_dbt_spark.salesorderheader_snapshot
[0m10:44:15.902761 [debug] [Thread-1 (]: Began executing node snapshot.medallion_dbt_spark.salesorderheader_snapshot
[0m10:44:15.902998 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=7.152557373046875e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.903280 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.903555 [debug] [Thread-1 (]: Finished running node snapshot.medallion_dbt_spark.salesorderheader_snapshot
[0m10:44:15.903780 [debug] [Thread-1 (]: Began running node model.medallion_dbt_spark.dim_customer
[0m10:44:15.904089 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=snapshot.medallion_dbt_spark.salesorderheader_snapshot, idle-time=0.0008242130279541016s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.904256 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly snapshot.medallion_dbt_spark.salesorderheader_snapshot, now model.medallion_dbt_spark.dim_customer)
[0m10:44:15.904473 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=model.medallion_dbt_spark.dim_customer, idle-time=0.0012030601501464844s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named snapshot.medallion_dbt_spark.salesorderheader_snapshot
[0m10:44:15.904691 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=model.medallion_dbt_spark.dim_customer, idle-time=0.0014181137084960938s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model '`hive_metastore`.`saleslt`.`dim_customer`'
[0m10:44:15.904877 [debug] [Thread-1 (]: Began compiling node model.medallion_dbt_spark.dim_customer
[0m10:44:15.907278 [debug] [Thread-1 (]: Writing injected SQL for node "model.medallion_dbt_spark.dim_customer"
[0m10:44:15.908180 [debug] [Thread-1 (]: Began executing node model.medallion_dbt_spark.dim_customer
[0m10:44:15.908485 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=model.medallion_dbt_spark.dim_customer, idle-time=7.152557373046875e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.908790 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=model.medallion_dbt_spark.dim_customer, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.909085 [debug] [Thread-1 (]: Finished running node model.medallion_dbt_spark.dim_customer
[0m10:44:15.909316 [debug] [Thread-1 (]: Began running node model.medallion_dbt_spark.dim_product
[0m10:44:15.909654 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=model.medallion_dbt_spark.dim_customer, idle-time=0.0008502006530761719s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.909862 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.medallion_dbt_spark.dim_customer, now model.medallion_dbt_spark.dim_product)
[0m10:44:15.910074 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=model.medallion_dbt_spark.dim_product, idle-time=0.001280069351196289s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named model.medallion_dbt_spark.dim_customer
[0m10:44:15.910287 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=model.medallion_dbt_spark.dim_product, idle-time=0.0014920234680175781s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model '`hive_metastore`.`saleslt`.`dim_product`'
[0m10:44:15.910471 [debug] [Thread-1 (]: Began compiling node model.medallion_dbt_spark.dim_product
[0m10:44:15.912691 [debug] [Thread-1 (]: Writing injected SQL for node "model.medallion_dbt_spark.dim_product"
[0m10:44:15.913126 [debug] [Thread-1 (]: Began executing node model.medallion_dbt_spark.dim_product
[0m10:44:15.913340 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=model.medallion_dbt_spark.dim_product, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.913596 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=model.medallion_dbt_spark.dim_product, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.913870 [debug] [Thread-1 (]: Finished running node model.medallion_dbt_spark.dim_product
[0m10:44:15.914077 [debug] [Thread-1 (]: Began running node model.medallion_dbt_spark.dim_sales
[0m10:44:15.914382 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=model.medallion_dbt_spark.dim_product, idle-time=0.0007641315460205078s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.914582 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.medallion_dbt_spark.dim_product, now model.medallion_dbt_spark.dim_sales)
[0m10:44:15.914795 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=model.medallion_dbt_spark.dim_sales, idle-time=0.0011942386627197266s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named model.medallion_dbt_spark.dim_product
[0m10:44:15.915003 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=model.medallion_dbt_spark.dim_sales, idle-time=0.001402139663696289s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model '`hive_metastore`.`saleslt`.`dim_sales`'
[0m10:44:15.915194 [debug] [Thread-1 (]: Began compiling node model.medallion_dbt_spark.dim_sales
[0m10:44:15.917675 [debug] [Thread-1 (]: Writing injected SQL for node "model.medallion_dbt_spark.dim_sales"
[0m10:44:15.918295 [debug] [Thread-1 (]: Began executing node model.medallion_dbt_spark.dim_sales
[0m10:44:15.918534 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=model.medallion_dbt_spark.dim_sales, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.918804 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=model.medallion_dbt_spark.dim_sales, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.919087 [debug] [Thread-1 (]: Finished running node model.medallion_dbt_spark.dim_sales
[0m10:44:15.919731 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0
[0m10:44:15.920052 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=model.medallion_dbt_spark.dim_sales, idle-time=0.0012481212615966797s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.920227 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.medallion_dbt_spark.dim_sales, now test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0)
[0m10:44:15.920426 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=0.0016269683837890625s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named model.medallion_dbt_spark.dim_sales
[0m10:44:15.920662 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=0.0018608570098876953s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:15.920865 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0
[0m10:44:15.928307 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0"
[0m10:44:15.928982 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0
[0m10:44:15.929232 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.929520 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.929801 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0
[0m10:44:15.930048 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411
[0m10:44:15.930377 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, idle-time=0.0008518695831298828s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.930559 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0, now test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411)
[0m10:44:15.930769 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=0.0012509822845458984s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_CustomerID.8c4a30b8c0
[0m10:44:15.930979 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=0.0014629364013671875s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:15.931172 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411
[0m10:44:15.933909 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411"
[0m10:44:15.934577 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411
[0m10:44:15.934801 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.935053 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.935319 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411
[0m10:44:15.935523 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb
[0m10:44:15.935781 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, idle-time=0.0007271766662597656s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.935945 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411, now test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb)
[0m10:44:15.936145 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=0.0010881423950195312s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_OrderQty.3075186411
[0m10:44:15.936344 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=0.0012891292572021484s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:15.936524 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb
[0m10:44:15.938905 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb"
[0m10:44:15.939589 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb
[0m10:44:15.939808 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.940081 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.940393 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb
[0m10:44:15.940660 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6
[0m10:44:15.941006 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, idle-time=0.0009109973907470703s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.941233 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb, now test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6)
[0m10:44:15.941446 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=0.0013840198516845703s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_SalesOrderDetailID.f224dee9bb
[0m10:44:15.941659 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=0.0015969276428222656s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:15.941856 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6
[0m10:44:15.945723 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6"
[0m10:44:15.946305 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6
[0m10:44:15.946521 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.946768 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.947045 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6
[0m10:44:15.947282 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m10:44:15.947543 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, idle-time=0.0007669925689697266s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.947702 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6, now test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131)
[0m10:44:15.947889 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.0011229515075683594s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_SalesOrderID.e4a71eaae6
[0m10:44:15.948089 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.0013201236724853516s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:15.948267 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m10:44:15.950619 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131"
[0m10:44:15.951599 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m10:44:15.951817 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.952067 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.952336 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m10:44:15.952534 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m10:44:15.952790 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, idle-time=0.0007259845733642578s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.952946 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131, now test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8)
[0m10:44:15.953138 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.0010700225830078125s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_freight.ca13e04131
[0m10:44:15.953338 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.0012710094451904297s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:15.953518 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m10:44:15.955952 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8"
[0m10:44:15.956368 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m10:44:15.956644 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.957013 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.957301 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m10:44:15.957511 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m10:44:15.957843 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, idle-time=0.0008151531219482422s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.958100 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8, now test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f)
[0m10:44:15.958313 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.0013120174407958984s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_lineTotal.d55bca27f8
[0m10:44:15.958527 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.0015270709991455078s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:15.958732 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m10:44:15.961253 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f"
[0m10:44:15.961809 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m10:44:15.962035 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.962294 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=4.76837158203125e-06s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.962599 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m10:44:15.962837 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m10:44:15.963095 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, idle-time=0.0008089542388916016s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.963252 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f, now test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77)
[0m10:44:15.963462 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0011739730834960938s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_listPrice.4ee58b9e3f
[0m10:44:15.963678 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0013849735260009766s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:15.963861 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m10:44:15.966169 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77"
[0m10:44:15.966490 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m10:44:15.966684 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.966930 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.967201 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m10:44:15.967401 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m10:44:15.967648 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, idle-time=0.0007200241088867188s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.967804 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77, now test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3)
[0m10:44:15.968011 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0010828971862792969s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_name.4c7b961f77
[0m10:44:15.968209 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0012791156768798828s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:15.968394 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m10:44:15.970817 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3"
[0m10:44:15.971149 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m10:44:15.971356 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.971606 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.971872 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m10:44:15.972085 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m10:44:15.972334 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, idle-time=0.0007281303405761719s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.972496 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3, now test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890)
[0m10:44:15.972687 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0010800361633300781s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_orderDate.6f6f720ec3
[0m10:44:15.972893 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0012860298156738281s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:15.973078 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m10:44:15.975577 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890"
[0m10:44:15.975920 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m10:44:15.976124 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.976364 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.976640 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m10:44:15.976846 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m10:44:15.977097 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, idle-time=0.0007340908050537109s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.977257 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890, now test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd)
[0m10:44:15.977458 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.001093149185180664s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_productID.cbf6d34890
[0m10:44:15.977657 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.001293182373046875s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:15.977836 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m10:44:15.980123 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd"
[0m10:44:15.980632 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m10:44:15.980845 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=7.152557373046875e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.981096 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.981362 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m10:44:15.981560 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m10:44:15.981820 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, idle-time=0.0007262229919433594s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.981978 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd, now test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118)
[0m10:44:15.982171 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0010781288146972656s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_productNumber.3a23a94ddd
[0m10:44:15.982376 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0012769699096679688s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:15.982553 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m10:44:15.984934 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118"
[0m10:44:15.985536 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m10:44:15.985744 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.985986 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.986246 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m10:44:15.986453 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m10:44:15.986703 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, idle-time=0.0007131099700927734s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.986862 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118, now test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3)
[0m10:44:15.987053 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0010671615600585938s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_sellStartDate.b44c8ea118
[0m10:44:15.987260 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0012722015380859375s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:15.987436 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m10:44:15.991263 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3"
[0m10:44:15.991645 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m10:44:15.991857 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=2.1457672119140625e-06s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.992105 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.992380 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m10:44:15.992588 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m10:44:15.992930 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, idle-time=0.0007851123809814453s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.993159 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3, now test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487)
[0m10:44:15.993374 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.0012619495391845703s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_standardCost.d3f58be9a3
[0m10:44:15.993589 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.0014801025390625s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:15.993772 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m10:44:15.996496 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487"
[0m10:44:15.997113 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m10:44:15.997340 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.997592 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:15.997878 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m10:44:15.998083 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m10:44:15.998339 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, idle-time=0.0007450580596923828s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:15.998499 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487, now test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a)
[0m10:44:15.998688 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.0010979175567626953s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_subTotal.bfeb62a487
[0m10:44:15.998885 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.001293182373046875s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:15.999073 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m10:44:16.001511 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a"
[0m10:44:16.002263 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m10:44:16.002487 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:16.002741 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:16.003012 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m10:44:16.003217 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m10:44:16.003467 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, idle-time=0.0007259845733642578s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:16.003627 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a, now test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023)
[0m10:44:16.003818 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.001077890396118164s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_taxAmt.94cff67d6a
[0m10:44:16.004016 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.0012781620025634766s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:16.004205 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m10:44:16.006629 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023"
[0m10:44:16.007003 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m10:44:16.007214 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:16.007471 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:16.007739 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m10:44:16.007946 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m10:44:16.008210 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, idle-time=0.0007398128509521484s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:16.008480 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023, now test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a)
[0m10:44:16.008779 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.0012879371643066406s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_totalDue.920571e023
[0m10:44:16.008989 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.001516103744506836s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:16.009171 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m10:44:16.011628 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a"
[0m10:44:16.012392 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m10:44:16.012694 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:16.013006 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:16.013304 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m10:44:16.013531 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108
[0m10:44:16.013860 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, idle-time=0.0008442401885986328s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:16.014066 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a, now test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108)
[0m10:44:16.014286 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=0.0012862682342529297s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.not_null_dim_sales_unitPrice.3545b5473a
[0m10:44:16.014497 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=0.001505136489868164s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:16.014694 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108
[0m10:44:16.018805 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108"
[0m10:44:16.019468 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108
[0m10:44:16.019692 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:16.019950 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=9.5367431640625e-07s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:16.020225 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108
[0m10:44:16.020433 [debug] [Thread-1 (]: Began running node test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef
[0m10:44:16.020693 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, idle-time=0.0007450580596923828s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:16.020855 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108, now test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef)
[0m10:44:16.021053 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef, idle-time=0.0011053085327148438s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named test.medallion_dbt_spark.unique_dim_sales_SalesOrderDetailID.46e1765108
[0m10:44:16.021257 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef, idle-time=0.0013060569763183594s, acquire-count=1, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource for model 'None'
[0m10:44:16.021437 [debug] [Thread-1 (]: Began compiling node test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef
[0m10:44:16.023978 [debug] [Thread-1 (]: Writing injected SQL for node "test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef"
[0m10:44:16.024508 [debug] [Thread-1 (]: Began executing node test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef
[0m10:44:16.024732 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef, idle-time=0.0s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:16.024980 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(id=5705475152, session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f, name=test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef, idle-time=1.1920928955078125e-06s, acquire-count=0, language=sql, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:16.025251 [debug] [Thread-1 (]: Finished running node test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef
[0m10:44:16.025863 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:44:16.026041 [debug] [MainThread]: Connection 'test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef' was properly closed.
[0m10:44:16.026199 [debug] [MainThread]: On test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef: ROLLBACK
[0m10:44:16.026355 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m10:44:16.026501 [debug] [MainThread]: On test.medallion_dbt_spark.unique_dim_sales_SalesOrderID.d1f82b14ef: Close
[0m10:44:16.026754 [debug] [MainThread]: Databricks adapter: Connection(session-id=c316da7a-af30-47ae-9edf-ee848a3ca04f) - Closing connection
[0m10:44:16.132273 [debug] [MainThread]: Command end result
[0m10:44:16.210292 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4410917200, session-id=None, name=generate_catalog, idle-time=0s, acquire-count=0, language=None, thread-identifier=(7390, 8194199360), compute-name=) - Creating connection
[0m10:44:16.210615 [debug] [MainThread]: Acquiring new databricks connection 'generate_catalog'
[0m10:44:16.210805 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4410917200, session-id=None, name=generate_catalog, idle-time=1.1920928955078125e-06s, acquire-count=1, language=None, thread-identifier=(7390, 8194199360), compute-name=) - Acquired connection on thread (7390, 8194199360), using default compute resource
[0m10:44:16.210965 [info ] [MainThread]: Building catalog
[0m10:44:16.212778 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5704636112, session-id=None, name=('hive_metastore', 'snapshots'), idle-time=0s, acquire-count=0, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Creating connection
[0m10:44:16.213036 [debug] [ThreadPool]: Acquiring new databricks connection '('hive_metastore', 'snapshots')'
[0m10:44:16.213219 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5704636112, session-id=None, name=('hive_metastore', 'snapshots'), idle-time=9.5367431640625e-07s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource
[0m10:44:16.214716 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5704636112, session-id=None, name=('hive_metastore', 'snapshots'), idle-time=0.0014917850494384766s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:16.214914 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5704636112, session-id=None, name=('hive_metastore', 'snapshots'), idle-time=0.0017027854919433594s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Retrieving connection
[0m10:44:16.215092 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5704636112, session-id=None, name=('hive_metastore', 'snapshots'), idle-time=0.001882791519165039s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:16.215253 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5704636112, session-id=None, name=('hive_metastore', 'snapshots'), idle-time=0.002046823501586914s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Retrieving connection
[0m10:44:16.215397 [debug] [ThreadPool]: Spark adapter: NotImplemented: add_begin_query
[0m10:44:16.215528 [debug] [ThreadPool]: Using databricks connection "('hive_metastore', 'snapshots')"
[0m10:44:16.215695 [debug] [ThreadPool]: On ('hive_metastore', 'snapshots'): /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "('hive_metastore', 'snapshots')"} */

      select current_catalog()
  
[0m10:44:16.215844 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:44:16.472704 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5704636112, session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, name=('hive_metastore', 'snapshots'), idle-time=1.0013580322265625e-05s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Connection created
[0m10:44:16.473997 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, command-id=Unknown) - Created cursor
[0m10:44:16.576657 [debug] [ThreadPool]: SQL status: OK in 0.360 seconds
[0m10:44:16.579577 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, command-id=791aa933-b8be-43fd-9439-0f093ac4fc49) - Closing cursor
[0m10:44:16.584794 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5704636112, session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, name=('hive_metastore', 'snapshots'), idle-time=0.11246991157531738s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:16.585060 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5704636112, session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, name=('hive_metastore', 'snapshots'), idle-time=0.11275792121887207s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Retrieving connection
[0m10:44:16.585232 [debug] [ThreadPool]: Using databricks connection "('hive_metastore', 'snapshots')"
[0m10:44:16.585416 [debug] [ThreadPool]: On ('hive_metastore', 'snapshots'): /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "('hive_metastore', 'snapshots')"} */
show table extended in `hive_metastore`.`snapshots` like 'productmodel_snapshot|salesorderheader_snapshot|customer_snapshot|product_snapshot|address_snapshot|customeraddress_snapshot|salesorderdetail_snapshot'
  
[0m10:44:16.585610 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, command-id=Unknown) - Created cursor
[0m10:44:18.388131 [debug] [ThreadPool]: SQL status: OK in 1.800 seconds
[0m10:44:18.393621 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, command-id=47d4e2ea-42b3-4eb9-87b5-cb9b70dbf7cb) - Closing cursor
[0m10:44:18.398015 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5704636112, session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, name=('hive_metastore', 'snapshots'), idle-time=2.1457672119140625e-06s, acquire-count=0, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:18.398436 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5704636112, session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, name=('hive_metastore', 'snapshots'), idle-time=0.0004379749298095703s, acquire-count=0, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:18.398666 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly ('hive_metastore', 'snapshots'), now ('hive_metastore', 'saleslt'))
[0m10:44:18.398861 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5704636112, session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, name=('hive_metastore', 'saleslt'), idle-time=0.0008661746978759766s, acquire-count=0, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Reusing connection previously named ('hive_metastore', 'snapshots')
[0m10:44:18.399043 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5704636112, session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, name=('hive_metastore', 'saleslt'), idle-time=0.0010521411895751953s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Acquired connection on thread (7390, 6149304320), using default compute resource
[0m10:44:18.400528 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5704636112, session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, name=('hive_metastore', 'saleslt'), idle-time=0.0025331974029541016s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:18.400721 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5704636112, session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, name=('hive_metastore', 'saleslt'), idle-time=0.0027320384979248047s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Retrieving connection
[0m10:44:18.400871 [debug] [ThreadPool]: Using databricks connection "('hive_metastore', 'saleslt')"
[0m10:44:18.401034 [debug] [ThreadPool]: On ('hive_metastore', 'saleslt'): /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "('hive_metastore', 'saleslt')"} */

      select current_catalog()
  
[0m10:44:18.401205 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, command-id=Unknown) - Created cursor
[0m10:44:18.520026 [debug] [ThreadPool]: SQL status: OK in 0.120 seconds
[0m10:44:18.523639 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, command-id=4cf26ab2-c57f-41d9-9290-ec43ce639b82) - Closing cursor
[0m10:44:18.527105 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5704636112, session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, name=('hive_metastore', 'saleslt'), idle-time=0.12906312942504883s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Checking idleness
[0m10:44:18.527477 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5704636112, session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, name=('hive_metastore', 'saleslt'), idle-time=0.12946724891662598s, acquire-count=1, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Retrieving connection
[0m10:44:18.527724 [debug] [ThreadPool]: Using databricks connection "('hive_metastore', 'saleslt')"
[0m10:44:18.528004 [debug] [ThreadPool]: On ('hive_metastore', 'saleslt'): /* {"app": "dbt", "dbt_version": "1.8.5", "dbt_databricks_version": "1.8.5", "databricks_sql_connector_version": "3.1.2", "profile_name": "medallion_dbt_spark", "target_name": "dev", "connection_name": "('hive_metastore', 'saleslt')"} */
show table extended in `hive_metastore`.`saleslt` like 'customeraddress|productmodel|productdescription|dim_product|dim_sales|salesorderdetail|dim_customer|customer|product|productcategory|address|salesorderheader'
  
[0m10:44:18.528221 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, command-id=Unknown) - Created cursor
[0m10:44:19.208389 [debug] [ThreadPool]: SQL status: OK in 0.680 seconds
[0m10:44:19.213392 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, command-id=5d36691b-837a-4520-8204-fe2d11c3901d) - Closing cursor
[0m10:44:19.217027 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(id=5704636112, session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b, name=('hive_metastore', 'saleslt'), idle-time=1.9073486328125e-06s, acquire-count=0, language=None, thread-identifier=(7390, 6149304320), compute-name=) - Released connection
[0m10:44:19.219335 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(id=4410917200, session-id=None, name=generate_catalog, idle-time=1.6689300537109375e-06s, acquire-count=0, language=None, thread-identifier=(7390, 8194199360), compute-name=) - Released connection
[0m10:44:19.253469 [info ] [MainThread]: Catalog written to /Users/vaishnavitamilvanan/Documents/GW MS DS/Semester/Fall 2024/NLP/PycharmProjects/Medallion-Spark-Azure-DBT/medallion_dbt_spark/target/catalog.json
[0m10:44:19.255964 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 7.790127, "process_user_time": 2.924284, "process_kernel_time": 2.240336, "process_mem_max_rss": "222789632", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m10:44:19.256351 [debug] [MainThread]: Command `dbt docs generate` succeeded at 10:44:19.256299 after 7.79 seconds
[0m10:44:19.256548 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m10:44:19.256701 [debug] [MainThread]: Connection '('hive_metastore', 'saleslt')' was properly closed.
[0m10:44:19.256849 [debug] [MainThread]: On ('hive_metastore', 'saleslt'): ROLLBACK
[0m10:44:19.257005 [debug] [MainThread]: Databricks adapter: NotImplemented: rollback
[0m10:44:19.257149 [debug] [MainThread]: On ('hive_metastore', 'saleslt'): Close
[0m10:44:19.257310 [debug] [MainThread]: Databricks adapter: Connection(session-id=a15e4f08-9e33-4faf-a5de-2ad3211c636b) - Closing connection
[0m10:44:19.308508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110959e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1540e5a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e94150>]}
[0m10:44:19.308974 [debug] [MainThread]: Flushing usage events
[0m10:45:49.706106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b65cc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6ada90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6bbc90>]}


============================== 10:45:49.709683 | c29d5e23-cb6c-4ad3-968d-8f96d04a46b9 ==============================
[0m10:45:49.709683 [info ] [MainThread]: Running with dbt=1.8.5
[0m10:45:49.710171 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/vaishnavitamilvanan/Documents/GW MS DS/Semester/Fall 2024/NLP/PycharmProjects/Medallion-Spark-Azure-DBT/medallion_dbt_spark/logs', 'debug': 'False', 'profiles_dir': '/Users/vaishnavitamilvanan/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt docs serve', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:45:49.810965 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m10:45:49.811473 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m10:45:49.811690 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m10:45:50.987581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c29d5e23-cb6c-4ad3-968d-8f96d04a46b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1663052d0>]}
[0m10:45:51.015119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c29d5e23-cb6c-4ad3-968d-8f96d04a46b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x166216250>]}
[0m12:02:11.184309 [error] [MainThread]: Encountered an error:

[0m12:02:11.197445 [error] [MainThread]: Traceback (most recent call last):
  File "/Users/vaishnavitamilvanan/anaconda3/lib/python3.11/site-packages/dbt/cli/requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/vaishnavitamilvanan/anaconda3/lib/python3.11/site-packages/dbt/cli/requires.py", line 101, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/vaishnavitamilvanan/anaconda3/lib/python3.11/site-packages/dbt/cli/requires.py", line 218, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/vaishnavitamilvanan/anaconda3/lib/python3.11/site-packages/dbt/cli/requires.py", line 247, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/vaishnavitamilvanan/anaconda3/lib/python3.11/site-packages/dbt/cli/requires.py", line 294, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/vaishnavitamilvanan/anaconda3/lib/python3.11/site-packages/dbt/cli/main.py", line 303, in docs_serve
    results = task.run()
              ^^^^^^^^^^
  File "/Users/vaishnavitamilvanan/anaconda3/lib/python3.11/site-packages/dbt/task/docs/serve.py", line 29, in run
    httpd.serve_forever()
  File "/Users/vaishnavitamilvanan/anaconda3/lib/python3.11/socketserver.py", line 233, in serve_forever
    ready = selector.select(poll_interval)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/vaishnavitamilvanan/anaconda3/lib/python3.11/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

[0m12:02:11.265885 [debug] [MainThread]: Resource report: {"command_name": "serve", "command_wall_clock_time": 62888.406, "process_user_time": 6.431442, "process_kernel_time": 5.750631, "process_mem_max_rss": "202162176", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m12:02:11.267459 [debug] [MainThread]: Command `dbt docs serve` failed at 12:02:11.267339 after 62888.41 seconds
[0m12:02:11.268310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6bbe10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b6c4490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b65fe10>]}
[0m12:02:11.268868 [debug] [MainThread]: Flushing usage events
